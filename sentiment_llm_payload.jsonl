{"id": 40345800, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Tiktoken added support for GPT-4o: It has an increased vocab size of 200k.", "normalized_text": "tiktoken added support for gpt 4o it has an increased vocab size of 200k", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "atgctg", "node_time": "2024-05-13T17:30:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345812, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "The most impressive part is that the voice uses the right feelings and tonal language during the presentation. I'm not sure how much of that was that they had tested this over and over, but it is really hard to get that right so if they didn't fake it in some way I'd say that is revolutionary.", "normalized_text": "the most impressive part is that the voice uses the right feelings and tonal language during the presentation i m not sure how much of that was that they had tested this over and over but it is really hard to get that right so if they didn t fake it in some way i d say that is revolutionary", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "Jensson", "node_time": "2024-05-13T17:31:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345816, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Parts of the demo were quite choppy (latency?) so this definitely feels rushed in response to Google I/O. Other than that, looks good. Desktop app is great, but I didn’t see no mention of being able to use your own API key so OS projects might still be needed. The biggest thing is bringing GPT-4 to free users, that is an interesting move. Depending on what the limits are, I might cancel my subscription.", "normalized_text": "parts of the demo were quite choppy latency so this definitely feels rushed in response to google i o other than that looks good desktop app is great but i didn’t see no mention of being able to use your own api key so os projects might still be needed the biggest thing is bringing gpt 4 to free users that is an interesting move depending on what the limits are i might cancel my subscription", "model_tags": ["openai", "google"], "aspect_hints": ["performance_speed", "usability_ux", "cost_price"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "skilled", "node_time": "2024-05-13T17:31:37+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345836, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I admit I drink the koolaid and love LLMs and their applications. But damn, the way it’s responds in the demo gave me goosebumps in a bad way. Like an uncanny valley instincts kicks in.", "normalized_text": "i admit i drink the koolaid and love llms and their applications but damn the way it’s responds in the demo gave me goosebumps in a bad way like an uncanny valley instincts kicks in", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "syntaxing", "node_time": "2024-05-13T17:33:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345909, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "They are admitting[1] that the new model is the gpt2-chatbot that we have seen before[2]. As many highlighted there, the model is not an improvement like GPT3->GPT4. I tested a bunch of programming stuff and it was not that much better. It's interesting that OpenAI is highlighting the Elo score instead of showing results for many many benchmarks that all models are stuck at 50-70% success. [1] [2]", "normalized_text": "they are admitting 1 that the new model is the gpt2 chatbot that we have seen before 2 as many highlighted there the model is not an improvement like gpt3 gpt4 i tested a bunch of programming stuff and it was not that much better it s interesting that openai is highlighting the elo score instead of showing results for many many benchmarks that all models are stuck at 50 70 success 1 2", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "msoad", "node_time": "2024-05-13T17:37:59+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345910, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Big questions are (1) when is this going to be rolled out to paid users? (2) what is the remaining benefit of being a paid user if this is rolled out to free users? (3) Biggest concern is will this degrade the paid experience since GPT-4 interactions are already rate limited. Does OpenAI have the hardware to handle this? Edit: according to @gdb this is coming in \"weeks\"", "normalized_text": "big questions are 1 when is this going to be rolled out to paid users 2 what is the remaining benefit of being a paid user if this is rolled out to free users 3 biggest concern is will this degrade the paid experience since gpt 4 interactions are already rate limited does openai have the hardware to handle this edit according to gdb this is coming in weeks", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "Jimmc414", "node_time": "2024-05-13T17:38:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345937, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Very, very impressive for a \"minor\" release demo. The capabilities here would look shockingly advanced just 5 years ago. Universal translator, pair programmer, completely human sounding voice assistant and all in real time. Scifi tropes made real. But: Interesting next to see how it actually performs IRL latency and without cherry-picking. No snark, it was great but need to see real world power. Also what the benefits are to subscribers if all this is going to be free...", "normalized_text": "very very impressive for a minor release demo the capabilities here would look shockingly advanced just 5 years ago universal translator pair programmer completely human sounding voice assistant and all in real time scifi tropes made real but interesting next to see how it actually performs irl latency and without cherry picking no snark it was great but need to see real world power also what the benefits are to subscribers if all this is going to be free", "model_tags": [], "aspect_hints": ["performance_speed", "regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "mellosouls", "node_time": "2024-05-13T17:39:36+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345988, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "This is really impressive engineering. I thought real time agents would completely change the way we're going to interact with large models but it would take 1~2 more years. I wonder what kind of new techs are developed to enable this, but OpenAI is fairly secretive so we won't be able to know their sauce. On the other hand, this also feels like a signal that reasoning capability has probably already been plateaued at GPT-4 level and OpenAI knew it so they decided to focus on research that matters to delivering product engineering rather than long-term research to unlock further general (super)intelligence.", "normalized_text": "this is really impressive engineering i thought real time agents would completely change the way we re going to interact with large models but it would take 1 2 more years i wonder what kind of new techs are developed to enable this but openai is fairly secretive so we won t be able to know their sauce on the other hand this also feels like a signal that reasoning capability has probably already been plateaued at gpt 4 level and openai knew it so they decided to focus on research that matters to delivering product engineering rather than long term research to unlock further general super intelligence", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "summerlight", "node_time": "2024-05-13T17:43:46+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346082, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "OAI just made an embarrassment of Google's fake demo earlier this year. Given how this was recorded, I am pretty certain it's authentic.", "normalized_text": "oai just made an embarrassment of google s fake demo earlier this year given how this was recorded i am pretty certain it s authentic", "model_tags": ["google"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "bearjaws", "node_time": "2024-05-13T17:50:09+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346200, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I found these videos quite hard to watch. There is a level of cringe that I found a bit unpleasant. It’s like some kind of uncanny valley of human interaction that I don’t get on nearly the same level with the text version.", "normalized_text": "i found these videos quite hard to watch there is a level of cringe that i found a bit unpleasant it’s like some kind of uncanny valley of human interaction that i don’t get on nearly the same level with the text version", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "Negitivefrags", "node_time": "2024-05-13T17:57:12+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346978, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Very interesting and extremely impressive! I tried using the voice chat in their app previously and was disappointed. The big UX problem was that it didn't try to understand when I had finished speaking. English is a second language and I paused a bit too long thinking of a word and it just started responding to my obviously half spoken sentence. Trying again it just became stressful as I had to rush my words out to avoid an annoying response to an unfinished thought. I didn't try interrupting it but judging by the comments here it was not possible. It was very surprising to me to be so overtly exposed to the nuances of real conversation. Just this one thing of not understanding when it's your turn to talk made the interaction very unpleasant, more than I would have expected. On that note, I noticed that the AI in the demo seems to be very rambly. It almost always just kept talking and many statements were reiterations of previous ones. It reminded me of a type of youtuber that uses a lot of filler phrases like \"let's go ahead and ...\", just to be more verbose and lessen silences. Most of the statements by the guy doing the demo were interrupting the AI. It's still extremely impressive but I found this interesting enough to share. It will be exciting to see how hard it is to reproduce these abilities in the open, and to solve this issue.", "normalized_text": "very interesting and extremely impressive i tried using the voice chat in their app previously and was disappointed the big ux problem was that it didn t try to understand when i had finished speaking english is a second language and i paused a bit too long thinking of a word and it just started responding to my obviously half spoken sentence trying again it just became stressful as i had to rush my words out to avoid an annoying response to an unfinished thought i didn t try interrupting it but judging by the comments here it was not possible it was very surprising to me to be so overtly exposed to the nuances of real conversation just this one thing of not understanding when it s your turn to talk made the interaction very unpleasant more than i would have expected on that note i noticed that the ai in the demo seems to be very rambly it almost always just kept talking and many statements were reiterations of previous ones it reminded me of a type of youtuber that uses a lot of filler phrases like let s go ahead and just to be more verbose and lessen silences most of the statements by the guy doing the demo were interrupting the ai it s still extremely impressive but i found this interesting enough to share it will be exciting to see how hard it is to reproduce these abilities in the open and to solve this issue", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "Hugsun", "node_time": "2024-05-13T19:02:47+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40347699, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Impressed by the model so far. As far as independent testing goes, it is topping our leaderboard for chess puzzle solving by a wide margin now:", "normalized_text": "impressed by the model so far as far as independent testing goes it is topping our leaderboard for chess puzzle solving by a wide margin now", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "freediver", "node_time": "2024-05-13T20:02:54+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40348664, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "We've had voice input and voice output with computers for a long time, but it's never felt like spoken conversation. At best it's a series of separate voice notes. It feels more like texting than talking. These demos show people talking to artificial intelligence. This is new. Humans are more partial to talking than writing. When people talk to each other (in person or over low-latency audio) there's a rich metadata channel of tone and timing, subtext, inexplicit knowledge. These videos seem to show the AI using this kind of metadata, in both input and output, and the conversation even flows reasonably well at times. I think this changes things a lot.", "normalized_text": "we ve had voice input and voice output with computers for a long time but it s never felt like spoken conversation at best it s a series of separate voice notes it feels more like texting than talking these demos show people talking to artificial intelligence this is new humans are more partial to talking than writing when people talk to each other in person or over low latency audio there s a rich metadata channel of tone and timing subtext inexplicit knowledge these videos seem to show the ai using this kind of metadata in both input and output and the conversation even flows reasonably well at times i think this changes things a lot", "model_tags": [], "aspect_hints": ["performance_speed", "privacy", "community_tone"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "cal85", "node_time": "2024-05-13T21:25:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40348813, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I worry that this tech will amplify the cultural values we have of \"good\" and \"bad\" emotions way more than the default restrictions that social media platforms put on the emoji reactions (e.g., can't be angry on LinkedIn). I worry that the AI will not express anger, not express sadness, not express frustration, not express uncertainty, and many other emotions that the culture of the fine-tuners might believe are \"bad\" emotions and that we may express a more and more narrow range of emotions going forward. Almost like it might become an AI \"yes man.\"", "normalized_text": "i worry that this tech will amplify the cultural values we have of good and bad emotions way more than the default restrictions that social media platforms put on the emoji reactions e g can t be angry on linkedin i worry that the ai will not express anger not express sadness not express frustration not express uncertainty and many other emotions that the culture of the fine tuners might believe are bad emotions and that we may express a more and more narrow range of emotions going forward almost like it might become an ai yes man", "model_tags": [], "aspect_hints": ["regulation_policy", "community_tone"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "jimkleiber", "node_time": "2024-05-13T21:38:53+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40350813, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I've worked quite a bit with STT and TTS over the past ~7 years, and this is the most impressive and even startling demo I've seen. But I would like to see how this is integrated into applications by third party developers where the AI is doing a specific job. Is it still as impressive? The biggest challenge I've had with building any autonomous \"agents\" with generic LLM's is they are overly gullible and accommodating, requiring the need to revert back to legacy chatbot logic trees etc. to stay on task and perform a job. Also STT is rife with speaker interjections, leading to significant user frustrations and they just want to talk to a person. Hard to see if this is really solved yet.", "normalized_text": "i ve worked quite a bit with stt and tts over the past 7 years and this is the most impressive and even startling demo i ve seen but i would like to see how this is integrated into applications by third party developers where the ai is doing a specific job is it still as impressive the biggest challenge i ve had with building any autonomous agents with generic llm s is they are overly gullible and accommodating requiring the need to revert back to legacy chatbot logic trees etc to stay on task and perform a job also stt is rife with speaker interjections leading to significant user frustrations and they just want to talk to a person hard to see if this is really solved yet", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "tompetry", "node_time": "2024-05-14T01:49:02+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40350884, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "GPT-4o tops the aider LLM code editing leaderboard at 72.9%, versus 68.4% for Opus. GPT-4o takes second on aider’s refactoring leaderboard with 62.9%, versus Opus at 72.3%. GPT-4o did much better than the 4-turbo models, and seems much less lazy. The latest release of aider uses GPT-4o by default.", "normalized_text": "gpt 4o tops the aider llm code editing leaderboard at 72 9 versus 68 4 for opus gpt 4o takes second on aider’s refactoring leaderboard with 62 9 versus opus at 72 3 gpt 4o did much better than the 4 turbo models and seems much less lazy the latest release of aider uses gpt 4o by default", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "anotherpaulg", "node_time": "2024-05-14T01:58:36+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40351027, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "This is the first demo where you can really sense that beating LLM benchmarks should not be the target. Just remember the time when the iPhone has meager specs but ultimately delivered a better phone experience than the competition. This is the power of the model where you can own the whole stack and build a product. Open Source will focus on LLM benchmarks since that is the only way foundational models can differentiate themselves, but it does not mean it is a path to a great user experience. So Open Source models like Llama will be here to stay, but it feels more like if you want to build a compelling product, you have to own and control your own model.", "normalized_text": "this is the first demo where you can really sense that beating llm benchmarks should not be the target just remember the time when the iphone has meager specs but ultimately delivered a better phone experience than the competition this is the power of the model where you can own the whole stack and build a product open source will focus on llm benchmarks since that is the only way foundational models can differentiate themselves but it does not mean it is a path to a great user experience so open source models like llama will be here to stay but it feels more like if you want to build a compelling product you have to own and control your own model", "model_tags": ["meta"], "aspect_hints": ["usability_ux", "business_model"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "dingclancy", "node_time": "2024-05-14T02:24:19+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40351436, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "This is a very cool demo - if you dig deeper there’s a clip of them having a “blind” AI talk to another AI with live camera input to ask it to explain what it’s seeing. Then they, together, sing a song about what they’re looking at, alternating each line, and rhyming with one another . Given all of the isolated capabilities of AI, this isn’t particularly surprising, but seeing it all work together in real time is pretty incredible. But it’s not scary. It’s… marvelous, cringey, uncomfortable, awe-inspiring. What’s scary is not what AI can currently do, but what we expect from it. Can it do math yet? Can it play chess? Can it write entire apps from scratch? Can it just do my entire job for me? We’re moving toward a world where every job will be modeled, and you’ll either be an AI owner, a model architect, an agent/hardware engineer, a technician, or just.. training data.", "normalized_text": "this is a very cool demo if you dig deeper there’s a clip of them having a “blind” ai talk to another ai with live camera input to ask it to explain what it’s seeing then they together sing a song about what they’re looking at alternating each line and rhyming with one another given all of the isolated capabilities of ai this isn’t particularly surprising but seeing it all work together in real time is pretty incredible but it’s not scary it’s… marvelous cringey uncomfortable awe inspiring what’s scary is not what ai can currently do but what we expect from it can it do math yet can it play chess can it write entire apps from scratch can it just do my entire job for me we’re moving toward a world where every job will be modeled and you’ll either be an ai owner a model architect an agent hardware engineer a technician or just training data", "model_tags": [], "aspect_hints": ["privacy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "plaidfuji", "node_time": "2024-05-14T03:41:23+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40352334, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Now that I see this, here is my wish (I know there are security privacy concerns but let's pretend there are not there for this wish): An app that runs on my desktop and has access to my screen(s) when I work. At any time I can ask it something about what's on the screen, it can jump in and let me know if it thinks I made a mistake (think pair programming) or a suggestion (drafting a document). It can also quickly take over if I ask it too (copilot on demand). Except for the last point and the desktop version I think it's already done in math demo video. I guess it will also pretty soon refuse to let me come back inside the spaceship, but until then it'll be a nice ride.", "normalized_text": "now that i see this here is my wish i know there are security privacy concerns but let s pretend there are not there for this wish an app that runs on my desktop and has access to my screen s when i work at any time i can ask it something about what s on the screen it can jump in and let me know if it thinks i made a mistake think pair programming or a suggestion drafting a document it can also quickly take over if i ask it too copilot on demand except for the last point and the desktop version i think it s already done in math demo video i guess it will also pretty soon refuse to let me come back inside the spaceship but until then it ll be a nice ride", "model_tags": [], "aspect_hints": ["security", "privacy", "usability_ux"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "maaaaattttt", "node_time": "2024-05-14T06:49:49+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40353317, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "That woman's voice intonation is just scary .Not because it talks really well, but because it is always happy, optimistic, enthusiastic. And this echoes to what several of my employers idealized as a good employee. That's terrifying because those AI become what their master's think an engaging human should be. It's quite close to Bostondynamics di some years ago. what did they show ? You can hit a robot very hard while it does its job and then what ? It just goes on without complaining. A perfect employee again. That's very dystopic to me. (but I'm impressed by the technical achievement)", "normalized_text": "that woman s voice intonation is just scary not because it talks really well but because it is always happy optimistic enthusiastic and this echoes to what several of my employers idealized as a good employee that s terrifying because those ai become what their master s think an engaging human should be it s quite close to bostondynamics di some years ago what did they show you can hit a robot very hard while it does its job and then what it just goes on without complaining a perfect employee again that s very dystopic to me but i m impressed by the technical achievement", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "wiz21c", "node_time": "2024-05-14T09:44:02+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40447613, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "If this really was a mistake the easiest way to deal with it would be to release people from their non disparagement agreements that were only signed by leaving employees under the duress of losing their vested equity. It's really easy to make people whole for this, so whether that happens or not is the difference between the apologies being real or just them just backpedaling because employees got upset. Edit: Looks like they're doing the right thing here: > Altman’s initial statement was criticized for doing too little to make things right for former employees, but in an emailed statement, OpenAI told me that “we are identifying and reaching out to former employees who signed a standard exit agreement to make it clear that OpenAI has not and will not cancel their vested equity and releases them from nondisparagement obligations” — which goes much further toward fixing their mistake.", "normalized_text": "if this really was a mistake the easiest way to deal with it would be to release people from their non disparagement agreements that were only signed by leaving employees under the duress of losing their vested equity it s really easy to make people whole for this so whether that happens or not is the difference between the apologies being real or just them just backpedaling because employees got upset edit looks like they re doing the right thing here altman’s initial statement was criticized for doing too little to make things right for former employees but in an emailed statement openai told me that “we are identifying and reaching out to former employees who signed a standard exit agreement to make it clear that openai has not and will not cancel their vested equity and releases them from nondisparagement obligations” — which goes much further toward fixing their mistake", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "tedivm", "node_time": "2024-05-22T22:38:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40447721, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Nothing quite like a contract’s consideration consisting solely of a pre-existing obligation. I wonder what they were thinking with that?", "normalized_text": "nothing quite like a contract’s consideration consisting solely of a pre existing obligation i wonder what they were thinking with that", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "tangentstar", "node_time": "2024-05-22T22:49:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448035, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Going to be hard to keep claiming you didn’t know something, if your signature is on it. I don’t really think a CEO gets to say he didn’t read what he was signing.", "normalized_text": "going to be hard to keep claiming you didn’t know something if your signature is on it i don’t really think a ceo gets to say he didn’t read what he was signing", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "dmitrygr", "node_time": "2024-05-22T23:16:26+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448287, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I wonder if this HN post will get torpedoed as fast as the one from yesterday[0]. 0.", "normalized_text": "i wonder if this hn post will get torpedoed as fast as the one from yesterday 0 0", "model_tags": [], "aspect_hints": ["performance_speed"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "istjohn", "node_time": "2024-05-22T23:37:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448305, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "PDF:", "normalized_text": "pdf", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "adt", "node_time": "2024-05-22T23:39:01+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448359, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I find it hard to believe that Sam didn’t know about something that draconian in something so sensitive as NDAs that affects to equity. He’s not exactly new to this whole startup thing and getting equity right is not a small part of that", "normalized_text": "i find it hard to believe that sam didn’t know about something that draconian in something so sensitive as ndas that affects to equity he’s not exactly new to this whole startup thing and getting equity right is not a small part of that", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "Havoc", "node_time": "2024-05-22T23:44:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448473, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Does someone know why the employees wanted him back so badly? Must be very few employees actually upset with him and his way of doing things.", "normalized_text": "does someone know why the employees wanted him back so badly must be very few employees actually upset with him and his way of doing things", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "thereal_tron", "node_time": "2024-05-22T23:54:59+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448629, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Everyone is out for Sam Altman, and there are reasons to scrutinize him. But on this issue - it is common for a company's Legal and HR teams to make decisions on language in docs like these (exit docs) entirely on their own. So it is plausible that Sam Altman had no idea that this aggressive language existed. One reason to think the same thing is true here, is I recall Sam spoke up for employee friendly equity plans when he was running YC.", "normalized_text": "everyone is out for sam altman and there are reasons to scrutinize him but on this issue it is common for a company s legal and hr teams to make decisions on language in docs like these exit docs entirely on their own so it is plausible that sam altman had no idea that this aggressive language existed one reason to think the same thing is true here is i recall sam spoke up for employee friendly equity plans when he was running yc", "model_tags": [], "aspect_hints": ["usability_ux", "community_tone"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "blackeyeblitzar", "node_time": "2024-05-23T00:09:44+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448839, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I'm not following this very closely, but agreements that block employees from selling (private) vested equity are a market term, not something uniquely aggressive OpenAI does. The Vox article calls this \"just as important\" as the clawback terms, but, obviously, no.", "normalized_text": "i m not following this very closely but agreements that block employees from selling private vested equity are a market term not something uniquely aggressive openai does the vox article calls this just as important as the clawback terms but obviously no", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy", "business_model"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "tptacek", "node_time": "2024-05-23T00:28:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450110, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Looking forward for a document leak about openai using YouTube data for training their models. When asked if they use it, Murali (CTO) told she doesn't know which makes you believe that for 99% they are using it.", "normalized_text": "looking forward for a document leak about openai using youtube data for training their models when asked if they use it murali cto told she doesn t know which makes you believe that for 99 they are using it", "model_tags": ["openai"], "aspect_hints": ["privacy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "zniturah", "node_time": "2024-05-23T03:21:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450321, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Do OpenAI employees actually get equity in the company (e.g. options or RSUs)? I was under the impression that the company awards \"profit units\" of some kind, and that many employees aren't sure how they work.", "normalized_text": "do openai employees actually get equity in the company e g options or rsus i was under the impression that the company awards profit units of some kind and that many employees aren t sure how they work", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "manlobster", "node_time": "2024-05-23T04:00:48+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40451004, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Great, if these documents are credible, this is exactly what I was implying[1] yesteday. Here, listen to Altman say how he is \"genuinely embarrassed\": \"this is on me and one of the few times i've been genuinely embarrassed running openai; i did not know this was happening and i should have.\" The first thing the above conjures up is the other disgraced Sam (Bankman-Fried) saying \"this is on me\" when FTX went bust. I bet euros-to-croissants I'm not the only one to notice this. Some amount of corporate ruthlessness is part of the game, whether we like it or not. But these SV robber-barrons really crank it up to something else. [1]", "normalized_text": "great if these documents are credible this is exactly what i was implying 1 yesteday here listen to altman say how he is genuinely embarrassed this is on me and one of the few times i ve been genuinely embarrassed running openai i did not know this was happening and i should have the first thing the above conjures up is the other disgraced sam bankman fried saying this is on me when ftx went bust i bet euros to croissants i m not the only one to notice this some amount of corporate ruthlessness is part of the game whether we like it or not but these sv robber barrons really crank it up to something else 1", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "kashyapc", "node_time": "2024-05-23T06:02:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40451049, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "> this is on me and one of the few times i've been genuinely embarrassed running openai This statement seems to suggest that feeling embarrassed by one's actions is a normal part of running a company. In reality, the expectation is that a CEO should strive to lead with integrity and foresight to avoid situations that lead to embarrassment.", "normalized_text": "this is on me and one of the few times i ve been genuinely embarrassed running openai this statement seems to suggest that feeling embarrassed by one s actions is a normal part of running a company in reality the expectation is that a ceo should strive to lead with integrity and foresight to avoid situations that lead to embarrassment", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "cambaceres", "node_time": "2024-05-23T06:12:09+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40451322, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "So what happened to Daniel Kokotajlo, the ex-OAI employee who made a comment saying that his equity was clawed back? Was it a miscommunication and he was referring to unvested equity, or is Sama just lying? In the original context, it sounded very much like he was referring to clawed-back equity. I’m trying to find the link.", "normalized_text": "so what happened to daniel kokotajlo the ex oai employee who made a comment saying that his equity was clawed back was it a miscommunication and he was referring to unvested equity or is sama just lying in the original context it sounded very much like he was referring to clawed back equity i’m trying to find the link", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "notshift", "node_time": "2024-05-23T06:50:40+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40451631, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "In my third world country, when they do something unethical they say \"everything is in accordance with the law\", here it's \"this is on me\", both are very cynical. From the time they went private, it was apparent that this company is unethical to say the least. Given what it is building, this can be very dangerous, but I think they are more proficient in creating hype, than actually coming up with something meaningful.", "normalized_text": "in my third world country when they do something unethical they say everything is in accordance with the law here it s this is on me both are very cynical from the time they went private it was apparent that this company is unethical to say the least given what it is building this can be very dangerous but i think they are more proficient in creating hype than actually coming up with something meaningful", "model_tags": [], "aspect_hints": ["usability_ux", "ethics", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "coahn", "node_time": "2024-05-23T07:32:12+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40451895, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "The amount [and scale] of practices, chaos and controversies caused by OpenAI since ChatGPT was released are \"on par\" with the powerful products it has built since.. in a negative way! These are the hottest controversial events so far , in a chronological order: OpenAI's deviation from its original mission ( The Altman's Saga ( The return of Altman (within a week) ( Musk vs. OpenAI ( The departure of high-profile employees (Karpathy: ,Sutskever: \"Why can’t former OpenAI employees talk?\" (", "normalized_text": "the amount and scale of practices chaos and controversies caused by openai since chatgpt was released are on par with the powerful products it has built since in a negative way these are the hottest controversial events so far in a chronological order openai s deviation from its original mission the altman s saga the return of altman within a week musk vs openai the departure of high profile employees karpathy sutskever why can’t former openai employees talk", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "redbell", "node_time": "2024-05-23T08:04:43+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40452539, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "> ..or agreeing not to criticize the company, with no end date Oh! free speech is on trade! We used to hear the above statement coming from some political regimes but this is the first time I read it in the tech world. Would we live to witness more variations of this behavior on a larger scale?! > High-pressure tactics at OpenAI > That meant the former employees had a week to decide whether to accept OpenAI’s muzzle or risk forfeiting what could be millions of dollars > When ex-employees asked for more time to seek legal aid and review the documents, they faced significant pushback from OpenAI. > “We want to make sure you understand that if you don't sign, it could impact your equity. That's true for everyone, and we're just doing things by the book,” Although they've been able to build the most capable AI models that could replace a lot of human jobs, they struggle to humanely manage the people behind these models!!", "normalized_text": "or agreeing not to criticize the company with no end date oh free speech is on trade we used to hear the above statement coming from some political regimes but this is the first time i read it in the tech world would we live to witness more variations of this behavior on a larger scale high pressure tactics at openai that meant the former employees had a week to decide whether to accept openai’s muzzle or risk forfeiting what could be millions of dollars when ex employees asked for more time to seek legal aid and review the documents they faced significant pushback from openai “we want to make sure you understand that if you don t sign it could impact your equity that s true for everyone and we re just doing things by the book ” although they ve been able to build the most capable ai models that could replace a lot of human jobs they struggle to humanely manage the people behind these models", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "redbell", "node_time": "2024-05-23T09:36:14+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40453444, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I'm surprised that an executive or lawyer didn't realise the reputational damage adding these clauses would eventually cause the leadership team. Were they really stupid enough to think that the amount of money being offered would bend some of the most principled people in the world? Whoever allowed those clauses to be added and let them remain has done more damage to the public face of OpenAI than any aggravated ex-employee ever could.", "normalized_text": "i m surprised that an executive or lawyer didn t realise the reputational damage adding these clauses would eventually cause the leadership team were they really stupid enough to think that the amount of money being offered would bend some of the most principled people in the world whoever allowed those clauses to be added and let them remain has done more damage to the public face of openai than any aggravated ex employee ever could", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "lhnz", "node_time": "2024-05-23T11:39:57+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40454371, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "It's funny how finding out about corporate misdoing has almost a common ritual attached to it. First shock and dismay is expressed to the findings, then the company leadership has to say it was a mistake (rather than an obvious strategy they literally signed off on), we then bring up the contradiction. Does this display of ignorance from every side really need to take place? Why bother asking for an explanation, they obviously did the thing they obviously did and will obviously do as much as possible to keep doing as much of things like that they can get away with.", "normalized_text": "it s funny how finding out about corporate misdoing has almost a common ritual attached to it first shock and dismay is expressed to the findings then the company leadership has to say it was a mistake rather than an obvious strategy they literally signed off on we then bring up the contradiction does this display of ignorance from every side really need to take place why bother asking for an explanation they obviously did the thing they obviously did and will obviously do as much as possible to keep doing as much of things like that they can get away with", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "boh", "node_time": "2024-05-23T13:22:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40461065, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Does anyone remember the name of that coder who made a kickstarter for his game but he was unable to finish it because it was a bit too big ( but still epic ) and then due to his talent he got hired at OpenAI? I always wanted to follow him on Twitter but I forgot his name :\\ if anyone knows that be great Edit - sry why is this the top comment", "normalized_text": "does anyone remember the name of that coder who made a kickstarter for his game but he was unable to finish it because it was a bit too big but still epic and then due to his talent he got hired at openai i always wanted to follow him on twitter but i forgot his name if anyone knows that be great edit sry why is this the top comment", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "ionwake", "node_time": "2024-05-23T23:19:26+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047035, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Sure but under what license? Because slapping “open source” on the model doesn’t make it open source if it’s not actually license that way. The 3.1 license still contains their non-commercial clause (over 700m users) and requires derivatives, whether fine tunings or trained on generated data, to use the llama name.", "normalized_text": "sure but under what license because slapping “open source” on the model doesn’t make it open source if it’s not actually license that way the 3 1 license still contains their non commercial clause over 700m users and requires derivatives whether fine tunings or trained on generated data to use the llama name", "model_tags": ["meta"], "aspect_hints": ["privacy", "usability_ux", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "amusingimpala75", "node_time": "2024-07-23T15:30:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047097, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "> This is how we’ve managed security on our social networks – our more robust AI systems identify and stop threats from less sophisticated actors who often use smaller scale AI systems. Ok, first of all, has this really worked? AI moderators still can't capture the mass of obvious spam/bots on all their platforms, threads included. Second, AI detection doesn't work, and with how much better the systems are getting, it's probably never going to, unless you keep the best models for yourself, and it's is clear from the rest of the note that its not zuck's intention to do so. > As long as everyone has access to similar generations of models – which open source promotes – then governments and institutions with more compute resources will be able to check bad actors with less compute. This just doesn't make sense. How are you going to prevent AI spam, AI deepfakes from causing harm with more compute? What are you gonna do with more compute about nonconsensual deepfakes? People are already using AI to bypass identity verification on your social media networks, and pump out loads of spam.", "normalized_text": "this is how we’ve managed security on our social networks – our more robust ai systems identify and stop threats from less sophisticated actors who often use smaller scale ai systems ok first of all has this really worked ai moderators still can t capture the mass of obvious spam bots on all their platforms threads included second ai detection doesn t work and with how much better the systems are getting it s probably never going to unless you keep the best models for yourself and it s is clear from the rest of the note that its not zuck s intention to do so as long as everyone has access to similar generations of models – which open source promotes – then governments and institutions with more compute resources will be able to check bad actors with less compute this just doesn t make sense how are you going to prevent ai spam ai deepfakes from causing harm with more compute what are you gonna do with more compute about nonconsensual deepfakes people are already using ai to bypass identity verification on your social media networks and pump out loads of spam", "model_tags": [], "aspect_hints": ["security", "ethics", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "kart23", "node_time": "2024-07-23T15:34:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047116, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "“The Heavy Press Program was a Cold War-era program of the United States Air Force to build the largest forging presses and extrusion presses in the world.” This ”program began in 1944 and concluded in 1957 after construction of four forging presses and six extruders, at an overall cost of $279 million. Six of them are still in operation today, manufacturing structural parts for military and commercial aircraft” [1]. $279mm in 1957 dollars is about $3.2bn today [2]. A public cluster of GPUs provided for free to American universities, companies and non-profits might not be a bad idea. [1] [2]", "normalized_text": "“the heavy press program was a cold war era program of the united states air force to build the largest forging presses and extrusion presses in the world ” this ”program began in 1944 and concluded in 1957 after construction of four forging presses and six extruders at an overall cost of 279 million six of them are still in operation today manufacturing structural parts for military and commercial aircraft” 1 279mm in 1957 dollars is about 3 2bn today 2 a public cluster of gpus provided for free to american universities companies and non profits might not be a bad idea 1 2", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "JumpCrisscross", "node_time": "2024-07-23T15:35:23+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047141, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "\"Eventually though, open source Linux gained popularity – initially because it allowed developers to modify its code however they wanted ...\" I find the language around \"open source AI\" to be confusing. With \"open source\" there's usually \"source\" to open, right? As in, there is human legible code that can be read and modified by the user? If so, then how can current ML models be open source? They're very large matrices that are, for the most part, inscrutable to the user. They seem akin to binaries, which, yes, can be modified by the user, but are extremely obscured to the user, and require enormous effort to understand and effectively modify. \"Open source\" code is not just code that isn't executed remotely over an API, and it seems like maybe its being conflated with that here?", "normalized_text": "eventually though open source linux gained popularity – initially because it allowed developers to modify its code however they wanted i find the language around open source ai to be confusing with open source there s usually source to open right as in there is human legible code that can be read and modified by the user if so then how can current ml models be open source they re very large matrices that are for the most part inscrutable to the user they seem akin to binaries which yes can be modified by the user but are extremely obscured to the user and require enormous effort to understand and effectively modify open source code is not just code that isn t executed remotely over an api and it seems like maybe its being conflated with that here", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "the8thbit", "node_time": "2024-07-23T15:37:01+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047360, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Huge companies like facebook will often argue for solutions that on the surface, seem to be in the public interest. But I have strong doubts they (or any other company) actually believe what they are saying. Here is the reality: - Facebook is spending untold billions on GPU hardware. - Facebook is arguing in favor of open sourcing the models, that they spent billions of dollars to generate, for free...? It follows that companies with much smaller resources (money) will not be able to match what Facebook is doing. Seems like an attempt to kill off the competition (specifically, smaller organizations) before they can take root.", "normalized_text": "huge companies like facebook will often argue for solutions that on the surface seem to be in the public interest but i have strong doubts they or any other company actually believe what they are saying here is the reality facebook is spending untold billions on gpu hardware facebook is arguing in favor of open sourcing the models that they spent billions of dollars to generate for free it follows that companies with much smaller resources money will not be able to match what facebook is doing seems like an attempt to kill off the competition specifically smaller organizations before they can take root", "model_tags": ["meta"], "aspect_hints": ["usability_ux", "regulation_policy", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "rybosworld", "node_time": "2024-07-23T15:52:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047467, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "> We’re releasing Llama 3.1 405B, the first frontier-level open source AI model, as well as new and improved Llama 3.1 70B and 8B models. Bravo! While I don't agree with Zuck's views and actions on many fronts, on this occasion I think he and the AI folks at Meta deserve our praise and gratitude. With this release, they have brought the cost of pretraining a frontier 400B+ parameter model to ZERO for pretty much everyone -- well, everyone except Meta's key competitors.[a] THANK YOU ZUCK. Meanwhile, the business-minded people at Meta surely won't mind if the release of these frontier models to the public happens to completely mess up the AI plans of competitors like OpenAI/Microsoft, Google, Anthropic, etc. Come to think of it, the negative impact on such competitors was likely a key motivation for releasing the new models. --- [a] The license is not open to the handful of companies worldwide which have more than 700M users.", "normalized_text": "we’re releasing llama 3 1 405b the first frontier level open source ai model as well as new and improved llama 3 1 70b and 8b models bravo while i don t agree with zuck s views and actions on many fronts on this occasion i think he and the ai folks at meta deserve our praise and gratitude with this release they have brought the cost of pretraining a frontier 400b parameter model to zero for pretty much everyone well everyone except meta s key competitors a thank you zuck meanwhile the business minded people at meta surely won t mind if the release of these frontier models to the public happens to completely mess up the ai plans of competitors like openai microsoft google anthropic etc come to think of it the negative impact on such competitors was likely a key motivation for releasing the new models a the license is not open to the handful of companies worldwide which have more than 700m users", "model_tags": ["openai", "anthropic", "google", "meta"], "aspect_hints": ["cost_price", "regulation_policy", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "cs702", "node_time": "2024-07-23T15:59:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047638, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "The big winners of this: devs and AI startups - No more vendor lock-in - Instead of just wrapping proprietary API endpoints, developers can now integrate AI deeply into their products in a very cost-effective and performant way - Price race to the bottom with near-instant LLM responses at very low prices are on the horizon As a founder, it feels like a very exciting time to build a startup as your product automatically becomes better, cheaper, and more scalable with every major AI advancement. This leads to a powerful flywheel effect:", "normalized_text": "the big winners of this devs and ai startups no more vendor lock in instead of just wrapping proprietary api endpoints developers can now integrate ai deeply into their products in a very cost effective and performant way price race to the bottom with near instant llm responses at very low prices are on the horizon as a founder it feels like a very exciting time to build a startup as your product automatically becomes better cheaper and more scalable with every major ai advancement this leads to a powerful flywheel effect", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "hubraumhugo", "node_time": "2024-07-23T16:11:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047695, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Meta makes their money off advertising, which means they profit from attention. This means they need content that will grab attention, and creating open source models that allow anyone to create any content on their own becomes good for Meta. The users of the models can post it to their Instagram/FB/Threads account. Releasing an open model also releases Meta from the burden of having to police the content the model generates, once the open source community fine-tunes the models. Overall, this move is good business move for Meta - the post doesn't really talk about the true benefit, instead moralizing about open source, but this is a sound business move for Meta.", "normalized_text": "meta makes their money off advertising which means they profit from attention this means they need content that will grab attention and creating open source models that allow anyone to create any content on their own becomes good for meta the users of the models can post it to their instagram fb threads account releasing an open model also releases meta from the burden of having to police the content the model generates once the open source community fine tunes the models overall this move is good business move for meta the post doesn t really talk about the true benefit instead moralizing about open source but this is a sound business move for meta", "model_tags": [], "aspect_hints": ["community_tone", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "bun_at_work", "node_time": "2024-07-23T16:15:39+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047722, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "This is really good news. Zuck sees the inevitability of it and the dystopian regulatory landscape and decided to go all in. This also has the important effect of neutralizing the critique of US Government AI regulation because it will democratize \"frontier\" models and make enforcement nearly impossible. Thank you, Zuck, this is an important and historic move. It also opens up the market to a lot more entry in the area of \"ancillary services to support the effective use of frontier models\" (including safety-oriented concerns), which should really be the larger market segment.", "normalized_text": "this is really good news zuck sees the inevitability of it and the dystopian regulatory landscape and decided to go all in this also has the important effect of neutralizing the critique of us government ai regulation because it will democratize frontier models and make enforcement nearly impossible thank you zuck this is an important and historic move it also opens up the market to a lot more entry in the area of ancillary services to support the effective use of frontier models including safety oriented concerns which should really be the larger market segment", "model_tags": [], "aspect_hints": ["cost_price", "regulation_policy", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "resters", "node_time": "2024-07-23T16:17:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41048452, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "> Third, a key difference between Meta and closed model providers is that selling access to AI models isn’t our business model. That means openly releasing Llama doesn’t undercut our revenue, sustainability, or ability to invest in research like it does for closed providers. (This is one reason several closed providers consistently lobby governments against open source.) The whole thing is interesting, but this part strikes me as potentially anticompetitive reasoning. I wonder what the lines are that they have to avoid crossing here?", "normalized_text": "third a key difference between meta and closed model providers is that selling access to ai models isn’t our business model that means openly releasing llama doesn’t undercut our revenue sustainability or ability to invest in research like it does for closed providers this is one reason several closed providers consistently lobby governments against open source the whole thing is interesting but this part strikes me as potentially anticompetitive reasoning i wonder what the lines are that they have to avoid crossing here", "model_tags": ["meta"], "aspect_hints": ["business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "6gvONxR4sf7o", "node_time": "2024-07-23T17:11:46+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
