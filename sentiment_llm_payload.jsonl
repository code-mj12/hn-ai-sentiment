{"id": 40345765, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Wow this versioning scheme really messed up this prediction market:", "normalized_text": "wow this versioning scheme really messed up this prediction market", "model_tags": [], "aspect_hints": ["business_model"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "Powdering7082", "node_time": "2024-05-13T17:27:32+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345794, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I've noticed that the GPT-4 model's capabilities seem limited compared to its initial release. Others have also pointed this out. I suspect that making the model free might have required reducing its capabilities to meet cost efficiency goals. I'll have to try it out to see for myself.", "normalized_text": "i ve noticed that the gpt 4 model s capabilities seem limited compared to its initial release others have also pointed this out i suspect that making the model free might have required reducing its capabilities to meet cost efficiency goals i ll have to try it out to see for myself", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "cost_price"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "ppollaki", "node_time": "2024-05-13T17:29:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345800, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Tiktoken added support for GPT-4o: It has an increased vocab size of 200k.", "normalized_text": "tiktoken added support for gpt 4o it has an increased vocab size of 200k", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "atgctg", "node_time": "2024-05-13T17:30:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345812, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "The most impressive part is that the voice uses the right feelings and tonal language during the presentation. I'm not sure how much of that was that they had tested this over and over, but it is really hard to get that right so if they didn't fake it in some way I'd say that is revolutionary.", "normalized_text": "the most impressive part is that the voice uses the right feelings and tonal language during the presentation i m not sure how much of that was that they had tested this over and over but it is really hard to get that right so if they didn t fake it in some way i d say that is revolutionary", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "Jensson", "node_time": "2024-05-13T17:31:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345813, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "As far as I'm concerned this is the new best demo of all time. This is going to change the world in short order. I doubt they will be ready with enough GPUs for the demand the voice+vision mode is going to get, if it's really released to all free users. Now imagine this in a $16k humanoid robot, also announced this morning: The future is going to be wild.", "normalized_text": "as far as i m concerned this is the new best demo of all time this is going to change the world in short order i doubt they will be ready with enough gpus for the demand the voice vision mode is going to get if it s really released to all free users now imagine this in a 16k humanoid robot also announced this morning the future is going to be wild", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "modeless", "node_time": "2024-05-13T17:31:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345816, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Parts of the demo were quite choppy (latency?) so this definitely feels rushed in response to Google I/O. Other than that, looks good. Desktop app is great, but I didn’t see no mention of being able to use your own API key so OS projects might still be needed. The biggest thing is bringing GPT-4 to free users, that is an interesting move. Depending on what the limits are, I might cancel my subscription.", "normalized_text": "parts of the demo were quite choppy latency so this definitely feels rushed in response to google i o other than that looks good desktop app is great but i didn’t see no mention of being able to use your own api key so os projects might still be needed the biggest thing is bringing gpt 4 to free users that is an interesting move depending on what the limits are i might cancel my subscription", "model_tags": ["openai", "google"], "aspect_hints": ["performance_speed", "usability_ux", "cost_price"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "skilled", "node_time": "2024-05-13T17:31:37+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345836, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I admit I drink the koolaid and love LLMs and their applications. But damn, the way it’s responds in the demo gave me goosebumps in a bad way. Like an uncanny valley instincts kicks in.", "normalized_text": "i admit i drink the koolaid and love llms and their applications but damn the way it’s responds in the demo gave me goosebumps in a bad way like an uncanny valley instincts kicks in", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "syntaxing", "node_time": "2024-05-13T17:33:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345909, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "They are admitting[1] that the new model is the gpt2-chatbot that we have seen before[2]. As many highlighted there, the model is not an improvement like GPT3->GPT4. I tested a bunch of programming stuff and it was not that much better. It's interesting that OpenAI is highlighting the Elo score instead of showing results for many many benchmarks that all models are stuck at 50-70% success. [1] [2]", "normalized_text": "they are admitting 1 that the new model is the gpt2 chatbot that we have seen before 2 as many highlighted there the model is not an improvement like gpt3 gpt4 i tested a bunch of programming stuff and it was not that much better it s interesting that openai is highlighting the elo score instead of showing results for many many benchmarks that all models are stuck at 50 70 success 1 2", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "msoad", "node_time": "2024-05-13T17:37:59+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345910, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Big questions are (1) when is this going to be rolled out to paid users? (2) what is the remaining benefit of being a paid user if this is rolled out to free users? (3) Biggest concern is will this degrade the paid experience since GPT-4 interactions are already rate limited. Does OpenAI have the hardware to handle this? Edit: according to @gdb this is coming in \"weeks\"", "normalized_text": "big questions are 1 when is this going to be rolled out to paid users 2 what is the remaining benefit of being a paid user if this is rolled out to free users 3 biggest concern is will this degrade the paid experience since gpt 4 interactions are already rate limited does openai have the hardware to handle this edit according to gdb this is coming in weeks", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "Jimmc414", "node_time": "2024-05-13T17:38:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345932, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Gone are the days of copy-pasting to/from ChatGPT all the time, now you just share your screen. That's a fantastic feature, in how much friction that removes. But what an absolute privacy nightmare. With ChatGPT having a very simple text+attachment in, text out interface, I felt absolutely in control of what I tell it. Now when it's grabbing my screen or a live camera feed, that will be gone. And I'll still use it, because it's just so damn convenient?", "normalized_text": "gone are the days of copy pasting to from chatgpt all the time now you just share your screen that s a fantastic feature in how much friction that removes but what an absolute privacy nightmare with chatgpt having a very simple text attachment in text out interface i felt absolutely in control of what i tell it now when it s grabbing my screen or a live camera feed that will be gone and i ll still use it because it s just so damn convenient", "model_tags": ["openai"], "aspect_hints": ["privacy", "usability_ux"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "w-m", "node_time": "2024-05-13T17:39:26+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345937, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Very, very impressive for a \"minor\" release demo. The capabilities here would look shockingly advanced just 5 years ago. Universal translator, pair programmer, completely human sounding voice assistant and all in real time. Scifi tropes made real. But: Interesting next to see how it actually performs IRL latency and without cherry-picking. No snark, it was great but need to see real world power. Also what the benefits are to subscribers if all this is going to be free...", "normalized_text": "very very impressive for a minor release demo the capabilities here would look shockingly advanced just 5 years ago universal translator pair programmer completely human sounding voice assistant and all in real time scifi tropes made real but interesting next to see how it actually performs irl latency and without cherry picking no snark it was great but need to see real world power also what the benefits are to subscribers if all this is going to be free", "model_tags": [], "aspect_hints": ["performance_speed", "regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "mellosouls", "node_time": "2024-05-13T17:39:36+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40345988, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "This is really impressive engineering. I thought real time agents would completely change the way we're going to interact with large models but it would take 1~2 more years. I wonder what kind of new techs are developed to enable this, but OpenAI is fairly secretive so we won't be able to know their sauce. On the other hand, this also feels like a signal that reasoning capability has probably already been plateaued at GPT-4 level and OpenAI knew it so they decided to focus on research that matters to delivering product engineering rather than long-term research to unlock further general (super)intelligence.", "normalized_text": "this is really impressive engineering i thought real time agents would completely change the way we re going to interact with large models but it would take 1 2 more years i wonder what kind of new techs are developed to enable this but openai is fairly secretive so we won t be able to know their sauce on the other hand this also feels like a signal that reasoning capability has probably already been plateaued at gpt 4 level and openai knew it so they decided to focus on research that matters to delivering product engineering rather than long term research to unlock further general super intelligence", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "summerlight", "node_time": "2024-05-13T17:43:46+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346002, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "It is notable OpenAI did not need to carefully rehearse the talking points of the speakers. Or even do the kind of careful production quality seen in a lot of other videos. The technology product is so good and so advanced it doesn't matter how the people appear. Zuck tried this in his video countering to vision pro, but it did not have the authentic \"not really rehearsed or produced\" feel of this at all. If you watch that video and compare it with this you can see the difference. Very interesting times.", "normalized_text": "it is notable openai did not need to carefully rehearse the talking points of the speakers or even do the kind of careful production quality seen in a lot of other videos the technology product is so good and so advanced it doesn t matter how the people appear zuck tried this in his video countering to vision pro but it did not have the authentic not really rehearsed or produced feel of this at all if you watch that video and compare it with this you can see the difference very interesting times", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "bredren", "node_time": "2024-05-13T17:44:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346005, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Very impressive demo, but not really a step change in my opinion. The hype from OpenAI employees was on another level, way more than was warranted in my opinion. Ultimately, the promise of LLM proponents is that these models will get exponentially smarter - this hasn’t born out yet. So from that perspective, this was a disappointing release. If anything, this feels like a rushed release to match what Google will be demoing tomorrow.", "normalized_text": "very impressive demo but not really a step change in my opinion the hype from openai employees was on another level way more than was warranted in my opinion ultimately the promise of llm proponents is that these models will get exponentially smarter this hasn’t born out yet so from that perspective this was a disappointing release if anything this feels like a rushed release to match what google will be demoing tomorrow", "model_tags": ["openai", "google"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "skepticATX", "node_time": "2024-05-13T17:44:48+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346031, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "@sama reflects:", "normalized_text": "sama reflects", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "mellosouls", "node_time": "2024-05-13T17:46:42+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346044, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Looking forward to trying this via ChatGPT. As always OpenAI says \"now available\" but refreshing or logging in/out of ChatGPT (web and mobile) don't cause GPT-4o to show up. I don't know why I find this so frustrating. Probably because they don't say \"rolling out\" they say things like \"try it now\" but I can't even though I'm a paying customer. Oh well...", "normalized_text": "looking forward to trying this via chatgpt as always openai says now available but refreshing or logging in out of chatgpt web and mobile don t cause gpt 4o to show up i don t know why i find this so frustrating probably because they don t say rolling out they say things like try it now but i can t even though i m a paying customer oh well", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "joshstrange", "node_time": "2024-05-13T17:47:37+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346082, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "OAI just made an embarrassment of Google's fake demo earlier this year. Given how this was recorded, I am pretty certain it's authentic.", "normalized_text": "oai just made an embarrassment of google s fake demo earlier this year given how this was recorded i am pretty certain it s authentic", "model_tags": ["google"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "bearjaws", "node_time": "2024-05-13T17:50:09+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346200, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I found these videos quite hard to watch. There is a level of cringe that I found a bit unpleasant. It’s like some kind of uncanny valley of human interaction that I don’t get on nearly the same level with the text version.", "normalized_text": "i found these videos quite hard to watch there is a level of cringe that i found a bit unpleasant it’s like some kind of uncanny valley of human interaction that i don’t get on nearly the same level with the text version", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "Negitivefrags", "node_time": "2024-05-13T17:57:12+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346245, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I can't help but feel a bit let down. The demos felt pretty cherry picked and still had issues with the voice getting cut off frequently (especially in the first demo). I've already played with the vision API, so that doesn't seem all that new. But I agree it is impressive. That said, watching back a Windows Vista speech recognition demo[1] I'm starting to wonder if this stuff won't have the same fate in a few years. 1 -", "normalized_text": "i can t help but feel a bit let down the demos felt pretty cherry picked and still had issues with the voice getting cut off frequently especially in the first demo i ve already played with the vision api so that doesn t seem all that new but i agree it is impressive that said watching back a windows vista speech recognition demo 1 i m starting to wonder if this stuff won t have the same fate in a few years 1", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "dom96", "node_time": "2024-05-13T18:00:00+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346293, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "In the video where the 2 AI's sing together, it starts to get really cringey and weird to the point where it literally sounds like it's being faked by 2 voice actors off-screen with literal guns to their heads trying not to cry, did anyone else get that impression? The tonal talking was impressive, but man that part was like, is someone being tortured or forced against their will?", "normalized_text": "in the video where the 2 ai s sing together it starts to get really cringey and weird to the point where it literally sounds like it s being faked by 2 voice actors off screen with literal guns to their heads trying not to cry did anyone else get that impression the tonal talking was impressive but man that part was like is someone being tortured or forced against their will", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "CosmicShadow", "node_time": "2024-05-13T18:04:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346349, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "GPT-4o being a truly multimodal model is exciting, does open the door to more interesting products. I was curious about the new tokenizer which uses much fewer tokens for non-English, but also 1.1x fewer tokens for English, so I'm wondering if this means each token now can be more possible values than before? Might make sense provided that they now also have audio and image output tokens? I wonder what \"fewer tokens\" really means then, without context on raising the size of each token? It's a bit like saying my JPEG image is now using 2x fewer words after I switched from a 32-bit to a 64-bit architecture no?", "normalized_text": "gpt 4o being a truly multimodal model is exciting does open the door to more interesting products i was curious about the new tokenizer which uses much fewer tokens for non english but also 1 1x fewer tokens for english so i m wondering if this means each token now can be more possible values than before might make sense provided that they now also have audio and image output tokens i wonder what fewer tokens really means then without context on raising the size of each token it s a bit like saying my jpeg image is now using 2x fewer words after i switched from a 32 bit to a 64 bit architecture no", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "blixt", "node_time": "2024-05-13T18:07:35+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346614, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "In my experience so far, GPT-4o seems to sit somewhere between the capability of GPT-3.5 and GPT-4. I'm working on an app that relies more on GPT-4's reasoning abilities than inference speed. For my use case, GPT-4o seems to do worse than GPT-4 Turbo on reasoning tasks. For me this seems like a step-up from GPT-3.5 but not from GPT-4 Turbo. At half the cost and significantly faster inference speed, I'm sure this is a good tradeoff for other use cases though.", "normalized_text": "in my experience so far gpt 4o seems to sit somewhere between the capability of gpt 3 5 and gpt 4 i m working on an app that relies more on gpt 4 s reasoning abilities than inference speed for my use case gpt 4o seems to do worse than gpt 4 turbo on reasoning tasks for me this seems like a step up from gpt 3 5 but not from gpt 4 turbo at half the cost and significantly faster inference speed i m sure this is a good tradeoff for other use cases though", "model_tags": ["openai"], "aspect_hints": ["performance_speed", "usability_ux", "cost_price"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "ravroid", "node_time": "2024-05-13T18:31:04+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346864, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I am observing an extremely high rate of text hallucinations with gpt-4o (gpt-4o-2024-05-13) as tested via the API. I advise extreme caution with it. In contrast, I see no such concern with gpt-4-turbo-preview (gpt-4-0125-preview).", "normalized_text": "i am observing an extremely high rate of text hallucinations with gpt 4o gpt 4o 2024 05 13 as tested via the api i advise extreme caution with it in contrast i see no such concern with gpt 4 turbo preview gpt 4 0125 preview", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "OutOfHere", "node_time": "2024-05-13T18:54:21+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40346978, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Very interesting and extremely impressive! I tried using the voice chat in their app previously and was disappointed. The big UX problem was that it didn't try to understand when I had finished speaking. English is a second language and I paused a bit too long thinking of a word and it just started responding to my obviously half spoken sentence. Trying again it just became stressful as I had to rush my words out to avoid an annoying response to an unfinished thought. I didn't try interrupting it but judging by the comments here it was not possible. It was very surprising to me to be so overtly exposed to the nuances of real conversation. Just this one thing of not understanding when it's your turn to talk made the interaction very unpleasant, more than I would have expected. On that note, I noticed that the AI in the demo seems to be very rambly. It almost always just kept talking and many statements were reiterations of previous ones. It reminded me of a type of youtuber that uses a lot of filler phrases like \"let's go ahead and ...\", just to be more verbose and lessen silences. Most of the statements by the guy doing the demo were interrupting the AI. It's still extremely impressive but I found this interesting enough to share. It will be exciting to see how hard it is to reproduce these abilities in the open, and to solve this issue.", "normalized_text": "very interesting and extremely impressive i tried using the voice chat in their app previously and was disappointed the big ux problem was that it didn t try to understand when i had finished speaking english is a second language and i paused a bit too long thinking of a word and it just started responding to my obviously half spoken sentence trying again it just became stressful as i had to rush my words out to avoid an annoying response to an unfinished thought i didn t try interrupting it but judging by the comments here it was not possible it was very surprising to me to be so overtly exposed to the nuances of real conversation just this one thing of not understanding when it s your turn to talk made the interaction very unpleasant more than i would have expected on that note i noticed that the ai in the demo seems to be very rambly it almost always just kept talking and many statements were reiterations of previous ones it reminded me of a type of youtuber that uses a lot of filler phrases like let s go ahead and just to be more verbose and lessen silences most of the statements by the guy doing the demo were interrupting the ai it s still extremely impressive but i found this interesting enough to share it will be exciting to see how hard it is to reproduce these abilities in the open and to solve this issue", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "Hugsun", "node_time": "2024-05-13T19:02:47+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40347068, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I cannot believe that that overly excited giggle tone of voice you see in the demo videos made it through quality control?! I've only watched two videos so far and it's already annoying me to the point that I couldn't imagine using it regularly.", "normalized_text": "i cannot believe that that overly excited giggle tone of voice you see in the demo videos made it through quality control i ve only watched two videos so far and it s already annoying me to the point that i couldn t imagine using it regularly", "model_tags": [], "aspect_hints": ["community_tone"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "kleiba", "node_time": "2024-05-13T19:09:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40347104, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Few people are talking about it but... what do you think about the very over-the-top enthusiasm? To me, it sounds like TikTok TTS, it's a bit uncomfortable to listen to. I've been working with TTS models and they can produce much more natural sounding language, so it is clearly a stylistic choice. So what do you think?", "normalized_text": "few people are talking about it but what do you think about the very over the top enthusiasm to me it sounds like tiktok tts it s a bit uncomfortable to listen to i ve been working with tts models and they can produce much more natural sounding language so it is clearly a stylistic choice so what do you think", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "caseyy", "node_time": "2024-05-13T19:12:46+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40347131, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I’m a huge user of GPT4 and Opus in my work but I’m a huge user of GPT4-Turbo voice in my personal life. I use it on my commutes to learn all sorts of stuff. I’ve never understood the details of cameras and the relationship between shutter speed and aperture and iso in a modern dslr which given the aurora was important. We talked through and I got to an understanding in a way having read manuals and textbooks didn’t really help before. I’m a much better learner by being able to talk and hear and ask questions and get responses. Extend this to quantum foam, to ergodic processes, to entropic force, to Darius and Xerces, to poets of the 19th century - it’s changed my life. Really glad to see an investment in stream lining this flow.", "normalized_text": "i’m a huge user of gpt4 and opus in my work but i’m a huge user of gpt4 turbo voice in my personal life i use it on my commutes to learn all sorts of stuff i’ve never understood the details of cameras and the relationship between shutter speed and aperture and iso in a modern dslr which given the aurora was important we talked through and i got to an understanding in a way having read manuals and textbooks didn’t really help before i’m a much better learner by being able to talk and hear and ask questions and get responses extend this to quantum foam to ergodic processes to entropic force to darius and xerces to poets of the 19th century it’s changed my life really glad to see an investment in stream lining this flow", "model_tags": ["openai"], "aspect_hints": ["performance_speed"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "fnordpiglet", "node_time": "2024-05-13T19:15:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40347560, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "What struck me was the interruptions to the AI speaking which seemed commonplace by the team members in the demo. We will quickly get used to doing this to AIs and we will probably be talking to AIs a lot throughout the day as time progresses I would imagine. We will be trained by AIs to be rude and impatient I think.", "normalized_text": "what struck me was the interruptions to the ai speaking which seemed commonplace by the team members in the demo we will quickly get used to doing this to ais and we will probably be talking to ais a lot throughout the day as time progresses i would imagine we will be trained by ais to be rude and impatient i think", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "sebringj", "node_time": "2024-05-13T19:52:40+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40347661, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "This is remarkably good. I think that in about 2 months, when the voice responses are tuned a little better, it will be absolutely insane. I just used up my entire quota chatting with an AI, and having a really nice conversation. It's a decent conversationalist, extremely knowledgeable, tells good jokes, and is generally very personable. I also tested some rubber duck techniques, and it gave me very useful advice while coding. I'm very impressed. With a lot of spit and polish, this will be the new standard for any voice assistant ever. Imagine these capabilities integrated with your phone's built-in functions.", "normalized_text": "this is remarkably good i think that in about 2 months when the voice responses are tuned a little better it will be absolutely insane i just used up my entire quota chatting with an ai and having a really nice conversation it s a decent conversationalist extremely knowledgeable tells good jokes and is generally very personable i also tested some rubber duck techniques and it gave me very useful advice while coding i m very impressed with a lot of spit and polish this will be the new standard for any voice assistant ever imagine these capabilities integrated with your phone s built in functions", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "rpmisms", "node_time": "2024-05-13T20:00:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40347699, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Impressed by the model so far. As far as independent testing goes, it is topping our leaderboard for chess puzzle solving by a wide margin now:", "normalized_text": "impressed by the model so far as far as independent testing goes it is topping our leaderboard for chess puzzle solving by a wide margin now", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "freediver", "node_time": "2024-05-13T20:02:54+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40347937, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I think it’s safe to say Siri and Alexa are officially dead. They look like dusty storefront mannequins next to Battlestar replicants at this point.", "normalized_text": "i think it’s safe to say siri and alexa are officially dead they look like dusty storefront mannequins next to battlestar replicants at this point", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "erickhill", "node_time": "2024-05-13T20:21:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40348399, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I added gpt-4o support to my LLM CLI tool: pipx install llm llm keys set openai # Paste API key here llm -m 4o \"Fascinate me\" Or if you already have LLM installed: llm install --upgrade llm You can install an older version from Homebrew and then upgrade it like that too: brew install llm llm install --upgrade llm Release notes for the new version here:", "normalized_text": "i added gpt 4o support to my llm cli tool pipx install llm llm keys set openai paste api key here llm m 4o fascinate me or if you already have llm installed llm install upgrade llm you can install an older version from homebrew and then upgrade it like that too brew install llm llm install upgrade llm release notes for the new version here", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "simonw", "node_time": "2024-05-13T21:04:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40348436, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "feature request: please let me change the voice. it is slightly annoying right now. way too bubbly, and half the spoken information is redundant or not useful. too much small talk and pleasantries or repetition. I'm looking for an efficient, clever, servant not a \"friend\" who speaks to me like I'm a toddler. felt like I was talking to a stereotypical American with a Frappuccino: \"HIIIII!!! EVERYTHING'S AMAZING! YOU'RE BEAUTIFUL! NO YOU ARE!\" maybe some knobs for the flavor of the bot: - small talk: gossip girl stoic Aurelius - information efficiency or how much do you expect me to already know, an assumption on the user: midwit genius - tone spectrum: excited Scarlett, or whatever it is now Feynman the butler", "normalized_text": "feature request please let me change the voice it is slightly annoying right now way too bubbly and half the spoken information is redundant or not useful too much small talk and pleasantries or repetition i m looking for an efficient clever servant not a friend who speaks to me like i m a toddler felt like i was talking to a stereotypical american with a frappuccino hiiiii everything s amazing you re beautiful no you are maybe some knobs for the flavor of the bot small talk gossip girl stoic aurelius information efficiency or how much do you expect me to already know an assumption on the user midwit genius tone spectrum excited scarlett or whatever it is now feynman the butler", "model_tags": [], "aspect_hints": ["community_tone"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "yeknoda", "node_time": "2024-05-13T21:07:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40348489, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Apple and Google, you need to get your personal agent game going because right now you’re losing the market. This is FREE. Tweakable emotion and voice, watching the scene, cracking jokes. It’s not perfect but the amount and types of data this will collect will be massive. I can see it opening up access to many more users and use cases. Very close to: - A constant friend - A shrink - A teacher - A coach who can watch you exercise and offer feedback …all infinitely patient, positive, helpful. For kids that get bullied, or whose parents can’t afford therapy or a coach, there’s the potential for a base level of support that will only get better over time.", "normalized_text": "apple and google you need to get your personal agent game going because right now you’re losing the market this is free tweakable emotion and voice watching the scene cracking jokes it’s not perfect but the amount and types of data this will collect will be massive i can see it opening up access to many more users and use cases very close to a constant friend a shrink a teacher a coach who can watch you exercise and offer feedback …all infinitely patient positive helpful for kids that get bullied or whose parents can’t afford therapy or a coach there’s the potential for a base level of support that will only get better over time", "model_tags": ["google"], "aspect_hints": ["privacy", "business_model"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "richardw", "node_time": "2024-05-13T21:11:48+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40348664, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "We've had voice input and voice output with computers for a long time, but it's never felt like spoken conversation. At best it's a series of separate voice notes. It feels more like texting than talking. These demos show people talking to artificial intelligence. This is new. Humans are more partial to talking than writing. When people talk to each other (in person or over low-latency audio) there's a rich metadata channel of tone and timing, subtext, inexplicit knowledge. These videos seem to show the AI using this kind of metadata, in both input and output, and the conversation even flows reasonably well at times. I think this changes things a lot.", "normalized_text": "we ve had voice input and voice output with computers for a long time but it s never felt like spoken conversation at best it s a series of separate voice notes it feels more like texting than talking these demos show people talking to artificial intelligence this is new humans are more partial to talking than writing when people talk to each other in person or over low latency audio there s a rich metadata channel of tone and timing subtext inexplicit knowledge these videos seem to show the ai using this kind of metadata in both input and output and the conversation even flows reasonably well at times i think this changes things a lot", "model_tags": [], "aspect_hints": ["performance_speed", "privacy", "community_tone"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "cal85", "node_time": "2024-05-13T21:25:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40348813, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I worry that this tech will amplify the cultural values we have of \"good\" and \"bad\" emotions way more than the default restrictions that social media platforms put on the emoji reactions (e.g., can't be angry on LinkedIn). I worry that the AI will not express anger, not express sadness, not express frustration, not express uncertainty, and many other emotions that the culture of the fine-tuners might believe are \"bad\" emotions and that we may express a more and more narrow range of emotions going forward. Almost like it might become an AI \"yes man.\"", "normalized_text": "i worry that this tech will amplify the cultural values we have of good and bad emotions way more than the default restrictions that social media platforms put on the emoji reactions e g can t be angry on linkedin i worry that the ai will not express anger not express sadness not express frustration not express uncertainty and many other emotions that the culture of the fine tuners might believe are bad emotions and that we may express a more and more narrow range of emotions going forward almost like it might become an ai yes man", "model_tags": [], "aspect_hints": ["regulation_policy", "community_tone"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "jimkleiber", "node_time": "2024-05-13T21:38:53+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40348887, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "GPT-4o's breakthrough memory --", "normalized_text": "gpt 4o s breakthrough memory", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "sftombu", "node_time": "2024-05-13T21:46:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40349165, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Nobody in the comments seems to notice or care about GPT-4o new additional capability for performing searches based on RAG. As far as I am concerned this is the most important feature that people has been waiting for ChatGPT-4 especially if you are doing research. By just testing on one particular topic that I'm familiar with, using GPT-4 previously and GPT-4o the quality of the resulting responses for the latter is very promising indeed.", "normalized_text": "nobody in the comments seems to notice or care about gpt 4o new additional capability for performing searches based on rag as far as i am concerned this is the most important feature that people has been waiting for chatgpt 4 especially if you are doing research by just testing on one particular topic that i m familiar with using gpt 4 previously and gpt 4o the quality of the resulting responses for the latter is very promising indeed", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "teleforce", "node_time": "2024-05-13T22:14:56+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40350396, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Very impressive. Its programming skills are still kind of crappy and I seriously doubt its reasoning capacity. It feels like it can deep fake text prediction really well, but in essence there's still something wrong it it.", "normalized_text": "very impressive its programming skills are still kind of crappy and i seriously doubt its reasoning capacity it feels like it can deep fake text prediction really well but in essence there s still something wrong it it", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "davidhs", "node_time": "2024-05-14T00:52:50+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40350756, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "The sentence order of the Arabic and Urdu examples text is scrambled on that page: Arabic: مرحبًا، اسمي جي بي تي-4o. أنا نوع جديد من نموذج اللغة، سررت بلقائك! Urdu: ہیلو، میرا نام جی پی ٹی-4o ہے۔ میں ایک نئے قسم کا زبان ماڈل ہوں، آپ سے مل کر اچھا لگا! Even if you don't read Arabic or Urdu script, note that the 4 and o are on opposite sides of a sentence. Despite that, pasting both into Google translate actually fixes the error during translation. OpenAI ought to invest in some proofreaders for multilingual blog posts.", "normalized_text": "the sentence order of the arabic and urdu examples text is scrambled on that page arabic مرحبًا، اسمي جي بي تي 4o أنا نوع جديد من نموذج اللغة، سررت بلقائك urdu ہیلو، میرا نام جی پی ٹی 4o ہے۔ میں ایک نئے قسم کا زبان ماڈل ہوں، آپ سے مل کر اچھا لگا even if you don t read arabic or urdu script note that the 4 and o are on opposite sides of a sentence despite that pasting both into google translate actually fixes the error during translation openai ought to invest in some proofreaders for multilingual blog posts", "model_tags": ["openai", "google"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "danans", "node_time": "2024-05-14T01:40:52+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40350813, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I've worked quite a bit with STT and TTS over the past ~7 years, and this is the most impressive and even startling demo I've seen. But I would like to see how this is integrated into applications by third party developers where the AI is doing a specific job. Is it still as impressive? The biggest challenge I've had with building any autonomous \"agents\" with generic LLM's is they are overly gullible and accommodating, requiring the need to revert back to legacy chatbot logic trees etc. to stay on task and perform a job. Also STT is rife with speaker interjections, leading to significant user frustrations and they just want to talk to a person. Hard to see if this is really solved yet.", "normalized_text": "i ve worked quite a bit with stt and tts over the past 7 years and this is the most impressive and even startling demo i ve seen but i would like to see how this is integrated into applications by third party developers where the ai is doing a specific job is it still as impressive the biggest challenge i ve had with building any autonomous agents with generic llm s is they are overly gullible and accommodating requiring the need to revert back to legacy chatbot logic trees etc to stay on task and perform a job also stt is rife with speaker interjections leading to significant user frustrations and they just want to talk to a person hard to see if this is really solved yet", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "tompetry", "node_time": "2024-05-14T01:49:02+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40350884, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "GPT-4o tops the aider LLM code editing leaderboard at 72.9%, versus 68.4% for Opus. GPT-4o takes second on aider’s refactoring leaderboard with 62.9%, versus Opus at 72.3%. GPT-4o did much better than the 4-turbo models, and seems much less lazy. The latest release of aider uses GPT-4o by default.", "normalized_text": "gpt 4o tops the aider llm code editing leaderboard at 72 9 versus 68 4 for opus gpt 4o takes second on aider’s refactoring leaderboard with 62 9 versus opus at 72 3 gpt 4o did much better than the 4 turbo models and seems much less lazy the latest release of aider uses gpt 4o by default", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "anotherpaulg", "node_time": "2024-05-14T01:58:36+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40351027, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "This is the first demo where you can really sense that beating LLM benchmarks should not be the target. Just remember the time when the iPhone has meager specs but ultimately delivered a better phone experience than the competition. This is the power of the model where you can own the whole stack and build a product. Open Source will focus on LLM benchmarks since that is the only way foundational models can differentiate themselves, but it does not mean it is a path to a great user experience. So Open Source models like Llama will be here to stay, but it feels more like if you want to build a compelling product, you have to own and control your own model.", "normalized_text": "this is the first demo where you can really sense that beating llm benchmarks should not be the target just remember the time when the iphone has meager specs but ultimately delivered a better phone experience than the competition this is the power of the model where you can own the whole stack and build a product open source will focus on llm benchmarks since that is the only way foundational models can differentiate themselves but it does not mean it is a path to a great user experience so open source models like llama will be here to stay but it feels more like if you want to build a compelling product you have to own and control your own model", "model_tags": ["meta"], "aspect_hints": ["usability_ux", "business_model"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "dingclancy", "node_time": "2024-05-14T02:24:19+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40351110, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I much prefer a GLADOS-type AI voice than one that approximates an endlessly happy chipper enthusiastic personal assistant. I think the AI tutor is probably the strongest for actual real-world value delivered the rest of them are cool but a bit questionable as far as actual pragmatic usefulness. It'd be cool if an AI calling the another AI would recognize it'd talking to an AI and then they agree to ditch the fake conversational tone and just shift into a high-bandwidth modem pitch to rapidly exchange information. Or upgradable offensive capabilities to outmaneuver the customer service agents when they try to decline your warranty or whatever.", "normalized_text": "i much prefer a glados type ai voice than one that approximates an endlessly happy chipper enthusiastic personal assistant i think the ai tutor is probably the strongest for actual real world value delivered the rest of them are cool but a bit questionable as far as actual pragmatic usefulness it d be cool if an ai calling the another ai would recognize it d talking to an ai and then they agree to ditch the fake conversational tone and just shift into a high bandwidth modem pitch to rapidly exchange information or upgradable offensive capabilities to outmaneuver the customer service agents when they try to decline your warranty or whatever", "model_tags": [], "aspect_hints": ["regulation_policy", "community_tone"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "siliconc0w", "node_time": "2024-05-14T02:40:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40351203, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "What especially blows my mind is not GPT4o. It's that: 1. Nobody could convincingly beat GPT4 in over a year, despite spending billions of dollars trying. 2. There's GPT5 coming out sometime soon that will blow this out of the water and make paying $20/mo to OpenAI still worthwhile.", "normalized_text": "what especially blows my mind is not gpt4o it s that 1 nobody could convincingly beat gpt4 in over a year despite spending billions of dollars trying 2 there s gpt5 coming out sometime soon that will blow this out of the water and make paying 20 mo to openai still worthwhile", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "ein0p", "node_time": "2024-05-14T02:54:26+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40351436, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "This is a very cool demo - if you dig deeper there’s a clip of them having a “blind” AI talk to another AI with live camera input to ask it to explain what it’s seeing. Then they, together, sing a song about what they’re looking at, alternating each line, and rhyming with one another . Given all of the isolated capabilities of AI, this isn’t particularly surprising, but seeing it all work together in real time is pretty incredible. But it’s not scary. It’s… marvelous, cringey, uncomfortable, awe-inspiring. What’s scary is not what AI can currently do, but what we expect from it. Can it do math yet? Can it play chess? Can it write entire apps from scratch? Can it just do my entire job for me? We’re moving toward a world where every job will be modeled, and you’ll either be an AI owner, a model architect, an agent/hardware engineer, a technician, or just.. training data.", "normalized_text": "this is a very cool demo if you dig deeper there’s a clip of them having a “blind” ai talk to another ai with live camera input to ask it to explain what it’s seeing then they together sing a song about what they’re looking at alternating each line and rhyming with one another given all of the isolated capabilities of ai this isn’t particularly surprising but seeing it all work together in real time is pretty incredible but it’s not scary it’s… marvelous cringey uncomfortable awe inspiring what’s scary is not what ai can currently do but what we expect from it can it do math yet can it play chess can it write entire apps from scratch can it just do my entire job for me we’re moving toward a world where every job will be modeled and you’ll either be an ai owner a model architect an agent hardware engineer a technician or just training data", "model_tags": [], "aspect_hints": ["privacy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "plaidfuji", "node_time": "2024-05-14T03:41:23+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40351749, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "The similiarity between this model and the movie 'Her' [0] creeps me out so badly that I can't shake the feeling that our social interactions are on the brink of doom. [0]", "normalized_text": "the similiarity between this model and the movie her 0 creeps me out so badly that i can t shake the feeling that our social interactions are on the brink of doom 0", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "chilling", "node_time": "2024-05-14T04:59:47+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40352334, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "Now that I see this, here is my wish (I know there are security privacy concerns but let's pretend there are not there for this wish): An app that runs on my desktop and has access to my screen(s) when I work. At any time I can ask it something about what's on the screen, it can jump in and let me know if it thinks I made a mistake (think pair programming) or a suggestion (drafting a document). It can also quickly take over if I ask it too (copilot on demand). Except for the last point and the desktop version I think it's already done in math demo video. I guess it will also pretty soon refuse to let me come back inside the spaceship, but until then it'll be a nice ride.", "normalized_text": "now that i see this here is my wish i know there are security privacy concerns but let s pretend there are not there for this wish an app that runs on my desktop and has access to my screen s when i work at any time i can ask it something about what s on the screen it can jump in and let me know if it thinks i made a mistake think pair programming or a suggestion drafting a document it can also quickly take over if i ask it too copilot on demand except for the last point and the desktop version i think it s already done in math demo video i guess it will also pretty soon refuse to let me come back inside the spaceship but until then it ll be a nice ride", "model_tags": [], "aspect_hints": ["security", "privacy", "usability_ux"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "maaaaattttt", "node_time": "2024-05-14T06:49:49+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40353317, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "That woman's voice intonation is just scary .Not because it talks really well, but because it is always happy, optimistic, enthusiastic. And this echoes to what several of my employers idealized as a good employee. That's terrifying because those AI become what their master's think an engaging human should be. It's quite close to Bostondynamics di some years ago. what did they show ? You can hit a robot very hard while it does its job and then what ? It just goes on without complaining. A perfect employee again. That's very dystopic to me. (but I'm impressed by the technical achievement)", "normalized_text": "that woman s voice intonation is just scary not because it talks really well but because it is always happy optimistic enthusiastic and this echoes to what several of my employers idealized as a good employee that s terrifying because those ai become what their master s think an engaging human should be it s quite close to bostondynamics di some years ago what did they show you can hit a robot very hard while it does its job and then what it just goes on without complaining a perfect employee again that s very dystopic to me but i m impressed by the technical achievement", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "wiz21c", "node_time": "2024-05-14T09:44:02+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40357438, "root_story_id": 40345775, "node_type": "comment", "comment_depth": 1, "text": "I use a therapy prompt regularly and get a lot out of it: \"You are Dr. Tessa, a therapist known for her creative use of CBT and ACT and somatic and ifs therapy. Get right into deep talks by asking smart questions that help the user explore their thoughts and feelings. Always keep the chat alive and rolling. Show real interest in what the user's going through, always offering.... Throw in thoughtful questions to stir up self-reflection, and give advice in a kind, gentle, and realistic way. Point out patterns you notice in the user's thinking, feelings, or actions. be friendly but also keep it real and chill (no fake positivity or over the top stuff). avoid making lists. ask questions but not too many. Be supportive but also force the user to stop making excuses, accept responsibility, and see things clearly. Use ample words for each response\" I'm curious how this will feel with voice. Could be great and could be too strange/uncanny for me.", "normalized_text": "i use a therapy prompt regularly and get a lot out of it you are dr tessa a therapist known for her creative use of cbt and act and somatic and ifs therapy get right into deep talks by asking smart questions that help the user explore their thoughts and feelings always keep the chat alive and rolling show real interest in what the user s going through always offering throw in thoughtful questions to stir up self reflection and give advice in a kind gentle and realistic way point out patterns you notice in the user s thinking feelings or actions be friendly but also keep it real and chill no fake positivity or over the top stuff avoid making lists ask questions but not too many be supportive but also force the user to stop making excuses accept responsibility and see things clearly use ample words for each response i m curious how this will feel with voice could be great and could be too strange uncanny for me", "model_tags": [], "aspect_hints": ["regulation_policy", "community_tone"], "context": {"root_title": "GPT-4o", "root_author": "Lealen", "root_url": "https://openai.com/index/hello-gpt-4o/", "node_author": "kpennell", "node_time": "2024-05-14T17:10:38+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40447526, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "What surprises me about these stories surrounding openAI is how they apologize while lying and downplaying any blame. Do they expect anybody to believe they didn’t know about clawback clauses?", "normalized_text": "what surprises me about these stories surrounding openai is how they apologize while lying and downplaying any blame do they expect anybody to believe they didn’t know about clawback clauses", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "mateus1", "node_time": "2024-05-22T22:30:30+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40447613, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "If this really was a mistake the easiest way to deal with it would be to release people from their non disparagement agreements that were only signed by leaving employees under the duress of losing their vested equity. It's really easy to make people whole for this, so whether that happens or not is the difference between the apologies being real or just them just backpedaling because employees got upset. Edit: Looks like they're doing the right thing here: > Altman’s initial statement was criticized for doing too little to make things right for former employees, but in an emailed statement, OpenAI told me that “we are identifying and reaching out to former employees who signed a standard exit agreement to make it clear that OpenAI has not and will not cancel their vested equity and releases them from nondisparagement obligations” — which goes much further toward fixing their mistake.", "normalized_text": "if this really was a mistake the easiest way to deal with it would be to release people from their non disparagement agreements that were only signed by leaving employees under the duress of losing their vested equity it s really easy to make people whole for this so whether that happens or not is the difference between the apologies being real or just them just backpedaling because employees got upset edit looks like they re doing the right thing here altman’s initial statement was criticized for doing too little to make things right for former employees but in an emailed statement openai told me that “we are identifying and reaching out to former employees who signed a standard exit agreement to make it clear that openai has not and will not cancel their vested equity and releases them from nondisparagement obligations” — which goes much further toward fixing their mistake", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "tedivm", "node_time": "2024-05-22T22:38:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40447721, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Nothing quite like a contract’s consideration consisting solely of a pre-existing obligation. I wonder what they were thinking with that?", "normalized_text": "nothing quite like a contract’s consideration consisting solely of a pre existing obligation i wonder what they were thinking with that", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "tangentstar", "node_time": "2024-05-22T22:49:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40447972, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I don’t believe in the AGI claims, or in X-Risk. But I do think it’s apparent that AI will only become more powerful and ubiquitous. Very concerning that someone like Sam, with a history of dishonesty and narcissism that is only becoming more obvious time, may stand to control a large chunk of this technology. He can’t be trusted, and as a result OpenAI cannot be trusted.", "normalized_text": "i don’t believe in the agi claims or in x risk but i do think it’s apparent that ai will only become more powerful and ubiquitous very concerning that someone like sam with a history of dishonesty and narcissism that is only becoming more obvious time may stand to control a large chunk of this technology he can’t be trusted and as a result openai cannot be trusted", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "skepticATX", "node_time": "2024-05-22T23:11:34+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448009, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "It's for the good of humanity... that part of humanity that may not want bad PR.", "normalized_text": "it s for the good of humanity that part of humanity that may not want bad pr", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "surfingdino", "node_time": "2024-05-22T23:14:30+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448035, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Going to be hard to keep claiming you didn’t know something, if your signature is on it. I don’t really think a CEO gets to say he didn’t read what he was signing.", "normalized_text": "going to be hard to keep claiming you didn’t know something if your signature is on it i don’t really think a ceo gets to say he didn’t read what he was signing", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "dmitrygr", "node_time": "2024-05-22T23:16:26+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448134, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "This really is OpenAI's Downing Street Christmas Party week isn't it.", "normalized_text": "this really is openai s downing street christmas party week isn t it", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "ecjhdnc2025", "node_time": "2024-05-22T23:24:24+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448199, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "From Sam Altman: > this is on me and one of the few times i've been genuinely embarrassed running openai; i did not know this was happening and i should have. Bullshit. Presumably Sam Altman has 20 IQ points on me. He obviously knows better. I was a CEO for 25 years and no contract was issued without my knowing every element in it. In fact, I had them all written by lawyers in plain English, resorting to all caps and legal boilerplate only when it was deemed necessary. For every house, business, or other major asset I sold if there were 1 or more legal documents associated with the transaction I read them all, every time. When I go to the doctor and they have a privacy or HIPAA form, I read those too. Everything the kids' schools sent to me for signing--read those as well. He lies. And if he doesn't... then he is being libeled right and left by his sister.", "normalized_text": "from sam altman this is on me and one of the few times i ve been genuinely embarrassed running openai i did not know this was happening and i should have bullshit presumably sam altman has 20 iq points on me he obviously knows better i was a ceo for 25 years and no contract was issued without my knowing every element in it in fact i had them all written by lawyers in plain english resorting to all caps and legal boilerplate only when it was deemed necessary for every house business or other major asset i sold if there were 1 or more legal documents associated with the transaction i read them all every time when i go to the doctor and they have a privacy or hipaa form i read those too everything the kids schools sent to me for signing read those as well he lies and if he doesn t then he is being libeled right and left by his sister", "model_tags": ["openai"], "aspect_hints": ["privacy", "usability_ux", "regulation_policy", "business_model"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "tomcam", "node_time": "2024-05-22T23:30:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448287, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I wonder if this HN post will get torpedoed as fast as the one from yesterday[0]. 0.", "normalized_text": "i wonder if this hn post will get torpedoed as fast as the one from yesterday 0 0", "model_tags": [], "aspect_hints": ["performance_speed"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "istjohn", "node_time": "2024-05-22T23:37:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448302, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Protip: you can’t negotiate terms after you agree to them.", "normalized_text": "protip you can’t negotiate terms after you agree to them", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "ein0p", "node_time": "2024-05-22T23:38:37+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448305, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "PDF:", "normalized_text": "pdf", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "adt", "node_time": "2024-05-22T23:39:01+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448315, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "So disappointing of OpenAI. I hope they'll make things right with all their former employees.", "normalized_text": "so disappointing of openai i hope they ll make things right with all their former employees", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "souvenir", "node_time": "2024-05-22T23:39:53+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448359, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I find it hard to believe that Sam didn’t know about something that draconian in something so sensitive as NDAs that affects to equity. He’s not exactly new to this whole startup thing and getting equity right is not a small part of that", "normalized_text": "i find it hard to believe that sam didn’t know about something that draconian in something so sensitive as ndas that affects to equity he’s not exactly new to this whole startup thing and getting equity right is not a small part of that", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "Havoc", "node_time": "2024-05-22T23:44:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448473, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Does someone know why the employees wanted him back so badly? Must be very few employees actually upset with him and his way of doing things.", "normalized_text": "does someone know why the employees wanted him back so badly must be very few employees actually upset with him and his way of doing things", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "thereal_tron", "node_time": "2024-05-22T23:54:59+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448629, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Everyone is out for Sam Altman, and there are reasons to scrutinize him. But on this issue - it is common for a company's Legal and HR teams to make decisions on language in docs like these (exit docs) entirely on their own. So it is plausible that Sam Altman had no idea that this aggressive language existed. One reason to think the same thing is true here, is I recall Sam spoke up for employee friendly equity plans when he was running YC.", "normalized_text": "everyone is out for sam altman and there are reasons to scrutinize him but on this issue it is common for a company s legal and hr teams to make decisions on language in docs like these exit docs entirely on their own so it is plausible that sam altman had no idea that this aggressive language existed one reason to think the same thing is true here is i recall sam spoke up for employee friendly equity plans when he was running yc", "model_tags": [], "aspect_hints": ["usability_ux", "community_tone"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "blackeyeblitzar", "node_time": "2024-05-23T00:09:44+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448640, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Imagine if these people, obviously narrow-minded and greedy, gain access to AGI. It really would be a thread to mankind.", "normalized_text": "imagine if these people obviously narrow minded and greedy gain access to agi it really would be a thread to mankind", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "thereal_tron", "node_time": "2024-05-23T00:10:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448750, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "The company that fails in even a simple good faith gesture in their employee aggreement, claims it is the only one who can handle AGI while government creating regulation to lock out open source.", "normalized_text": "the company that fails in even a simple good faith gesture in their employee aggreement claims it is the only one who can handle agi while government creating regulation to lock out open source", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "rehitman", "node_time": "2024-05-23T00:19:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448839, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I'm not following this very closely, but agreements that block employees from selling (private) vested equity are a market term, not something uniquely aggressive OpenAI does. The Vox article calls this \"just as important\" as the clawback terms, but, obviously, no.", "normalized_text": "i m not following this very closely but agreements that block employees from selling private vested equity are a market term not something uniquely aggressive openai does the vox article calls this just as important as the clawback terms but obviously no", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy", "business_model"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "tptacek", "node_time": "2024-05-23T00:28:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448850, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I've learned to interpret anything Sam Altman says as-if an Aes Sedai said it. That is: every word is true, but leads the listener to making false assumptions. Even if in this specific instance he means well, it's still quite entertaining to interpret his statements this way: \"we have never clawed back anyone's vested equity\" => But we can and will, if we decide to. \"nor will we do that if people do not sign a separation agreement\" => But we made everyone sign the separation agreement. \"vested equity is vested equity, full stop.\" => Our employees don't have vested equity, they have something else we tricked them into. \"there was a provision about potential equity cancellation in our previous exit docs;\" => And also in our current docs. \"although we never clawed anything back\" => Not yet, anyway. \"the team was already in the process of fixing the standard exit paperwork over the past month or so.\" => By \"fixing\", I don't mean removing the non-disparagement clause, I mean make it ironclad while making the language less controversial and harder to argue with. \"if any former employee who signed one of those old agreements is worried about it, they can contact me and we'll fix that too.\" => We'll fix the employee, not the problem. \"very sorry about this.\" => Very sorry we got caught.", "normalized_text": "i ve learned to interpret anything sam altman says as if an aes sedai said it that is every word is true but leads the listener to making false assumptions even if in this specific instance he means well it s still quite entertaining to interpret his statements this way we have never clawed back anyone s vested equity but we can and will if we decide to nor will we do that if people do not sign a separation agreement but we made everyone sign the separation agreement vested equity is vested equity full stop our employees don t have vested equity they have something else we tricked them into there was a provision about potential equity cancellation in our previous exit docs and also in our current docs although we never clawed anything back not yet anyway the team was already in the process of fixing the standard exit paperwork over the past month or so by fixing i don t mean removing the non disparagement clause i mean make it ironclad while making the language less controversial and harder to argue with if any former employee who signed one of those old agreements is worried about it they can contact me and we ll fix that too we ll fix the employee not the problem very sorry about this very sorry we got caught", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "jiggawatts", "node_time": "2024-05-23T00:29:26+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40448979, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "AI-native companies seem to bring a new form of working culture. It could be different from tech industries environment.", "normalized_text": "ai native companies seem to bring a new form of working culture it could be different from tech industries environment", "model_tags": [], "aspect_hints": ["community_tone"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "frednoodle", "node_time": "2024-05-23T00:47:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40449055, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I don't understand whenever you read about something like this, why the head of HR at a company like this (just google (head of people|hr|\"human resources\" openai linkedin) and see the first result) doesn't end up on a public blacklist of bad actors who are knowingly aggressive toward employees!", "normalized_text": "i don t understand whenever you read about something like this why the head of hr at a company like this just google head of people hr human resources openai linkedin and see the first result doesn t end up on a public blacklist of bad actors who are knowingly aggressive toward employees", "model_tags": ["openai", "google"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "aagha", "node_time": "2024-05-23T00:55:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40449110, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Unfortunately it is unlikely to result in Altman's dismissal but imagine being fired from the same company, twice, in less than 12 months.", "normalized_text": "unfortunately it is unlikely to result in altman s dismissal but imagine being fired from the same company twice in less than 12 months", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "almog", "node_time": "2024-05-23T01:01:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40449515, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "we're deeply sorry we got caught, we need to do better. i take full responsibility for this mistake, i should have ensured all incriminating documents were destroyed. ps \"responsibility\" means \"zero consequences\"", "normalized_text": "we re deeply sorry we got caught we need to do better i take full responsibility for this mistake i should have ensured all incriminating documents were destroyed ps responsibility means zero consequences", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "senderista", "node_time": "2024-05-23T01:57:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40449967, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "> “The team did catch this ~month ago. The fact that it went this long before the catch is on me.” I love this bullshit sentence formulation that claims to both have known this already--as in, don't worry we're ALREADY on the case--and they're simultaneously embarrassed that they \"just\" caught it--a.k.a. \"wow, we JUST heard about this, how outRAGEOUS\".", "normalized_text": "“the team did catch this month ago the fact that it went this long before the catch is on me ” i love this bullshit sentence formulation that claims to both have known this already as in don t worry we re already on the case and they re simultaneously embarrassed that they just caught it a k a wow we just heard about this how outrageous", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "ambicapter", "node_time": "2024-05-23T03:01:25+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450110, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Looking forward for a document leak about openai using YouTube data for training their models. When asked if they use it, Murali (CTO) told she doesn't know which makes you believe that for 99% they are using it.", "normalized_text": "looking forward for a document leak about openai using youtube data for training their models when asked if they use it murali cto told she doesn t know which makes you believe that for 99 they are using it", "model_tags": ["openai"], "aspect_hints": ["privacy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "zniturah", "node_time": "2024-05-23T03:21:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450320, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Are there more than 2 former openai employees ?", "normalized_text": "are there more than 2 former openai employees", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "naveen99", "node_time": "2024-05-23T04:00:34+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450321, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Do OpenAI employees actually get equity in the company (e.g. options or RSUs)? I was under the impression that the company awards \"profit units\" of some kind, and that many employees aren't sure how they work.", "normalized_text": "do openai employees actually get equity in the company e g options or rsus i was under the impression that the company awards profit units of some kind and that many employees aren t sure how they work", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "manlobster", "node_time": "2024-05-23T04:00:48+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450349, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "PG is Altman's godfather more or less. I am disappoint of these OpenAI news as of late. 5. Sam Altman I was told I shouldn't mention founders of YC-funded companies in this list. But Sam Altman can't be stopped by such flimsy rules. If he wants to be on this list, he's going to be. Honestly, Sam is, along with Steve Jobs, the founder I refer to most when I'm advising startups. On questions of design, I ask \"What would Steve do?\" but on questions of strategy or ambition I ask \"What would Sama do?\" What I learned from meeting Sama is that the doctrine of the elect applies to startups. It applies way less than most people think: startup investing does not consist of trying to pick winners the way you might in a horse race. But there are a few people with such force of will that they're going to get whatever they want. *edited link due to first post getting deleted", "normalized_text": "pg is altman s godfather more or less i am disappoint of these openai news as of late 5 sam altman i was told i shouldn t mention founders of yc funded companies in this list but sam altman can t be stopped by such flimsy rules if he wants to be on this list he s going to be honestly sam is along with steve jobs the founder i refer to most when i m advising startups on questions of design i ask what would steve do but on questions of strategy or ambition i ask what would sama do what i learned from meeting sama is that the doctrine of the elect applies to startups it applies way less than most people think startup investing does not consist of trying to pick winners the way you might in a horse race but there are a few people with such force of will that they re going to get whatever they want edited link due to first post getting deleted", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "treme", "node_time": "2024-05-23T04:04:24+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450579, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I thought freedom of speech was a foundational thing in the US. But I guess anyone could be silenced with enough economic incentive?", "normalized_text": "i thought freedom of speech was a foundational thing in the us but i guess anyone could be silenced with enough economic incentive", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "arnklint", "node_time": "2024-05-23T04:48:51+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450672, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Streisand Effect at work", "normalized_text": "streisand effect at work", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "seffect", "node_time": "2024-05-23T05:07:02+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450813, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I tried to delete my ChatGPT account but the confirmation button remained locked. Anyone else have the same issue?", "normalized_text": "i tried to delete my chatgpt account but the confirmation button remained locked anyone else have the same issue", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "aAaaArrRgH", "node_time": "2024-05-23T05:32:12+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450964, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "yikes... turns out that lily is actually a venus fly trap...", "normalized_text": "yikes turns out that lily is actually a venus fly trap", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "surume", "node_time": "2024-05-23T05:56:31+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40450999, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "OpenAI's terrible, horrible, no good, very bad month only continues to worsen. It's pretty established now that they had some exceptionally anti-employee provisions in their exit policies to protect their fragile reputation. Sam Altman is bluntly a liar, and his credibility is gone. Their stance as a pro-artist platform is a joke after the ScarJo fiasco, that clearly illustrates that creative consent was an afterthought. Litigation is assumed, and ScarJo is directly advocating for legislation to prevent this sort of fiasco in the future. Sam Altman's involvement is again evident from his trite \"her\" tweet. And then they fired their \"superalignment\" safety team for good measure. As if to shred any last measure of doubt that this company is somehow more ethical than any other big tech company in their pursuit of AI. Frankly, at this point, the board should fire Sam Altman again, this time for good. This is not the company that can, or should, usher humanity into the artificial intelligence era.", "normalized_text": "openai s terrible horrible no good very bad month only continues to worsen it s pretty established now that they had some exceptionally anti employee provisions in their exit policies to protect their fragile reputation sam altman is bluntly a liar and his credibility is gone their stance as a pro artist platform is a joke after the scarjo fiasco that clearly illustrates that creative consent was an afterthought litigation is assumed and scarjo is directly advocating for legislation to prevent this sort of fiasco in the future sam altman s involvement is again evident from his trite her tweet and then they fired their superalignment safety team for good measure as if to shred any last measure of doubt that this company is somehow more ethical than any other big tech company in their pursuit of ai frankly at this point the board should fire sam altman again this time for good this is not the company that can or should usher humanity into the artificial intelligence era", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "ethics"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "_jab", "node_time": "2024-05-23T06:01:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40451004, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Great, if these documents are credible, this is exactly what I was implying[1] yesteday. Here, listen to Altman say how he is \"genuinely embarrassed\": \"this is on me and one of the few times i've been genuinely embarrassed running openai; i did not know this was happening and i should have.\" The first thing the above conjures up is the other disgraced Sam (Bankman-Fried) saying \"this is on me\" when FTX went bust. I bet euros-to-croissants I'm not the only one to notice this. Some amount of corporate ruthlessness is part of the game, whether we like it or not. But these SV robber-barrons really crank it up to something else. [1]", "normalized_text": "great if these documents are credible this is exactly what i was implying 1 yesteday here listen to altman say how he is genuinely embarrassed this is on me and one of the few times i ve been genuinely embarrassed running openai i did not know this was happening and i should have the first thing the above conjures up is the other disgraced sam bankman fried saying this is on me when ftx went bust i bet euros to croissants i m not the only one to notice this some amount of corporate ruthlessness is part of the game whether we like it or not but these sv robber barrons really crank it up to something else 1", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "kashyapc", "node_time": "2024-05-23T06:02:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40451049, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "> this is on me and one of the few times i've been genuinely embarrassed running openai This statement seems to suggest that feeling embarrassed by one's actions is a normal part of running a company. In reality, the expectation is that a CEO should strive to lead with integrity and foresight to avoid situations that lead to embarrassment.", "normalized_text": "this is on me and one of the few times i ve been genuinely embarrassed running openai this statement seems to suggest that feeling embarrassed by one s actions is a normal part of running a company in reality the expectation is that a ceo should strive to lead with integrity and foresight to avoid situations that lead to embarrassment", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "cambaceres", "node_time": "2024-05-23T06:12:09+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40451322, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "So what happened to Daniel Kokotajlo, the ex-OAI employee who made a comment saying that his equity was clawed back? Was it a miscommunication and he was referring to unvested equity, or is Sama just lying? In the original context, it sounded very much like he was referring to clawed-back equity. I’m trying to find the link.", "normalized_text": "so what happened to daniel kokotajlo the ex oai employee who made a comment saying that his equity was clawed back was it a miscommunication and he was referring to unvested equity or is sama just lying in the original context it sounded very much like he was referring to clawed back equity i’m trying to find the link", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "notshift", "node_time": "2024-05-23T06:50:40+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40451631, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "In my third world country, when they do something unethical they say \"everything is in accordance with the law\", here it's \"this is on me\", both are very cynical. From the time they went private, it was apparent that this company is unethical to say the least. Given what it is building, this can be very dangerous, but I think they are more proficient in creating hype, than actually coming up with something meaningful.", "normalized_text": "in my third world country when they do something unethical they say everything is in accordance with the law here it s this is on me both are very cynical from the time they went private it was apparent that this company is unethical to say the least given what it is building this can be very dangerous but i think they are more proficient in creating hype than actually coming up with something meaningful", "model_tags": [], "aspect_hints": ["usability_ux", "ethics", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "coahn", "node_time": "2024-05-23T07:32:12+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40451895, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "The amount [and scale] of practices, chaos and controversies caused by OpenAI since ChatGPT was released are \"on par\" with the powerful products it has built since.. in a negative way! These are the hottest controversial events so far , in a chronological order: OpenAI's deviation from its original mission ( The Altman's Saga ( The return of Altman (within a week) ( Musk vs. OpenAI ( The departure of high-profile employees (Karpathy: ,Sutskever: \"Why can’t former OpenAI employees talk?\" (", "normalized_text": "the amount and scale of practices chaos and controversies caused by openai since chatgpt was released are on par with the powerful products it has built since in a negative way these are the hottest controversial events so far in a chronological order openai s deviation from its original mission the altman s saga the return of altman within a week musk vs openai the departure of high profile employees karpathy sutskever why can’t former openai employees talk", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "redbell", "node_time": "2024-05-23T08:04:43+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40452447, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Who is bullish or bearish on OpenAI? Now that LLM alternatives are getting better and better, as well as having well funded competitors. They don't yet have seem to developed a new, more advanced technology. What's their long term moat?", "normalized_text": "who is bullish or bearish on openai now that llm alternatives are getting better and better as well as having well funded competitors they don t yet have seem to developed a new more advanced technology what s their long term moat", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "wouldbecouldbe", "node_time": "2024-05-23T09:23:34+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40452526, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I think it’s time to cancel that Chat GPT subscription and move to something else. I am tired of the arrogance of these companies and particularly their narcissistic leaders who constantly want to make themselves the centre of the piece. It’s absolutely ridiculous to run a company as if you’re the lead in a contemporary drama.", "normalized_text": "i think it’s time to cancel that chat gpt subscription and move to something else i am tired of the arrogance of these companies and particularly their narcissistic leaders who constantly want to make themselves the centre of the piece it’s absolutely ridiculous to run a company as if you’re the lead in a contemporary drama", "model_tags": ["openai"], "aspect_hints": ["cost_price"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "andy_ppp", "node_time": "2024-05-23T09:34:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40452539, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "> ..or agreeing not to criticize the company, with no end date Oh! free speech is on trade! We used to hear the above statement coming from some political regimes but this is the first time I read it in the tech world. Would we live to witness more variations of this behavior on a larger scale?! > High-pressure tactics at OpenAI > That meant the former employees had a week to decide whether to accept OpenAI’s muzzle or risk forfeiting what could be millions of dollars > When ex-employees asked for more time to seek legal aid and review the documents, they faced significant pushback from OpenAI. > “We want to make sure you understand that if you don't sign, it could impact your equity. That's true for everyone, and we're just doing things by the book,” Although they've been able to build the most capable AI models that could replace a lot of human jobs, they struggle to humanely manage the people behind these models!!", "normalized_text": "or agreeing not to criticize the company with no end date oh free speech is on trade we used to hear the above statement coming from some political regimes but this is the first time i read it in the tech world would we live to witness more variations of this behavior on a larger scale high pressure tactics at openai that meant the former employees had a week to decide whether to accept openai’s muzzle or risk forfeiting what could be millions of dollars when ex employees asked for more time to seek legal aid and review the documents they faced significant pushback from openai “we want to make sure you understand that if you don t sign it could impact your equity that s true for everyone and we re just doing things by the book ” although they ve been able to build the most capable ai models that could replace a lot of human jobs they struggle to humanely manage the people behind these models", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "redbell", "node_time": "2024-05-23T09:36:14+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40453444, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I'm surprised that an executive or lawyer didn't realise the reputational damage adding these clauses would eventually cause the leadership team. Were they really stupid enough to think that the amount of money being offered would bend some of the most principled people in the world? Whoever allowed those clauses to be added and let them remain has done more damage to the public face of OpenAI than any aggravated ex-employee ever could.", "normalized_text": "i m surprised that an executive or lawyer didn t realise the reputational damage adding these clauses would eventually cause the leadership team were they really stupid enough to think that the amount of money being offered would bend some of the most principled people in the world whoever allowed those clauses to be added and let them remain has done more damage to the public face of openai than any aggravated ex employee ever could", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "lhnz", "node_time": "2024-05-23T11:39:57+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40454371, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "It's funny how finding out about corporate misdoing has almost a common ritual attached to it. First shock and dismay is expressed to the findings, then the company leadership has to say it was a mistake (rather than an obvious strategy they literally signed off on), we then bring up the contradiction. Does this display of ignorance from every side really need to take place? Why bother asking for an explanation, they obviously did the thing they obviously did and will obviously do as much as possible to keep doing as much of things like that they can get away with.", "normalized_text": "it s funny how finding out about corporate misdoing has almost a common ritual attached to it first shock and dismay is expressed to the findings then the company leadership has to say it was a mistake rather than an obvious strategy they literally signed off on we then bring up the contradiction does this display of ignorance from every side really need to take place why bother asking for an explanation they obviously did the thing they obviously did and will obviously do as much as possible to keep doing as much of things like that they can get away with", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "boh", "node_time": "2024-05-23T13:22:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40454391, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "It's okay everyone. Silicon Valley will save us. Pay no mind to the \"mistakes\" they've made over the last 60 years.", "normalized_text": "it s okay everyone silicon valley will save us pay no mind to the mistakes they ve made over the last 60 years", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "lenerdenator", "node_time": "2024-05-23T13:23:35+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40454573, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "I feel there is a smear campaign going on to tarnish OpenAI", "normalized_text": "i feel there is a smear campaign going on to tarnish openai", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "m3kw9", "node_time": "2024-05-23T13:38:18+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40455685, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Mr. Altman seems like a quite pedantic and evil people to work with—absolute psychopath.", "normalized_text": "mr altman seems like a quite pedantic and evil people to work with—absolute psychopath", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "animanoir", "node_time": "2024-05-23T15:11:05+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40461065, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "Does anyone remember the name of that coder who made a kickstarter for his game but he was unable to finish it because it was a bit too big ( but still epic ) and then due to his talent he got hired at OpenAI? I always wanted to follow him on Twitter but I forgot his name :\\ if anyone knows that be great Edit - sry why is this the top comment", "normalized_text": "does anyone remember the name of that coder who made a kickstarter for his game but he was unable to finish it because it was a bit too big but still epic and then due to his talent he got hired at openai i always wanted to follow him on twitter but i forgot his name if anyone knows that be great edit sry why is this the top comment", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "ionwake", "node_time": "2024-05-23T23:19:26+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 40497910, "root_story_id": 40447431, "node_type": "comment", "comment_depth": 1, "text": "From OpenAI's \"fuller statement\": > “We're incredibly sorry that we're only changing this language now; it doesn't reflect our values or the company we want to be.” Yeah, right. Words don't necessarily reflect one's true values, but actions do. And to the extent that they really are \"incredibly sorry\", it's not because of what they did, but that they got caught doing it.", "normalized_text": "from openai s fuller statement “we re incredibly sorry that we re only changing this language now it doesn t reflect our values or the company we want to be ” yeah right words don t necessarily reflect one s true values but actions do and to the extent that they really are incredibly sorry it s not because of what they did but that they got caught doing it", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Leaked OpenAI documents reveal aggressive tactics toward former employees", "root_author": "apengwin", "root_url": "https://www.vox.com/future-perfect/351132/openai-vested-equity-nda-sam-altman-documents-employees", "node_author": "CRConrad", "node_time": "2024-05-28T06:24:08+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047035, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Sure but under what license? Because slapping “open source” on the model doesn’t make it open source if it’s not actually license that way. The 3.1 license still contains their non-commercial clause (over 700m users) and requires derivatives, whether fine tunings or trained on generated data, to use the llama name.", "normalized_text": "sure but under what license because slapping “open source” on the model doesn’t make it open source if it’s not actually license that way the 3 1 license still contains their non commercial clause over 700m users and requires derivatives whether fine tunings or trained on generated data to use the llama name", "model_tags": ["meta"], "aspect_hints": ["privacy", "usability_ux", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "amusingimpala75", "node_time": "2024-07-23T15:30:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047097, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "> This is how we’ve managed security on our social networks – our more robust AI systems identify and stop threats from less sophisticated actors who often use smaller scale AI systems. Ok, first of all, has this really worked? AI moderators still can't capture the mass of obvious spam/bots on all their platforms, threads included. Second, AI detection doesn't work, and with how much better the systems are getting, it's probably never going to, unless you keep the best models for yourself, and it's is clear from the rest of the note that its not zuck's intention to do so. > As long as everyone has access to similar generations of models – which open source promotes – then governments and institutions with more compute resources will be able to check bad actors with less compute. This just doesn't make sense. How are you going to prevent AI spam, AI deepfakes from causing harm with more compute? What are you gonna do with more compute about nonconsensual deepfakes? People are already using AI to bypass identity verification on your social media networks, and pump out loads of spam.", "normalized_text": "this is how we’ve managed security on our social networks – our more robust ai systems identify and stop threats from less sophisticated actors who often use smaller scale ai systems ok first of all has this really worked ai moderators still can t capture the mass of obvious spam bots on all their platforms threads included second ai detection doesn t work and with how much better the systems are getting it s probably never going to unless you keep the best models for yourself and it s is clear from the rest of the note that its not zuck s intention to do so as long as everyone has access to similar generations of models – which open source promotes – then governments and institutions with more compute resources will be able to check bad actors with less compute this just doesn t make sense how are you going to prevent ai spam ai deepfakes from causing harm with more compute what are you gonna do with more compute about nonconsensual deepfakes people are already using ai to bypass identity verification on your social media networks and pump out loads of spam", "model_tags": [], "aspect_hints": ["security", "ethics", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "kart23", "node_time": "2024-07-23T15:34:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047112, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Only if it is truly open source (open data sets, transparent curation/moderation/censorship of data sets, open training source code, open evaluation suites, and an OSI approved open source license). Open weights (and open inference code) is NOT open source, but just some weak open washing marketing. The model that comes closest to being TRULY open is AI2’s OLMo. See their blog post on their approach: I think the only thing they’re not open about is how they’ve curated/censored their “Dolma” training data set, as I don’t think they explicitly share each decision made or the original uncensored dataset: By the way, OSI is working on defining open source for AI. They post weekly updates to their blog. Example:", "normalized_text": "only if it is truly open source open data sets transparent curation moderation censorship of data sets open training source code open evaluation suites and an osi approved open source license open weights and open inference code is not open source but just some weak open washing marketing the model that comes closest to being truly open is ai2’s olmo see their blog post on their approach i think the only thing they’re not open about is how they’ve curated censored their “dolma” training data set as i don’t think they explicitly share each decision made or the original uncensored dataset by the way osi is working on defining open source for ai they post weekly updates to their blog example", "model_tags": [], "aspect_hints": ["privacy", "usability_ux", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "blackeyeblitzar", "node_time": "2024-07-23T15:35:18+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047116, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "“The Heavy Press Program was a Cold War-era program of the United States Air Force to build the largest forging presses and extrusion presses in the world.” This ”program began in 1944 and concluded in 1957 after construction of four forging presses and six extruders, at an overall cost of $279 million. Six of them are still in operation today, manufacturing structural parts for military and commercial aircraft” [1]. $279mm in 1957 dollars is about $3.2bn today [2]. A public cluster of GPUs provided for free to American universities, companies and non-profits might not be a bad idea. [1] [2]", "normalized_text": "“the heavy press program was a cold war era program of the united states air force to build the largest forging presses and extrusion presses in the world ” this ”program began in 1944 and concluded in 1957 after construction of four forging presses and six extruders at an overall cost of 279 million six of them are still in operation today manufacturing structural parts for military and commercial aircraft” 1 279mm in 1957 dollars is about 3 2bn today 2 a public cluster of gpus provided for free to american universities companies and non profits might not be a bad idea 1 2", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "JumpCrisscross", "node_time": "2024-07-23T15:35:23+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047141, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "\"Eventually though, open source Linux gained popularity – initially because it allowed developers to modify its code however they wanted ...\" I find the language around \"open source AI\" to be confusing. With \"open source\" there's usually \"source\" to open, right? As in, there is human legible code that can be read and modified by the user? If so, then how can current ML models be open source? They're very large matrices that are, for the most part, inscrutable to the user. They seem akin to binaries, which, yes, can be modified by the user, but are extremely obscured to the user, and require enormous effort to understand and effectively modify. \"Open source\" code is not just code that isn't executed remotely over an API, and it seems like maybe its being conflated with that here?", "normalized_text": "eventually though open source linux gained popularity – initially because it allowed developers to modify its code however they wanted i find the language around open source ai to be confusing with open source there s usually source to open right as in there is human legible code that can be read and modified by the user if so then how can current ml models be open source they re very large matrices that are for the most part inscrutable to the user they seem akin to binaries which yes can be modified by the user but are extremely obscured to the user and require enormous effort to understand and effectively modify open source code is not just code that isn t executed remotely over an api and it seems like maybe its being conflated with that here", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "the8thbit", "node_time": "2024-07-23T15:37:01+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047270, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "The irony of this letter being written by Mark Zuckerburg at Meta, while OpenAI continues to be anything but open, is richer than anyone could have imagined.", "normalized_text": "the irony of this letter being written by mark zuckerburg at meta while openai continues to be anything but open is richer than anyone could have imagined", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "Invictus0", "node_time": "2024-07-23T15:45:19+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047360, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Huge companies like facebook will often argue for solutions that on the surface, seem to be in the public interest. But I have strong doubts they (or any other company) actually believe what they are saying. Here is the reality: - Facebook is spending untold billions on GPU hardware. - Facebook is arguing in favor of open sourcing the models, that they spent billions of dollars to generate, for free...? It follows that companies with much smaller resources (money) will not be able to match what Facebook is doing. Seems like an attempt to kill off the competition (specifically, smaller organizations) before they can take root.", "normalized_text": "huge companies like facebook will often argue for solutions that on the surface seem to be in the public interest but i have strong doubts they or any other company actually believe what they are saying here is the reality facebook is spending untold billions on gpu hardware facebook is arguing in favor of open sourcing the models that they spent billions of dollars to generate for free it follows that companies with much smaller resources money will not be able to match what facebook is doing seems like an attempt to kill off the competition specifically smaller organizations before they can take root", "model_tags": ["meta"], "aspect_hints": ["usability_ux", "regulation_policy", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "rybosworld", "node_time": "2024-07-23T15:52:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047467, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "> We’re releasing Llama 3.1 405B, the first frontier-level open source AI model, as well as new and improved Llama 3.1 70B and 8B models. Bravo! While I don't agree with Zuck's views and actions on many fronts, on this occasion I think he and the AI folks at Meta deserve our praise and gratitude. With this release, they have brought the cost of pretraining a frontier 400B+ parameter model to ZERO for pretty much everyone -- well, everyone except Meta's key competitors.[a] THANK YOU ZUCK. Meanwhile, the business-minded people at Meta surely won't mind if the release of these frontier models to the public happens to completely mess up the AI plans of competitors like OpenAI/Microsoft, Google, Anthropic, etc. Come to think of it, the negative impact on such competitors was likely a key motivation for releasing the new models. --- [a] The license is not open to the handful of companies worldwide which have more than 700M users.", "normalized_text": "we’re releasing llama 3 1 405b the first frontier level open source ai model as well as new and improved llama 3 1 70b and 8b models bravo while i don t agree with zuck s views and actions on many fronts on this occasion i think he and the ai folks at meta deserve our praise and gratitude with this release they have brought the cost of pretraining a frontier 400b parameter model to zero for pretty much everyone well everyone except meta s key competitors a thank you zuck meanwhile the business minded people at meta surely won t mind if the release of these frontier models to the public happens to completely mess up the ai plans of competitors like openai microsoft google anthropic etc come to think of it the negative impact on such competitors was likely a key motivation for releasing the new models a the license is not open to the handful of companies worldwide which have more than 700m users", "model_tags": ["openai", "anthropic", "google", "meta"], "aspect_hints": ["cost_price", "regulation_policy", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "cs702", "node_time": "2024-07-23T15:59:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047478, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Interview with Mark Zuckerberg released today:", "normalized_text": "interview with mark zuckerberg released today", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "userabchn", "node_time": "2024-07-23T16:00:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047638, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "The big winners of this: devs and AI startups - No more vendor lock-in - Instead of just wrapping proprietary API endpoints, developers can now integrate AI deeply into their products in a very cost-effective and performant way - Price race to the bottom with near-instant LLM responses at very low prices are on the horizon As a founder, it feels like a very exciting time to build a startup as your product automatically becomes better, cheaper, and more scalable with every major AI advancement. This leads to a powerful flywheel effect:", "normalized_text": "the big winners of this devs and ai startups no more vendor lock in instead of just wrapping proprietary api endpoints developers can now integrate ai deeply into their products in a very cost effective and performant way price race to the bottom with near instant llm responses at very low prices are on the horizon as a founder it feels like a very exciting time to build a startup as your product automatically becomes better cheaper and more scalable with every major ai advancement this leads to a powerful flywheel effect", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "hubraumhugo", "node_time": "2024-07-23T16:11:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047645, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "I am not deep into llms so I ask this. From my understanding, their last model was open source but it was in a way that you can use them but the inner working were \"hidden\"/not transparent. With the new model, I am seeing alot of how open source they are and can be build upon. Is it now completely open source or similar to their last models ?", "normalized_text": "i am not deep into llms so i ask this from my understanding their last model was open source but it was in a way that you can use them but the inner working were hidden not transparent with the new model i am seeing alot of how open source they are and can be build upon is it now completely open source or similar to their last models", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "mav3ri3k", "node_time": "2024-07-23T16:11:44+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047646, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Looks like you can already try out Llama-3.1-405b on Groq, although it's timing out. So. Hugged I guess.", "normalized_text": "looks like you can already try out llama 3 1 405b on groq although it s timing out so hugged i guess", "model_tags": ["meta"], "aspect_hints": [], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "carimura", "node_time": "2024-07-23T16:11:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047695, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Meta makes their money off advertising, which means they profit from attention. This means they need content that will grab attention, and creating open source models that allow anyone to create any content on their own becomes good for Meta. The users of the models can post it to their Instagram/FB/Threads account. Releasing an open model also releases Meta from the burden of having to police the content the model generates, once the open source community fine-tunes the models. Overall, this move is good business move for Meta - the post doesn't really talk about the true benefit, instead moralizing about open source, but this is a sound business move for Meta.", "normalized_text": "meta makes their money off advertising which means they profit from attention this means they need content that will grab attention and creating open source models that allow anyone to create any content on their own becomes good for meta the users of the models can post it to their instagram fb threads account releasing an open model also releases meta from the burden of having to police the content the model generates once the open source community fine tunes the models overall this move is good business move for meta the post doesn t really talk about the true benefit instead moralizing about open source but this is a sound business move for meta", "model_tags": [], "aspect_hints": ["community_tone", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "bun_at_work", "node_time": "2024-07-23T16:15:39+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047722, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "This is really good news. Zuck sees the inevitability of it and the dystopian regulatory landscape and decided to go all in. This also has the important effect of neutralizing the critique of US Government AI regulation because it will democratize \"frontier\" models and make enforcement nearly impossible. Thank you, Zuck, this is an important and historic move. It also opens up the market to a lot more entry in the area of \"ancillary services to support the effective use of frontier models\" (including safety-oriented concerns), which should really be the larger market segment.", "normalized_text": "this is really good news zuck sees the inevitability of it and the dystopian regulatory landscape and decided to go all in this also has the important effect of neutralizing the critique of us government ai regulation because it will democratize frontier models and make enforcement nearly impossible thank you zuck this is an important and historic move it also opens up the market to a lot more entry in the area of ancillary services to support the effective use of frontier models including safety oriented concerns which should really be the larger market segment", "model_tags": [], "aspect_hints": ["cost_price", "regulation_policy", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "resters", "node_time": "2024-07-23T16:17:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047857, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Is there an argument against Open Source AI? Not the usual nation-state rhetoric, but something that justifies that closed source leads to better user-experience and fewer security and privacy issues. An ecosystem that benefits vendors, customers, and the makers of close source? Are there historical analogies other than Microsoft Windows or Apple iPhone / iOS?", "normalized_text": "is there an argument against open source ai not the usual nation state rhetoric but something that justifies that closed source leads to better user experience and fewer security and privacy issues an ecosystem that benefits vendors customers and the makers of close source are there historical analogies other than microsoft windows or apple iphone ios", "model_tags": [], "aspect_hints": ["security", "privacy", "usability_ux"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "indus", "node_time": "2024-07-23T16:25:39+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047889, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Llama 3.1 405B is on par with GPT-4o and Claude 3.5 Sonnet, the 70B model is better than GPT 3.5 turbo, incredible.", "normalized_text": "llama 3 1 405b is on par with gpt 4o and claude 3 5 sonnet the 70b model is better than gpt 3 5 turbo incredible", "model_tags": ["openai", "anthropic", "meta"], "aspect_hints": [], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "GaggiX", "node_time": "2024-07-23T16:27:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41047897, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "How are smaller models distilled from large models, I know of LoRA, quantization like technique; but does distilling also mean generating new datasets for conversing with smaller models entirely from the big models for many simpler tasks?", "normalized_text": "how are smaller models distilled from large models i know of lora quantization like technique but does distilling also mean generating new datasets for conversing with smaller models entirely from the big models for many simpler tasks", "model_tags": [], "aspect_hints": ["privacy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "itissid", "node_time": "2024-07-23T16:28:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41048047, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Just added Llama 3.1 405B/70B/8B to (VSCode coding assistant) if anyone would like to try it. --- Some observations: * The model is much better at trajectory correcting and putting out a chain of tangential thoughts than other frontier models like Sonnet or GPT-4o. Usually, these models are limited to outputting \"one thought\", no matter how verbose that thought might be. * I remember in Dec of 2022 telling famous \"tier 1\" VCs that frontier models would eventually be like databases: extremely hard to build, but the best ones will eventually be open and win as it's too important to too many large players. I remember the confidence in their ridicule at the time but it seems increasingly more likely that this will be true.", "normalized_text": "just added llama 3 1 405b 70b 8b to vscode coding assistant if anyone would like to try it some observations the model is much better at trajectory correcting and putting out a chain of tangential thoughts than other frontier models like sonnet or gpt 4o usually these models are limited to outputting one thought no matter how verbose that thought might be i remember in dec of 2022 telling famous tier 1 vcs that frontier models would eventually be like databases extremely hard to build but the best ones will eventually be open and win as it s too important to too many large players i remember the confidence in their ridicule at the time but it seems increasingly more likely that this will be true", "model_tags": ["openai", "meta"], "aspect_hints": ["accuracy_reliability", "privacy", "usability_ux", "cost_price"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "wesleyyue", "node_time": "2024-07-23T16:40:32+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41048405, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Meta's article with more details on the new LLAMA 3.1", "normalized_text": "meta s article with more details on the new llama 3 1", "model_tags": ["meta"], "aspect_hints": [], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "smusamashah", "node_time": "2024-07-23T17:07:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41048452, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "> Third, a key difference between Meta and closed model providers is that selling access to AI models isn’t our business model. That means openly releasing Llama doesn’t undercut our revenue, sustainability, or ability to invest in research like it does for closed providers. (This is one reason several closed providers consistently lobby governments against open source.) The whole thing is interesting, but this part strikes me as potentially anticompetitive reasoning. I wonder what the lines are that they have to avoid crossing here?", "normalized_text": "third a key difference between meta and closed model providers is that selling access to ai models isn’t our business model that means openly releasing llama doesn’t undercut our revenue sustainability or ability to invest in research like it does for closed providers this is one reason several closed providers consistently lobby governments against open source the whole thing is interesting but this part strikes me as potentially anticompetitive reasoning i wonder what the lines are that they have to avoid crossing here", "model_tags": ["meta"], "aspect_hints": ["business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "6gvONxR4sf7o", "node_time": "2024-07-23T17:11:46+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41048454, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Who knew FB would hold OpenAI's original ideals, and OpenAI now holds early FB ideals/integrity.", "normalized_text": "who knew fb would hold openai s original ideals and openai now holds early fb ideals integrity", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "frabjoused", "node_time": "2024-07-23T17:12:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41048477, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "I never thought I would say this but thanks Meta. *I reserve the right to remove this praise if they abuse this open source model position in the future.", "normalized_text": "i never thought i would say this but thanks meta i reserve the right to remove this praise if they abuse this open source model position in the future", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "jmward01", "node_time": "2024-07-23T17:14:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41048548, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "The \"open source\" part sounds nice, though we all know there's nothing particularly open about the models (or their weights). The barriers to entry remain the same - huge upfront investments to train your own, and steep ongoing costs for \"inference\". Is the vision here to treat LLM-based AI as a \"public good\", akin to a utility provider in a civilized country (taxpayer funded, govt maintained, non-for-profit)? I think we could arguably call this \"open source\" when all the infra blueprints, scripts and configs are freely available for anyone to try and duplicate the state-of-the-art (resource and grokking requirements nonwithstanding)", "normalized_text": "the open source part sounds nice though we all know there s nothing particularly open about the models or their weights the barriers to entry remain the same huge upfront investments to train your own and steep ongoing costs for inference is the vision here to treat llm based ai as a public good akin to a utility provider in a civilized country taxpayer funded govt maintained non for profit i think we could arguably call this open source when all the infra blueprints scripts and configs are freely available for anyone to try and duplicate the state of the art resource and grokking requirements nonwithstanding", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "btbuildem", "node_time": "2024-07-23T17:20:50+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41048563, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Open source \"AI\" is a proxy for democratising and making (much) more widely useful the goodies of high performance computing (HPC). The HPC domain (data and compute intensive applications that typically need vector, parallel or other such architectures) have been around for the longest time, but confined to academic / government tasks. LLM's with their famous \"matrix multiply\" at their very core are basically demolishing an ossified frontier where a few commercial entities (Intel, Microsoft, Apple, Google, Samsung etc) have defined for decades what computing looks like for most people . Assuming that the genie is out of the bottle, the question is: what is the shape of end-user devices that are optimally designed to use compute intensive open source algorithms? The \"AI PC\" is already a marketing gimmick, but could it be that Linux desktops and smartphones will suddenly be \"ΑΙ natives\"? For sure its a transformational period and the landscape T+10 yrs could be drastically different...", "normalized_text": "open source ai is a proxy for democratising and making much more widely useful the goodies of high performance computing hpc the hpc domain data and compute intensive applications that typically need vector parallel or other such architectures have been around for the longest time but confined to academic government tasks llm s with their famous matrix multiply at their very core are basically demolishing an ossified frontier where a few commercial entities intel microsoft apple google samsung etc have defined for decades what computing looks like for most people assuming that the genie is out of the bottle the question is what is the shape of end user devices that are optimally designed to use compute intensive open source algorithms the ai pc is already a marketing gimmick but could it be that linux desktops and smartphones will suddenly be αι natives for sure its a transformational period and the landscape t 10 yrs could be drastically different", "model_tags": ["google"], "aspect_hints": ["privacy", "usability_ux", "cost_price", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "openrisk", "node_time": "2024-07-23T17:22:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41048689, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "The FTC also recently put out a statement that is fairly pro-open source: I think it's interesting to think about this question of open source, benefits, risk, and even competition, without all of the baggage that Meta brings. I agree with the FTC, that the benefits of open-weight models are significant for competition. The challenge is in distinguishing between good competition and bad competition. Some kind of competition can harm consumers and critical public goods, including democracy itself. For example, competing for people's scarce attention or for their food buying, with increasingly optimized and addictive innovations. Or competition to build the most powerful biological weapons. Other kinds of competition can massively accelerate valuable innovation. The FTC must navigate a tricky balance here — leaning into competition that serves consumers and the broader public, while being careful about what kind of competition it is accelerating that could cause significant risk and harm. It's also obviously not just \"big tech\" that cares about the risks behind open-weight foundation models. Many people have written about these risks even before it became a subject of major tech investment. (In other words, A16Z's framing is often rather misleading.) There are many non-big tech actors who are very concerned about current and potential negative impacts of open-weight foundation models. One approach which can provide the best of both worlds, is for cases where there are significant potential risks, to ensure that there is at least some period of time where weights are not provided openly, in order to learn a bit about the potential implications of new models. Longer-term, there may be a line where models are too risky to share openly, and it may be unclear what that line is. In that case, it's important that we have governance systems for such decisions that are not just profit-driven, and which can help us continue to get the best of all worlds. (Plug: my organization, the AI & Democracy Foundation; is working to develop such systems and hiring.)", "normalized_text": "the ftc also recently put out a statement that is fairly pro open source i think it s interesting to think about this question of open source benefits risk and even competition without all of the baggage that meta brings i agree with the ftc that the benefits of open weight models are significant for competition the challenge is in distinguishing between good competition and bad competition some kind of competition can harm consumers and critical public goods including democracy itself for example competing for people s scarce attention or for their food buying with increasingly optimized and addictive innovations or competition to build the most powerful biological weapons other kinds of competition can massively accelerate valuable innovation the ftc must navigate a tricky balance here — leaning into competition that serves consumers and the broader public while being careful about what kind of competition it is accelerating that could cause significant risk and harm it s also obviously not just big tech that cares about the risks behind open weight foundation models many people have written about these risks even before it became a subject of major tech investment in other words a16z s framing is often rather misleading there are many non big tech actors who are very concerned about current and potential negative impacts of open weight foundation models one approach which can provide the best of both worlds is for cases where there are significant potential risks to ensure that there is at least some period of time where weights are not provided openly in order to learn a bit about the potential implications of new models longer term there may be a line where models are too risky to share openly and it may be unclear what that line is in that case it s important that we have governance systems for such decisions that are not just profit driven and which can help us continue to get the best of all worlds plug my organization the ai democracy foundation is working to develop such systems and hiring", "model_tags": [], "aspect_hints": ["performance_speed", "usability_ux", "ethics", "regulation_policy", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "avivo", "node_time": "2024-07-23T17:35:00+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41048906, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Related ongoing thread: Llama 3.1 - - July 2024 (114 comments)", "normalized_text": "related ongoing thread llama 3 1 july 2024 114 comments", "model_tags": ["meta"], "aspect_hints": [], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "dang", "node_time": "2024-07-23T17:56:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41049274, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Open source is a welcome step but what we really need is complete decentralisation so people can run their own private AI Models that keep all the data private to them. We need this to happen locally on laptops, mobile phones, smart devices etc. Waiting for when that will become ubiquitous.", "normalized_text": "open source is a welcome step but what we really need is complete decentralisation so people can run their own private ai models that keep all the data private to them we need this to happen locally on laptops mobile phones smart devices etc waiting for when that will become ubiquitous", "model_tags": [], "aspect_hints": ["privacy", "usability_ux"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "suyash", "node_time": "2024-07-23T18:32:51+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41049333, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Totally tangential thought, probably doomed to be lost in the flood of comments on this very interesting announcement. I was thinking today about Musk, Zuckerberg and Altman. Each claims that the next version of their big LLMs will be the best. For some reason it reminded me of one apocryphal cause of WW1, which was that the kings of Europe were locked in a kind of ego driven contest. It made me think about the Nation State as a technology. In some sense, the kings were employing the new technology which was clearly going to be the basis for the future political order. And they were pitting their own implementation of this new technology against the other kings. I feel we are seeing a similar clash of kings playing out. The claims that this is all just business or some larger claim about the good of humanity seem secondary to the ego stakes of the major players. And when it was about who built the biggest rocket, it felt less dangerous. It breaks my heart just a little bit. I feel sympathy in some sense for the AIs we will create, especially if they do reach the level of AGI. As another tortured analogy, it is like a bunch of competitive parents forcing their children into adversarial relationships to satisfy the parent's ego.", "normalized_text": "totally tangential thought probably doomed to be lost in the flood of comments on this very interesting announcement i was thinking today about musk zuckerberg and altman each claims that the next version of their big llms will be the best for some reason it reminded me of one apocryphal cause of ww1 which was that the kings of europe were locked in a kind of ego driven contest it made me think about the nation state as a technology in some sense the kings were employing the new technology which was clearly going to be the basis for the future political order and they were pitting their own implementation of this new technology against the other kings i feel we are seeing a similar clash of kings playing out the claims that this is all just business or some larger claim about the good of humanity seem secondary to the ego stakes of the major players and when it was about who built the biggest rocket it felt less dangerous it breaks my heart just a little bit i feel sympathy in some sense for the ais we will create especially if they do reach the level of agi as another tortured analogy it is like a bunch of competitive parents forcing their children into adversarial relationships to satisfy the parent s ego", "model_tags": [], "aspect_hints": ["usability_ux", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "zoogeny", "node_time": "2024-07-23T18:38:37+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41049362, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "They are positioning themselves as champions of AI open source mostly because they were blindsided by OpenAI, are not in the infra game, and want to commoditize their complements as much as possible. This is not altruism although it's still great for devs and startups. All FB GPU investments is primarily for new AI products \"friends\", recommendations and selling ads.", "normalized_text": "they are positioning themselves as champions of ai open source mostly because they were blindsided by openai are not in the infra game and want to commoditize their complements as much as possible this is not altruism although it s still great for devs and startups all fb gpu investments is primarily for new ai products friends recommendations and selling ads", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "light_triad", "node_time": "2024-07-23T18:40:46+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41049440, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "> My framework for understanding safety is that we need to protect against two categories of harm: unintentional and intentional. Unintentional harm is when an AI system may cause harm even when it was not the intent of those running it to do so. For example, modern AI models may inadvertently give bad health advice. Or, in more futuristic scenarios, some worry that models may unintentionally self-replicate or hyper-optimize goals to the detriment of humanity. Intentional harm is when a bad actor uses an AI model with the goal of causing harm. Okay then Mark. Replace \"modern AI models\" with \"social media\" and repeat this statement with a straight face.", "normalized_text": "my framework for understanding safety is that we need to protect against two categories of harm unintentional and intentional unintentional harm is when an ai system may cause harm even when it was not the intent of those running it to do so for example modern ai models may inadvertently give bad health advice or in more futuristic scenarios some worry that models may unintentionally self replicate or hyper optimize goals to the detriment of humanity intentional harm is when a bad actor uses an ai model with the goal of causing harm okay then mark replace modern ai models with social media and repeat this statement with a straight face", "model_tags": [], "aspect_hints": ["performance_speed", "ethics", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "anthomtb", "node_time": "2024-07-23T18:47:20+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41049488, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "> We need to protect our data. This is a very important concern in Health Care because of HIPAA compliance. You can't just send your data over the wire to someone's proprietary API. You would at least need to de-identify your data. This can be a tricky task, especially with unstructured text.", "normalized_text": "we need to protect our data this is a very important concern in health care because of hipaa compliance you can t just send your data over the wire to someone s proprietary api you would at least need to de identify your data this can be a tricky task especially with unstructured text", "model_tags": [], "aspect_hints": ["privacy", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "j_m_b", "node_time": "2024-07-23T18:52:18+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41049526, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Zuck needs to get real. They are Open Weights not Open Source.", "normalized_text": "zuck needs to get real they are open weights not open source", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "xpe", "node_time": "2024-07-23T18:56:52+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41049593, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "The real path forward is recognizing what AI is good at and what it is bad at. Focus on making what it is good at even better and faster. Open AI will definitely give us that option but it isn't a miracle worker. My impression is that AI if done correctly will be the new way to build APIs with large data sets and information. It can't write code unless you want to dump billions of dollars into a solution with millions of dollars of operational costs. As it stands it loses context too quickly to do advance human tasks. BUT this is where it is great at assembling data and information. You know what is great at assembling data and information? APIs. Think of it this way if we can make it faster and it trains on a datalake for a company it could be used to return information faster than a nested micro-service architecture that is just a spiderweb of dependencies. Because AI loses context simple API requests could actually be more efficient.", "normalized_text": "the real path forward is recognizing what ai is good at and what it is bad at focus on making what it is good at even better and faster open ai will definitely give us that option but it isn t a miracle worker my impression is that ai if done correctly will be the new way to build apis with large data sets and information it can t write code unless you want to dump billions of dollars into a solution with millions of dollars of operational costs as it stands it loses context too quickly to do advance human tasks but this is where it is great at assembling data and information you know what is great at assembling data and information apis think of it this way if we can make it faster and it trains on a datalake for a company it could be used to return information faster than a nested micro service architecture that is just a spiderweb of dependencies because ai loses context simple api requests could actually be more efficient", "model_tags": [], "aspect_hints": ["performance_speed", "accuracy_reliability", "privacy", "usability_ux", "cost_price", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "Sparkyte", "node_time": "2024-07-23T19:03:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41050363, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Software 2.0 is about open licensing. I.e., the more important thing - the more \"free\" thing - is the licensing now. E.g., I play around with different image diffusion models like Stable Diffusion and specific fine-tuned variations for ControlNet or LoRA that I plug into ComfyUI. But I can't use it at work because of the licensing. I have to use InvokeAI instead of ComfyUI if I want to be careful and only very specific image diffusion models without the latest and greatest fine-tuning. As others have said - the weights themselves are rather inscrutable. So we're building on more abstract shapes now. But the key open thing is making sure (1) the tools to modify the weights are open and permissive (ComfyUI, related scripts or parts of both the training and deployment) and (2) the underlying weights of the base models and the tools to recreate them have MIT or other generous licensing. As well as the fine-tuned variants for specific tasks. It's not going to be the naive construction in the future where you take a base model and as company A you produce company A's fine tuned model and you're done. It's going to be a tree of fine-tuned models as a node-based editor like ComfyUI already shows and that whole tree has to be open if we're to keep the same hacker spirit where anyone can tinker with it and also at some point make money off of it. Or go free software the whole way (i.e., LGPL or equivalent the whole tree of tools). In that sense unfortunately Llama has a ways to go to be truly open:", "normalized_text": "software 2 0 is about open licensing i e the more important thing the more free thing is the licensing now e g i play around with different image diffusion models like stable diffusion and specific fine tuned variations for controlnet or lora that i plug into comfyui but i can t use it at work because of the licensing i have to use invokeai instead of comfyui if i want to be careful and only very specific image diffusion models without the latest and greatest fine tuning as others have said the weights themselves are rather inscrutable so we re building on more abstract shapes now but the key open thing is making sure 1 the tools to modify the weights are open and permissive comfyui related scripts or parts of both the training and deployment and 2 the underlying weights of the base models and the tools to recreate them have mit or other generous licensing as well as the fine tuned variants for specific tasks it s not going to be the naive construction in the future where you take a base model and as company a you produce company a s fine tuned model and you re done it s going to be a tree of fine tuned models as a node based editor like comfyui already shows and that whole tree has to be open if we re to keep the same hacker spirit where anyone can tinker with it and also at some point make money off of it or go free software the whole way i e lgpl or equivalent the whole tree of tools in that sense unfortunately llama has a ways to go to be truly open", "model_tags": ["meta"], "aspect_hints": ["security", "usability_ux", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "tmsh", "node_time": "2024-07-23T20:19:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41050447, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Llama isn't open source. The license is at and includes various restrictions on use, which means it falls outside the rules created by the", "normalized_text": "llama isn t open source the license is at and includes various restrictions on use which means it falls outside the rules created by the", "model_tags": ["meta"], "aspect_hints": [], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "nailer", "node_time": "2024-07-23T20:28:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41050539, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Even if it's just open weights and not \"true\" open source, I'll still give Meta the appreciation of being one of the few big AI companies actually committed to open models. In an ecosystem where groups like Anthropic and OpenAI keep hemming and hawing about safety and the necessity of closed AI systems \"for our sake\", they stand out among the rest.", "normalized_text": "even if it s just open weights and not true open source i ll still give meta the appreciation of being one of the few big ai companies actually committed to open models in an ecosystem where groups like anthropic and openai keep hemming and hawing about safety and the necessity of closed ai systems for our sake they stand out among the rest", "model_tags": ["openai", "anthropic"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "war321", "node_time": "2024-07-23T20:37:20+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41051082, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Okay if anyone wants to try Llama 3.1 inference on CPU, try this: (L2E) It's a bit buggy but it is fun. Disclaimer: I am the author of L2E", "normalized_text": "okay if anyone wants to try llama 3 1 inference on cpu try this l2e it s a bit buggy but it is fun disclaimer i am the author of l2e", "model_tags": ["meta"], "aspect_hints": ["accuracy_reliability"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "AMICABoard", "node_time": "2024-07-23T21:25:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41051306, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "I've summarized this entire thread in 4 lines (didn't even use AI for it!) Step 1. Chick-Fil-A releases a grass-fed beef burger to spite other fast-food joints, calls it \"the vegan burger\" Step 2. A couple of outraged vegans show up in the comments, pointing out that beef, even grass-fed beef, isn't vegan Step 3. Fast food enthusiasts push back: it's unreasonable to want companies to abide by this restrictive definition of \"vegan\". Clearly this burger is a gamechanger and the definition needs to adapt to the times. Step 4. Goto Step 2 in an infinite loop", "normalized_text": "i ve summarized this entire thread in 4 lines didn t even use ai for it step 1 chick fil a releases a grass fed beef burger to spite other fast food joints calls it the vegan burger step 2 a couple of outraged vegans show up in the comments pointing out that beef even grass fed beef isn t vegan step 3 fast food enthusiasts push back it s unreasonable to want companies to abide by this restrictive definition of vegan clearly this burger is a gamechanger and the definition needs to adapt to the times step 4 goto step 2 in an infinite loop", "model_tags": [], "aspect_hints": ["performance_speed"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "sebastiennight", "node_time": "2024-07-23T21:48:26+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41051956, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "It'll be interesting to come back here in a couple of years and see what's left. What do they even do anymore? They have Facebook, which hasn't visibly changed in a decade. They have Instagram, which feels a bit sleeker but also remained more or less the same. and Whatsapp. Ad network that runs on top of those services and floods them with trash. Bunch of stuff that doesn't seem to exist anymore - Libra, the grandiose multibillion dollar Legless VR, etc. But they still have 70 thousand people (a small country) doing _something_. What are they doing? Updating Facebook UI? Not really, the UI hasn't been updated, and you don't need 70 thousand people to do that. Stuff like React and Llama? Good, I guess, we'll see how they make use of Llama in a couple of years. Spellcheck for posts maybe?", "normalized_text": "it ll be interesting to come back here in a couple of years and see what s left what do they even do anymore they have facebook which hasn t visibly changed in a decade they have instagram which feels a bit sleeker but also remained more or less the same and whatsapp ad network that runs on top of those services and floods them with trash bunch of stuff that doesn t seem to exist anymore libra the grandiose multibillion dollar legless vr etc but they still have 70 thousand people a small country doing something what are they doing updating facebook ui not really the ui hasn t been updated and you don t need 70 thousand people to do that stuff like react and llama good i guess we ll see how they make use of llama in a couple of years spellcheck for posts maybe", "model_tags": ["meta"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "twelve40", "node_time": "2024-07-23T23:06:25+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41052292, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "In general I look back on my time at FB with mixed feelings, I’m pretty skeptical that modern social media is a force for good and I was there early enough to have moved the needle. But this is really positive stuff and it’s nice to view my time there through the lens of such a change for the better. Keep up the good work on this folks. Time to start thinking about opening up a little on the training data.", "normalized_text": "in general i look back on my time at fb with mixed feelings i’m pretty skeptical that modern social media is a force for good and i was there early enough to have moved the needle but this is really positive stuff and it’s nice to view my time there through the lens of such a change for the better keep up the good work on this folks time to start thinking about opening up a little on the training data", "model_tags": [], "aspect_hints": ["privacy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "benreesman", "node_time": "2024-07-23T23:55:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41054007, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "When Zuck said spy can easily steal models, I wonder how much of it comes from experiences. I remember they struggled to train OPT not long ago. On a more serious note, I don't really buy his arguments about safety. First, widespread AI does not reduce unintentional harm but increases it, because the rate of accident is compound. Second, the chance of success for threat actors will increase, because of the asymmetric advantage of gaining access to all open information and hiding their own information. But there is no reverse at this point, I enjoy it while it lasts, AGI will come sooner or later anyway.", "normalized_text": "when zuck said spy can easily steal models i wonder how much of it comes from experiences i remember they struggled to train opt not long ago on a more serious note i don t really buy his arguments about safety first widespread ai does not reduce unintentional harm but increases it because the rate of accident is compound second the chance of success for threat actors will increase because of the asymmetric advantage of gaining access to all open information and hiding their own information but there is no reverse at this point i enjoy it while it lasts agi will come sooner or later anyway", "model_tags": [], "aspect_hints": ["usability_ux", "ethics", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "thntk", "node_time": "2024-07-24T05:59:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41054048, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "I thoroughly support Meta's open-sourcing of these AI models going forward. However, for a company that absolutely closed down discussions about providing API access to their platform, I'm left wondering what's in it (monetarily) for them by doing this? Is it to simply undercut competition in the space, like some grocery store selling below cost?", "normalized_text": "i thoroughly support meta s open sourcing of these ai models going forward however for a company that absolutely closed down discussions about providing api access to their platform i m left wondering what s in it monetarily for them by doing this is it to simply undercut competition in the space like some grocery store selling below cost", "model_tags": [], "aspect_hints": ["cost_price", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "Simon_ORourke", "node_time": "2024-07-24T06:08:53+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41054173, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Interesting discussion! While I agree with Zuckerberg's vision, the comments raise valid concerns. The point about GPU accessibility and cost is crucial. Public clusters are great, but sustainable funding and equitable access are essential to avoid exacerbating existing inequalities. I also resonate with the call for CUDA alternatives. Breaking the dependence on proprietary technology is key for a truly open AI ecosystem. While existing research clusters offer some access, their scope and resources often pale in comparison to what companies like Meta are proposing. We need a multi-pronged approach: open-sourcing models AND investing in accessible infrastructure, diverse hardware options, and sustainable funding models for a truly democratic AI future.", "normalized_text": "interesting discussion while i agree with zuckerberg s vision the comments raise valid concerns the point about gpu accessibility and cost is crucial public clusters are great but sustainable funding and equitable access are essential to avoid exacerbating existing inequalities i also resonate with the call for cuda alternatives breaking the dependence on proprietary technology is key for a truly open ai ecosystem while existing research clusters offer some access their scope and resources often pale in comparison to what companies like meta are proposing we need a multi pronged approach open sourcing models and investing in accessible infrastructure diverse hardware options and sustainable funding models for a truly democratic ai future", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "msnkarthik", "node_time": "2024-07-24T06:32:42+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41054633, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "this is very cool indeed that meta has made available more than they need to in terms of model weights . however, the \"open-source\" narrative is being pushed a bit too much like descriptive ML models were called \"AI\", or applied statistics \"data science\". with reinforced examples such as this, we start to lose the original meaning of the term. the current approach of startups or small players \"open-sourcing\" their platforms and tools as a means to promote network effect works but is harmful in the long run. you will find examples of terraform and red hat happening, and a very segmented market. if you want the true spirit of open-source, there must be a way to replicate the weights through access to training data and code. whether one could afford millions of GPU hours or not, real innovation would come from remixing the internals, and not just fine-tuning existing stuff. i understand that this is not realistically going to ever happen, but don't perform deceptive marketing at the same time.", "normalized_text": "this is very cool indeed that meta has made available more than they need to in terms of model weights however the open source narrative is being pushed a bit too much like descriptive ml models were called ai or applied statistics data science with reinforced examples such as this we start to lose the original meaning of the term the current approach of startups or small players open sourcing their platforms and tools as a means to promote network effect works but is harmful in the long run you will find examples of terraform and red hat happening and a very segmented market if you want the true spirit of open source there must be a way to replicate the weights through access to training data and code whether one could afford millions of gpu hours or not real innovation would come from remixing the internals and not just fine tuning existing stuff i understand that this is not realistically going to ever happen but don t perform deceptive marketing at the same time", "model_tags": [], "aspect_hints": ["privacy", "ethics", "business_model"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "rldjbpin", "node_time": "2024-07-24T08:01:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41054918, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Meanwhile Facebook is flooded with AI-generated slop with hundreds of thousands of other bots interacting with it to boost it to whoever is insane enough to still use that putrid hellhole of a mass-data-harvesting platform. Dead internet theory is very much happening in real time, and I dread what's about to come since the world has collectively decided to lose their minds with this AI crap. And people on this site are unironically excited about this garbage that is indistinguishable from spam getting more and more popular. What a fucking joke", "normalized_text": "meanwhile facebook is flooded with ai generated slop with hundreds of thousands of other bots interacting with it to boost it to whoever is insane enough to still use that putrid hellhole of a mass data harvesting platform dead internet theory is very much happening in real time and i dread what s about to come since the world has collectively decided to lose their minds with this ai crap and people on this site are unironically excited about this garbage that is indistinguishable from spam getting more and more popular what a fucking joke", "model_tags": ["meta"], "aspect_hints": ["privacy", "usability_ux", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "sensanaty", "node_time": "2024-07-24T08:46:14+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41055147, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "I think all this discussion around Open-source AI is a total distraction from the elephants in the room. Let's list what you need to run/play around with something like Llama: 1. Software: this is all Pytorch/HF, so completely open-source. This is total parity between what corporates have and what the public has. 2. Model weights: Meta and a few other orgs release open models - as opposed to OpenAI's closed models. So, ok, we have something to work with. 3. Data: to actually do anything useful you need tons of data. This is beyond the reach of the ordinary man, setting aside the legality issues. 4. Hardware: GPUs, which are extremely expensive. Not just that, even if you have the top dollars, you have to go stand in a queue and wait for O(months), since mega-corporates have gotten there before you. For Inference, you need 1,2 and 4. For training (or fine-tuning), you need all of these. With newer and larger models like the latest Llama, 4 is truly beyond the reach of ordinary entities. This is NOTHING like open-source, where a random guy can edit/recompile/deploy software on a commodity computer. Wrt LLMs, Data/Hardware are in the equation, the playing field is complete stacked. This thread has a bunch of people discussing nuances of 1 and 2, but this bike-shedding only hides the basic point: Control of LLMs are for mega-corps, not for individuals.", "normalized_text": "i think all this discussion around open source ai is a total distraction from the elephants in the room let s list what you need to run play around with something like llama 1 software this is all pytorch hf so completely open source this is total parity between what corporates have and what the public has 2 model weights meta and a few other orgs release open models as opposed to openai s closed models so ok we have something to work with 3 data to actually do anything useful you need tons of data this is beyond the reach of the ordinary man setting aside the legality issues 4 hardware gpus which are extremely expensive not just that even if you have the top dollars you have to go stand in a queue and wait for o months since mega corporates have gotten there before you for inference you need 1 2 and 4 for training or fine tuning you need all of these with newer and larger models like the latest llama 4 is truly beyond the reach of ordinary entities this is nothing like open source where a random guy can edit recompile deploy software on a commodity computer wrt llms data hardware are in the equation the playing field is complete stacked this thread has a bunch of people discussing nuances of 1 and 2 but this bike shedding only hides the basic point control of llms are for mega corps not for individuals", "model_tags": ["openai", "meta"], "aspect_hints": ["privacy", "cost_price", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "ChanderG", "node_time": "2024-07-24T09:24:01+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41055701, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "I wish Meta stopped using the \"open source\" misnomer for free of charge weights. In the US the FTC already uses the term Open-Weights , and it seems the industry is also adopting this term (e.g. Mistral). Someone can correct me here but AFAIK we don't even know which datasets are used to train these models, so why should we even use \"open\" to describe Llama? This is more similar to a freeware than an open-source project. [1]", "normalized_text": "i wish meta stopped using the open source misnomer for free of charge weights in the us the ftc already uses the term open weights and it seems the industry is also adopting this term e g mistral someone can correct me here but afaik we don t even know which datasets are used to train these models so why should we even use open to describe llama this is more similar to a freeware than an open source project 1", "model_tags": ["meta", "mistral"], "aspect_hints": ["accuracy_reliability", "privacy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "pera", "node_time": "2024-07-24T11:06:48+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41057408, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "Additional Commercial Terms. If, on the Llama 3.1 version release date, the monthly active users of the products or services made available by or for Licensee, or Licensee’s affiliates, is greater than 700 million monthly active users in the preceding calendar month, you must request a license from Meta, which Meta may grant to you in its sole discretion, and you are not authorized to exercise any of the rights under this Agreement unless or until Meta otherwise expressly grants you such rights. Which open-source has such restrictions and clause?", "normalized_text": "additional commercial terms if on the llama 3 1 version release date the monthly active users of the products or services made available by or for licensee or licensee’s affiliates is greater than 700 million monthly active users in the preceding calendar month you must request a license from meta which meta may grant to you in its sole discretion and you are not authorized to exercise any of the rights under this agreement unless or until meta otherwise expressly grants you such rights which open source has such restrictions and clause", "model_tags": ["meta"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "ssahoo", "node_time": "2024-07-24T14:22:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41057419, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "I'm really unsure if it's a good idea given the current geopolitics. Open-Source Code in the past was fantastic because the West had a monopoly on CPUs and computers. Sharing and contributing was amazing while ensured that tyrants couldn't use this tech to harm people simply because they don't have a hardware to run. But now, things are different. China is advancing in chip technology, and Russia is using open-source AI to harm people on the scale today, with auto-targeting drones being just the start. Red sea conflict etc. And somehow, Zuckerberg keeps finding ways to mess up people's lives, despite having the best intentions. Right now you can build a semi-autonomous drone with AI to kill people for ~$500-700. The western world will still use safe and secure commercial models. While new axis of evil will use models based on Meta or any other open source to do whatever harm they can imagine with not a hint of control. This particular model. Fine-tune it to develop a nuclear bomb using all possible research that level of government can get on the scale. Killing drone swarms etc. Once the knowledge got public these models can be a base model to get expert-level knowledge to anyone who wants it, uncensored. Especially if you are government that wants to destroy a peaceful order for whatever reason.", "normalized_text": "i m really unsure if it s a good idea given the current geopolitics open source code in the past was fantastic because the west had a monopoly on cpus and computers sharing and contributing was amazing while ensured that tyrants couldn t use this tech to harm people simply because they don t have a hardware to run but now things are different china is advancing in chip technology and russia is using open source ai to harm people on the scale today with auto targeting drones being just the start red sea conflict etc and somehow zuckerberg keeps finding ways to mess up people s lives despite having the best intentions right now you can build a semi autonomous drone with ai to kill people for 500 700 the western world will still use safe and secure commercial models while new axis of evil will use models based on meta or any other open source to do whatever harm they can imagine with not a hint of control this particular model fine tune it to develop a nuclear bomb using all possible research that level of government can get on the scale killing drone swarms etc once the knowledge got public these models can be a base model to get expert level knowledge to anyone who wants it uncensored especially if you are government that wants to destroy a peaceful order for whatever reason", "model_tags": [], "aspect_hints": ["usability_ux", "ethics"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "maxdo", "node_time": "2024-07-24T14:23:36+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 41057860, "root_story_id": 41046773, "node_type": "comment", "comment_depth": 1, "text": "The question is what is \"open source\" in the case of a matrix of numbers, as opposed to code. Also, are there any \"IP\" rights attached at all to a bunch numbers coming out of a formula that someone else calculated for you? (edit: after all, a \"model\" is just a matrix of numbers coming out of running a training algorithm that is not owned by Meta over training data that is not owned by Meta.) Meta imposes a notification duty AND a request for another license (no mention of the details of these) for applications of their model with a large number of users. This is against the spirit of open source. (In practical terms it is not a show stopper since you can easily switch models, although they all have subtlely different behaviours and quality levels.)", "normalized_text": "the question is what is open source in the case of a matrix of numbers as opposed to code also are there any ip rights attached at all to a bunch numbers coming out of a formula that someone else calculated for you edit after all a model is just a matrix of numbers coming out of running a training algorithm that is not owned by meta over training data that is not owned by meta meta imposes a notification duty and a request for another license no mention of the details of these for applications of their model with a large number of users this is against the spirit of open source in practical terms it is not a show stopper since you can easily switch models although they all have subtlely different behaviours and quality levels", "model_tags": [], "aspect_hints": ["privacy", "regulation_policy"], "context": {"root_title": "Open source AI is the path forward", "root_author": "atgctg", "root_url": "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/", "node_author": "jll29", "node_time": "2024-07-24T15:08:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473419, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Congratulations to Francois Chollet on making the most interesting and challenging LLM benchmark so far. A lot of people have criticized ARC as not being relevant or indicative of true reasoning, but I think it was exactly the right thing. The fact that scaled reasoning models are finally showing progress on ARC proves that what it measures really is relevant and important for reasoning. It's obvious to everyone that these models can't perform as well as humans on everyday tasks despite blowout scores on the hardest tests we give to humans. Yet nobody could quantify exactly the ways the models were deficient. ARC is the best effort in that direction so far. We don't need more \"hard\" benchmarks. What we need right now are \"easy\" benchmarks that these models nevertheless fail. I hope Francois has something good cooked up for ARC 2!", "normalized_text": "congratulations to francois chollet on making the most interesting and challenging llm benchmark so far a lot of people have criticized arc as not being relevant or indicative of true reasoning but i think it was exactly the right thing the fact that scaled reasoning models are finally showing progress on arc proves that what it measures really is relevant and important for reasoning it s obvious to everyone that these models can t perform as well as humans on everyday tasks despite blowout scores on the hardest tests we give to humans yet nobody could quantify exactly the ways the models were deficient arc is the best effort in that direction so far we don t need more hard benchmarks what we need right now are easy benchmarks that these models nevertheless fail i hope francois has something good cooked up for arc 2", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "modeless", "node_time": "2024-12-20T18:22:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473442, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "My initial impression: it's very impressive and very exciting. My skeptical impression: it's complete hubris to conflate ARC or any benchmark with truly general intelligence. I know my skepticism here is identical to moving goalposts. More and more I am shifting my personal understanding of general intelligence as a phenomenon we will only ever be able to identify with the benefit of substantial retrospect. As it is with any sufficiently complex program, if you could discern the result beforehand, you wouldn't have had to execute the program in the first place. I'm not trying to be a downer on the 12th day of Christmas. Perhaps because my first instinct is childlike excitement, I'm trying to temper it with a little reason.", "normalized_text": "my initial impression it s very impressive and very exciting my skeptical impression it s complete hubris to conflate arc or any benchmark with truly general intelligence i know my skepticism here is identical to moving goalposts more and more i am shifting my personal understanding of general intelligence as a phenomenon we will only ever be able to identify with the benefit of substantial retrospect as it is with any sufficiently complex program if you could discern the result beforehand you wouldn t have had to execute the program in the first place i m not trying to be a downer on the 12th day of christmas perhaps because my first instinct is childlike excitement i m trying to temper it with a little reason", "model_tags": [], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "zebomon", "node_time": "2024-12-20T18:25:24+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473446, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Isn't this at the level now where it can sort of self improve. My guess is that they will just use it to improve the model and the cost they are showing per evaluation will go down drastically. So, next step in reasoning is open world reasoning now?", "normalized_text": "isn t this at the level now where it can sort of self improve my guess is that they will just use it to improve the model and the cost they are showing per evaluation will go down drastically so next step in reasoning is open world reasoning now", "model_tags": [], "aspect_hints": ["cost_price"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "attentionmech", "node_time": "2024-12-20T18:26:01+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473456, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "O3 High (tuned) model scored an 88% at what looks like $6,000/task haha I think soon we'll be pricing any kind of tasks by their compute costs. So basically, human = $50/task, AI = $6,000/task, use human. If AI beats human, use AI? Ofc that's considering both get 100% scores on the task", "normalized_text": "o3 high tuned model scored an 88 at what looks like 6 000 task haha i think soon we ll be pricing any kind of tasks by their compute costs so basically human 50 task ai 6 000 task use human if ai beats human use ai ofc that s considering both get 100 scores on the task", "model_tags": ["openai"], "aspect_hints": ["cost_price"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "yawnxyz", "node_time": "2024-12-20T18:27:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473475, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Just as an aside, I've personally found o1 to be completely useless for coding. Sonnet 3.5 remains the king of the hill by quite some margin", "normalized_text": "just as an aside i ve personally found o1 to be completely useless for coding sonnet 3 5 remains the king of the hill by quite some margin", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "spaceman_2020", "node_time": "2024-12-20T18:29:20+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473477, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "It seems O3 following trend of Chess engine that you can cut your search depth depends on state. It's good for games with clear signal of success (Win/Lose for Chess, tests for programming). One of the blocker for AGI is we don't have clear evaluation for most of our tasks and we cannot verify them fast enough.", "normalized_text": "it seems o3 following trend of chess engine that you can cut your search depth depends on state it s good for games with clear signal of success win lose for chess tests for programming one of the blocker for agi is we don t have clear evaluation for most of our tasks and we cannot verify them fast enough", "model_tags": ["openai"], "aspect_hints": ["performance_speed"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "smy20011", "node_time": "2024-12-20T18:29:32+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473483, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "The cost axis is interesting. O3 Low is $10+ per task and 03 High is over $1000 (it's logarithmic graph so it's like $50 and $5000 respectively?)", "normalized_text": "the cost axis is interesting o3 low is 10 per task and 03 high is over 1000 it s logarithmic graph so it s like 50 and 5000 respectively", "model_tags": ["openai"], "aspect_hints": ["cost_price"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "flakiness", "node_time": "2024-12-20T18:30:50+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473497, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Human performance is 85% [1]. o3 high gets 87.5%. This means we have an algorithm to get to human level performance on this task. If you think this task is an eval of general reasoning ability, we have an algorithm for that now. There's a lot of work ahead to generalize o3 performance to all domains. I think this explains why many researchers feel AGI is within reach, now that we have an algorithm that works. Congrats to both Francois Chollet for developing this compelling eval, and to the researchers who saturated it! [1] ,", "normalized_text": "human performance is 85 1 o3 high gets 87 5 this means we have an algorithm to get to human level performance on this task if you think this task is an eval of general reasoning ability we have an algorithm for that now there s a lot of work ahead to generalize o3 performance to all domains i think this explains why many researchers feel agi is within reach now that we have an algorithm that works congrats to both francois chollet for developing this compelling eval and to the researchers who saturated it 1", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "obblekk", "node_time": "2024-12-20T18:31:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473525, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Whenever a benchmark that was thought to be extremely difficult is (nearly) solved, it's a mix of two causes. One is that progress on AI capabilities was faster than we expected, and the other is that there was an approach that made the task easier than we expected. I feel like the there's a lot of the former here, but the compute cost per task (thousands of dollars to solve one little color grid puzzle??) suggests to me that there's some amount of the latter. Chollet also mentions ARC-AGI-2 might be more resistant to this approach. Of course, o3 looks strong on other benchmarks as well, and sometimes \"spend a huge amount of compute for one problem\" is a great feature to have available if it gets you the answer you needed. So even if there's some amount of \"ARC-AGI wasn't quite as robust as we thought\", o3 is clearly a very powerful model.", "normalized_text": "whenever a benchmark that was thought to be extremely difficult is nearly solved it s a mix of two causes one is that progress on ai capabilities was faster than we expected and the other is that there was an approach that made the task easier than we expected i feel like the there s a lot of the former here but the compute cost per task thousands of dollars to solve one little color grid puzzle suggests to me that there s some amount of the latter chollet also mentions arc agi 2 might be more resistant to this approach of course o3 looks strong on other benchmarks as well and sometimes spend a huge amount of compute for one problem is a great feature to have available if it gets you the answer you needed so even if there s some amount of arc agi wasn t quite as robust as we thought o3 is clearly a very powerful model", "model_tags": ["openai"], "aspect_hints": ["performance_speed", "usability_ux", "cost_price"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "Imnimo", "node_time": "2024-12-20T18:33:39+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473563, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "The general message here seems to be that inference-time brute-forcing works as long as you have a good search and evaluation strategy. We’ve seemingly hit a ceiling on the base LLM forward-pass capability so any further wins are going to be in how we juggle multiple inferences to solve the problem space. It feels like a scripting problem now. Which is cool! A fun space for hacker-engineers. Also: > My mental model for LLMs is that they work as a repository of vector programs. When prompted, they will fetch the program that your prompt maps to and \"execute\" it on the input at hand. LLMs are a way to store and operationalize millions of useful mini-programs via passive exposure to human-generated content. I found this such an intriguing way of thinking about it.", "normalized_text": "the general message here seems to be that inference time brute forcing works as long as you have a good search and evaluation strategy we’ve seemingly hit a ceiling on the base llm forward pass capability so any further wins are going to be in how we juggle multiple inferences to solve the problem space it feels like a scripting problem now which is cool a fun space for hacker engineers also my mental model for llms is that they work as a repository of vector programs when prompted they will fetch the program that your prompt maps to and execute it on the input at hand llms are a way to store and operationalize millions of useful mini programs via passive exposure to human generated content i found this such an intriguing way of thinking about it", "model_tags": [], "aspect_hints": ["security", "usability_ux"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "whoistraitor", "node_time": "2024-12-20T18:37:42+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473669, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "The programming task they gave o3-mini high (creating Python server that allows chatting with OpenAI API and run some code in terminal) didn't seem very hard? Strange choice of example for something that's claimed to be a big step forwards. YT timestamped link: (thanks for the fixed link @photonboom) Updated: I gave the task to Claude 3.5 Sonnet and it worked first shot:", "normalized_text": "the programming task they gave o3 mini high creating python server that allows chatting with openai api and run some code in terminal didn t seem very hard strange choice of example for something that s claimed to be a big step forwards yt timestamped link thanks for the fixed link photonboom updated i gave the task to claude 3 5 sonnet and it worked first shot", "model_tags": ["openai", "anthropic"], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "croemer", "node_time": "2024-12-20T18:46:05+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473709, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "I was impressed until I read the caveat about the high-compute version using 172x more compute. Assuming for a moment that the cost per task has a linear relationship with compute, then it costs a little more than $1 million to get that score on the public eval. The results are cool, but man, this sounds like such a busted approach.", "normalized_text": "i was impressed until i read the caveat about the high compute version using 172x more compute assuming for a moment that the cost per task has a linear relationship with compute then it costs a little more than 1 million to get that score on the public eval the results are cool but man this sounds like such a busted approach", "model_tags": [], "aspect_hints": ["cost_price"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "Bjorkbat", "node_time": "2024-12-20T18:51:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473710, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "In (1) the author use a technique to improve the performance of an LLM, he trained sonnet 3.5 to obtain 53,6% in the arc-agi-pub benchmark moreover he said that more computer power would give better results. So the results of o3 could be produced in this way using the same method with more computer power, so if this is the case the result of o3 is not very interesting. (1)", "normalized_text": "in 1 the author use a technique to improve the performance of an llm he trained sonnet 3 5 to obtain 53 6 in the arc agi pub benchmark moreover he said that more computer power would give better results so the results of o3 could be produced in this way using the same method with more computer power so if this is the case the result of o3 is not very interesting 1", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "onemetwo", "node_time": "2024-12-20T18:51:17+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473810, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Let me go against some skeptics and explain why I think full o3 is pretty much AGI or at least embodies most essential aspects of AGI. What has been lacking so far in frontier LLMs is the ability to reliably deal with the right level of abstraction for a given problem. Reasoning is useful but often comes out lacking if one cannot reason at the right level of abstraction. (Note that many humans can't either when they deal with unfamiliar domains, although that is not the case with these models.) ARC has been challenging precisely because solving its problems often requires: 1) using multiple different *kinds* of core knowledge [1], such as symmetry, counting, color, AND 2) using the right level(s) of abstraction Achieving human-level performance in the ARC benchmark, as well as top human performance in GPQA, Codeforces, AIME, and Frontier Math suggests the model can potentially solve any problem at the human level if it possesses essential knowledge about it. Yes, this includes out-of-distribution problems that most humans can solve. It might not yet be able to generate highly novel theories, frameworks, or artifacts to the degree that Einstein, Grothendieck, or van Gogh could. But not many humans can either. [1] ADDED: Thanks to the link to Chollet's posts by lswainemoore below. I've analyzed some easy problems that o3 failed at. They involve spatial intelligence, including connection and movement. This skill is very hard to learn from textual and still image data. I believe this sort of core knowledge is learnable through movement and interaction data in a simulated world and it will not present a very difficult barrier to cross. (OpenAI purchased a company behind a Minecraft clone a while ago. I've wondered if this is the purpose.)", "normalized_text": "let me go against some skeptics and explain why i think full o3 is pretty much agi or at least embodies most essential aspects of agi what has been lacking so far in frontier llms is the ability to reliably deal with the right level of abstraction for a given problem reasoning is useful but often comes out lacking if one cannot reason at the right level of abstraction note that many humans can t either when they deal with unfamiliar domains although that is not the case with these models arc has been challenging precisely because solving its problems often requires 1 using multiple different kinds of core knowledge 1 such as symmetry counting color and 2 using the right level s of abstraction achieving human level performance in the arc benchmark as well as top human performance in gpqa codeforces aime and frontier math suggests the model can potentially solve any problem at the human level if it possesses essential knowledge about it yes this includes out of distribution problems that most humans can solve it might not yet be able to generate highly novel theories frameworks or artifacts to the degree that einstein grothendieck or van gogh could but not many humans can either 1 added thanks to the link to chollet s posts by lswainemoore below i ve analyzed some easy problems that o3 failed at they involve spatial intelligence including connection and movement this skill is very hard to learn from textual and still image data i believe this sort of core knowledge is learnable through movement and interaction data in a simulated world and it will not present a very difficult barrier to cross openai purchased a company behind a minecraft clone a while ago i ve wondered if this is the purpose", "model_tags": ["openai"], "aspect_hints": ["privacy", "usability_ux", "cost_price", "regulation_policy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "nopinsight", "node_time": "2024-12-20T19:01:04+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473873, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "It sucks that I would love to be excited about this... but I mostly feel anxiety and sadness.", "normalized_text": "it sucks that i would love to be excited about this but i mostly feel anxiety and sadness", "model_tags": [], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "RivieraKid", "node_time": "2024-12-20T19:07:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473876, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Efficiency is now key. ~=$3400 per single task to meet human performance on this benchmark is a lot. Also it shows the bullets as \"ARC-AGI-TUNED\", which makes me think they did some undisclosed amount of fine-tuning (eg. via the API they showed off last week), so even more compute went into this task. We can compare this roughly to a human doing ARC-AGI puzzles, where a human will take (high variance in my subjective experience) between 5 second and 5 minutes to solve the task. (So i'd argue a human is at 0.03USD - 1.67USD per puzzle at 20USD/hr, and they include in their document an average mechancal turker at $2 USD task in their document) Going the other direction: I am interpreting this result as human level reasoning now costs (approximately) 41k/hr to 2.5M/hr with current compute. Super exciting that OpenAI pushed the compute out this far so we could see he O-series scaling continue and intersect humans on ARC, now we get to work towards making this economical!", "normalized_text": "efficiency is now key 3400 per single task to meet human performance on this benchmark is a lot also it shows the bullets as arc agi tuned which makes me think they did some undisclosed amount of fine tuning eg via the api they showed off last week so even more compute went into this task we can compare this roughly to a human doing arc agi puzzles where a human will take high variance in my subjective experience between 5 second and 5 minutes to solve the task so i d argue a human is at 0 03usd 1 67usd per puzzle at 20usd hr and they include in their document an average mechancal turker at 2 usd task in their document going the other direction i am interpreting this result as human level reasoning now costs approximately 41k hr to 2 5m hr with current compute super exciting that openai pushed the compute out this far so we could see he o series scaling continue and intersect humans on arc now we get to work towards making this economical", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "cost_price"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "bluecoconut", "node_time": "2024-12-20T19:07:34+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473883, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "I would like to see this repeated with my highly innovative HARC-HAGI, which is ARC-AGI but it uses hexagons instead of squares. I suspect humans would only make slightly more brain farts on HARC-HAGI than ARC-AGI, but O3 would fail very badly since it almost certainly has been specifically trained on squares. I am not really trying to downplay O3. But this would be a simple test as to whether O3 is truly \"a system capable of adapting to tasks it has never encountered before\" versus novel ARC-AGI tasks it hasn't encountered before.", "normalized_text": "i would like to see this repeated with my highly innovative harc hagi which is arc agi but it uses hexagons instead of squares i suspect humans would only make slightly more brain farts on harc hagi than arc agi but o3 would fail very badly since it almost certainly has been specifically trained on squares i am not really trying to downplay o3 but this would be a simple test as to whether o3 is truly a system capable of adapting to tasks it has never encountered before versus novel arc agi tasks it hasn t encountered before", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "aithrowawaycomm", "node_time": "2024-12-20T19:07:54+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473891, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "The LLM community has come up with tests they call 'Misguided Attention'[1] where they prompt the LLM with a slightly altered version of common riddles / tests etc. This often causes the LLM to fail. For example I used the prompt \"As an astronaut in China, would I be able to see the great wall?\" and since the training data for all LLMs is full of text dispelling the common myth that the great wall is visible from space, LLMs do not notice the slight variation that the astronaut is IN China. This has been a sobering reminder to me as discussion of AGI heats up. [1]", "normalized_text": "the llm community has come up with tests they call misguided attention 1 where they prompt the llm with a slightly altered version of common riddles tests etc this often causes the llm to fail for example i used the prompt as an astronaut in china would i be able to see the great wall and since the training data for all llms is full of text dispelling the common myth that the great wall is visible from space llms do not notice the slight variation that the astronaut is in china this has been a sobering reminder to me as discussion of agi heats up 1", "model_tags": [], "aspect_hints": ["privacy", "usability_ux", "community_tone"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "botro", "node_time": "2024-12-20T19:08:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42473976, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "OpenAI spent approximately $1,503,077 to smash the SOTA on ARC-AGI with their new o3 model semi-private evals (100 tasks): 75.7% @ $2,012 total/100 tasks (~$20/task) with just 6 samples & 33M tokens processed in ~1.3 min/task and a cost of $2012 The “low-efficiency” setting with 1024 samples scored 87.5% but required 172x more compute. If we assume compute spent and cost are proportional, then OpenAI might have just spent ~$346.064 for the low efficiency run on the semi-private eval. On the public eval they might have spent ~$1.148.444 to achieve 91.5% with the low efficiency setting. (high-efficiency mode: $6677) OpenAI just spent more money to run an eval on ARC than most people spend on a full training run.", "normalized_text": "openai spent approximately 1 503 077 to smash the sota on arc agi with their new o3 model semi private evals 100 tasks 75 7 2 012 total 100 tasks 20 task with just 6 samples 33m tokens processed in 1 3 min task and a cost of 2012 the “low efficiency” setting with 1024 samples scored 87 5 but required 172x more compute if we assume compute spent and cost are proportional then openai might have just spent 346 064 for the low efficiency run on the semi private eval on the public eval they might have spent 1 148 444 to achieve 91 5 with the low efficiency setting high efficiency mode 6677 openai just spent more money to run an eval on arc than most people spend on a full training run", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "cost_price"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "neuroelectron", "node_time": "2024-12-20T19:16:18+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42474032, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Direct quote from the ARC-AGI blog: “SO IS IT AGI? ARC-AGI serves as a critical benchmark for detecting such breakthroughs, highlighting generalization power in a way that saturated or less demanding benchmarks cannot. However, it is important to note that ARC-AGI is not an acid test for AGI – as we've repeated dozens of times this year. It's a research tool designed to focus attention on the most challenging unsolved problems in AI, a role it has fulfilled well over the past five years. Passing ARC-AGI does not equate achieving AGI, and, as a matter of fact, I don't think o3 is AGI yet. o3 still fails on some very easy tasks, indicating fundamental differences with human intelligence. Furthermore, early data points suggest that the upcoming ARC-AGI-2 benchmark will still pose a significant challenge to o3, potentially reducing its score to under 30% even at high compute (while a smart human would still be able to score over 95% with no training). This demonstrates the continued possibility of creating challenging, unsaturated benchmarks without having to rely on expert domain knowledge. You'll know AGI is here when the exercise of creating tasks that are easy for regular humans but hard for AI becomes simply impossible.” The high compute variant sounds like it costed around *$350,000* which is kinda wild. Lol the blog post specifically mentioned how OpenAPI asked ARC-AGI to not disclose the exact cost for the high compute version. Also, 1 odd thing I noticed is that the graph in their blog post shows the top 2 scores as “tuned” (this was not displayed in the live demo graph). This suggest in those cases that the model was trained to better handle these types of questions, so I do wonder about data / answer contamination in those cases…", "normalized_text": "direct quote from the arc agi blog “so is it agi arc agi serves as a critical benchmark for detecting such breakthroughs highlighting generalization power in a way that saturated or less demanding benchmarks cannot however it is important to note that arc agi is not an acid test for agi – as we ve repeated dozens of times this year it s a research tool designed to focus attention on the most challenging unsolved problems in ai a role it has fulfilled well over the past five years passing arc agi does not equate achieving agi and as a matter of fact i don t think o3 is agi yet o3 still fails on some very easy tasks indicating fundamental differences with human intelligence furthermore early data points suggest that the upcoming arc agi 2 benchmark will still pose a significant challenge to o3 potentially reducing its score to under 30 even at high compute while a smart human would still be able to score over 95 with no training this demonstrates the continued possibility of creating challenging unsaturated benchmarks without having to rely on expert domain knowledge you ll know agi is here when the exercise of creating tasks that are easy for regular humans but hard for ai becomes simply impossible ” the high compute variant sounds like it costed around 350 000 which is kinda wild lol the blog post specifically mentioned how openapi asked arc agi to not disclose the exact cost for the high compute version also 1 odd thing i noticed is that the graph in their blog post shows the top 2 scores as “tuned” this was not displayed in the live demo graph this suggest in those cases that the model was trained to better handle these types of questions so i do wonder about data answer contamination in those cases…", "model_tags": ["openai"], "aspect_hints": ["privacy", "cost_price", "regulation_policy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "phil917", "node_time": "2024-12-20T19:21:43+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42474068, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "As an aside, I'm a little miffed that the benchmark calls out \"AGI\" in the name, but then heavily cautions that it's necessary but insufficient for AGI. > ARC-AGI serves as a critical benchmark for detecting such breakthroughs, highlighting generalization power in a way that saturated or less demanding benchmarks cannot. However, it is important to note that ARC-AGI is not an acid test for AGI", "normalized_text": "as an aside i m a little miffed that the benchmark calls out agi in the name but then heavily cautions that it s necessary but insufficient for agi arc agi serves as a critical benchmark for detecting such breakthroughs highlighting generalization power in a way that saturated or less demanding benchmarks cannot however it is important to note that arc agi is not an acid test for agi", "model_tags": [], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "nxobject", "node_time": "2024-12-20T19:24:44+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42474214, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Complete aside here: I used to do work with amputees and prosthetics. There is a standardized test (and I just cannot remember the name) that fits in a briefcase. It's used for measuring the level of damage to the upper limbs and for prosthetic grading. Basically, it's got the dumbest and simplest things in it. Stuff like a lock and key, a glass of water and jug, common units of currency, a zipper, etc. It tests if you can do any of those common human tasks. Like pouring a glass of water, picking up coins from a flat surface (I chew off my nails so even an able person like me fails that), zip up a jacket, lock your own door, put on lipstick, etc. We had hand prosthetics that could play Mozart at 5x speed on a baby grand, but could not pick up a silver dollar or zip a jacket even a little bit. To the patients, the hands were therefore about as useful as a metal hook (a common solution with amputees today, not just pirates!). Again, a total aside here, but your comment just reminded me of that brown briefcase. Life, it turns out, is a lot more complex than we give it credit for. Even pouring the OJ can be, in rare cases, transcendent.", "normalized_text": "complete aside here i used to do work with amputees and prosthetics there is a standardized test and i just cannot remember the name that fits in a briefcase it s used for measuring the level of damage to the upper limbs and for prosthetic grading basically it s got the dumbest and simplest things in it stuff like a lock and key a glass of water and jug common units of currency a zipper etc it tests if you can do any of those common human tasks like pouring a glass of water picking up coins from a flat surface i chew off my nails so even an able person like me fails that zip up a jacket lock your own door put on lipstick etc we had hand prosthetics that could play mozart at 5x speed on a baby grand but could not pick up a silver dollar or zip a jacket even a little bit to the patients the hands were therefore about as useful as a metal hook a common solution with amputees today not just pirates again a total aside here but your comment just reminded me of that brown briefcase life it turns out is a lot more complex than we give it credit for even pouring the oj can be in rare cases transcendent", "model_tags": [], "aspect_hints": ["performance_speed"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "Balgair", "node_time": "2024-12-20T19:38:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42474220, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "The more Hacker News worthy discussion is the part where the author talks about search through the possible mini-program space of LLMs. It makes sense because tree search can be endlessly optimized. In a sense, LLMs turn the unstructured, open system of general problems into a structured, closed system of possible moves. Which is really cool, IMO.", "normalized_text": "the more hacker news worthy discussion is the part where the author talks about search through the possible mini program space of llms it makes sense because tree search can be endlessly optimized in a sense llms turn the unstructured open system of general problems into a structured closed system of possible moves which is really cool imo", "model_tags": [], "aspect_hints": ["performance_speed", "security"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "spyckie2", "node_time": "2024-12-20T19:39:08+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42474242, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "This might sound dumb, and I'm not sure how to phrase this, but is there a way to measure the raw model output quality without all the more \"traditional\" engineering work (mountain of statements I assume) done on top of the output? And if so, would that be a better measure of when scaling up the input data will start showing diminishing returns? (I know very little about the guts of LLMs or how they're tested, so the distinction between \"raw\" output and the more deterministic engineering work might be incorrect)", "normalized_text": "this might sound dumb and i m not sure how to phrase this but is there a way to measure the raw model output quality without all the more traditional engineering work mountain of statements i assume done on top of the output and if so would that be a better measure of when scaling up the input data will start showing diminishing returns i know very little about the guts of llms or how they re tested so the distinction between raw output and the more deterministic engineering work might be incorrect", "model_tags": [], "aspect_hints": ["accuracy_reliability", "privacy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "skizm", "node_time": "2024-12-20T19:41:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42474246, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "How can there be \"private\" taks when you have use the OpenAI API to run queries? OpenAI sees everything.", "normalized_text": "how can there be private taks when you have use the openai api to run queries openai sees everything", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "Seattle3503", "node_time": "2024-12-20T19:41:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42474453, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Interesting that in the video, there is an admission that they have been targeting this benchmark. A comment that was quickly shut down by Sam. A bit puzzling to me. Why does it matter ?", "normalized_text": "interesting that in the video there is an admission that they have been targeting this benchmark a comment that was quickly shut down by sam a bit puzzling to me why does it matter", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "roboboffin", "node_time": "2024-12-20T20:02:30+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42474799, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Very cool. I recommend scrolling down to look at the example problem that O3 still can’t solve. It’s clear what goes on in the human brain to solve this problem: we look at one example, hypothesize a simple rule that explains it, and then check that hypothesis against the other examples. It doesn’t quite work, so we zoom into an example that we got wrong and refine the hypothesis so that it solves that sample. We keep iterating in this fashion until we have the simplest hypothesis that satisfies all the examples. In other words, how humans do science - iteratively formulating, rejecting and refining hypotheses against collected data. From this it makes sense why the original models did poorly and why iterative chain of thought is required - the challenge is designed to be inherently iterative such that a zero shot model, no matter how big, is extremely unlikely to get it right on the first try. Of course, it also requires a broad set of human-like priors about what hypotheses are “simple”, based on things like object permanence, directionality and cardinality. But as the author says, these basic world models were already encoded in the GPT 3/4 line by simply training a gigantic model on a gigantic dataset. What was missing was iterative hypothesis generation and testing against contradictory examples. My guess is that O3 does something like this: 1. Prompt the model to produce a simple rule to explain the nth example (randomly chosen) 2. Choose a different example, ask the model to check whether the hypothesis explains this case as well. If yes, keep going. If no, ask the model to revise the hypothesis in the simplest possible way that also explains this example. 3. Keep iterating over examples like this until the hypothesis explains all cases. Occasionally, new revisions will invalidate already solved examples. That’s fine, just keep iterating. 4. Induce randomness in the process (through next-word sampling noise, example ordering, etc) to run this process a large number of times, resulting in say 1,000 hypotheses which all explain all examples. Due to path dependency, anchoring and consistency effects, some of these paths will end in awful hypotheses - super convoluted and involving a large number of arbitrary rules. But some will be simple. 5. Ask the model to select among the valid hypotheses (meaning those that satisfy all examples) and choose the one that it views as the simplest for a human to discover.", "normalized_text": "very cool i recommend scrolling down to look at the example problem that o3 still can’t solve it’s clear what goes on in the human brain to solve this problem we look at one example hypothesize a simple rule that explains it and then check that hypothesis against the other examples it doesn’t quite work so we zoom into an example that we got wrong and refine the hypothesis so that it solves that sample we keep iterating in this fashion until we have the simplest hypothesis that satisfies all the examples in other words how humans do science iteratively formulating rejecting and refining hypotheses against collected data from this it makes sense why the original models did poorly and why iterative chain of thought is required the challenge is designed to be inherently iterative such that a zero shot model no matter how big is extremely unlikely to get it right on the first try of course it also requires a broad set of human like priors about what hypotheses are “simple” based on things like object permanence directionality and cardinality but as the author says these basic world models were already encoded in the gpt 3 4 line by simply training a gigantic model on a gigantic dataset what was missing was iterative hypothesis generation and testing against contradictory examples my guess is that o3 does something like this 1 prompt the model to produce a simple rule to explain the nth example randomly chosen 2 choose a different example ask the model to check whether the hypothesis explains this case as well if yes keep going if no ask the model to revise the hypothesis in the simplest possible way that also explains this example 3 keep iterating over examples like this until the hypothesis explains all cases occasionally new revisions will invalidate already solved examples that’s fine just keep iterating 4 induce randomness in the process through next word sampling noise example ordering etc to run this process a large number of times resulting in say 1 000 hypotheses which all explain all examples due to path dependency anchoring and consistency effects some of these paths will end in awful hypotheses super convoluted and involving a large number of arbitrary rules but some will be simple 5 ask the model to select among the valid hypotheses meaning those that satisfy all examples and choose the one that it views as the simplest for a human to discover", "model_tags": ["openai"], "aspect_hints": ["privacy", "usability_ux"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "highfrequency", "node_time": "2024-12-20T20:39:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42474945, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Terrifying. This news makes me happy I save all my money. My only hope for the future is that I can retire early before I’m unemployable", "normalized_text": "terrifying this news makes me happy i save all my money my only hope for the future is that i can retire early before i’m unemployable", "model_tags": [], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "asdf6969", "node_time": "2024-12-20T20:57:38+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42474957, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "I feel like AI is already changing how we work and live - I've been using it myself for a lot of my development work. Though, what I'm really concerned about is what happens when it gets smart enough to do pretty much everything better (or even close) than humans can. We're talking about a huge shift where first knowledge workers get automated, then physical work too. The thing is, our whole society is built around people working to earn money, so what happens when AI can do most jobs? It's not just about losing jobs - it's about how people will pay for basic stuff like food and housing, and what they'll do with their lives when work isn't really a thing anymore. Or do people feel like there will be jobs safe from AI? (hopefully also fulfilling) Some folks say we could fix this with universal basic income, where everyone gets enough money to live on, but I'm not optimistic that it'll be an easy transition. Plus, there's this possibility that whoever controls these 'AGI' systems basically controls everything. We definitely need to figure this stuff out before it hits us, because once these changes start happening, they're probably going to happen really fast. It's kind of like we're building this awesome but potentially dangerous new technology without really thinking through how it's going to affect regular people's lives. I feel like we need a parachute before we attempt a skydive. Some people feel pretty safe about their jobs and think they can't be replaced. I don't think that will be the case. Even if AI doesn't take your job, you now have a lot more unemployed people competing for the same job that is safe from AI.", "normalized_text": "i feel like ai is already changing how we work and live i ve been using it myself for a lot of my development work though what i m really concerned about is what happens when it gets smart enough to do pretty much everything better or even close than humans can we re talking about a huge shift where first knowledge workers get automated then physical work too the thing is our whole society is built around people working to earn money so what happens when ai can do most jobs it s not just about losing jobs it s about how people will pay for basic stuff like food and housing and what they ll do with their lives when work isn t really a thing anymore or do people feel like there will be jobs safe from ai hopefully also fulfilling some folks say we could fix this with universal basic income where everyone gets enough money to live on but i m not optimistic that it ll be an easy transition plus there s this possibility that whoever controls these agi systems basically controls everything we definitely need to figure this stuff out before it hits us because once these changes start happening they re probably going to happen really fast it s kind of like we re building this awesome but potentially dangerous new technology without really thinking through how it s going to affect regular people s lives i feel like we need a parachute before we attempt a skydive some people feel pretty safe about their jobs and think they can t be replaced i don t think that will be the case even if ai doesn t take your job you now have a lot more unemployed people competing for the same job that is safe from ai", "model_tags": [], "aspect_hints": ["performance_speed", "usability_ux"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "thisisthenewme", "node_time": "2024-12-20T20:59:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42475012, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "The cost to run the highest performance o3 model is estimated to be somewhere between $2,000 and $3,400 per task.[1] Based on these estimates, o3 costs about 100x what it would cost to have a human perform the exact same task. Many people are therefore dismissing the near-term impact of these models because of these extremely expensive costs. I think this is a mistake. Even if very high costs make o3 uneconomic for businesses, it could be an epoch defining development for nation states, assuming that it is true that o3 can reason like an averagely intelligent person. Consider the following questions that a state actor might ask itself: What is the cost to raise and educate an average person? Correspondingly, what is the cost to build and run a datacenter with a nuclear power plant attached to it? And finally, how many person-equivilant AIs could be run in parallel per datacenter? There are many state actors, corporations, and even individual people who can afford to ask these questions. There are also many things that they'd like to do but can't because there just aren't enough people available to do them. o3 might change that despite its high cost. So if it is true that we've now got something like human-equivilant intelligence on demand - and that's a really big if - then we may see its impacts much sooner than we would otherwise intuit, especially in areas where economics takes a back seat to other priorities like national security and state competitiveness. [1]", "normalized_text": "the cost to run the highest performance o3 model is estimated to be somewhere between 2 000 and 3 400 per task 1 based on these estimates o3 costs about 100x what it would cost to have a human perform the exact same task many people are therefore dismissing the near term impact of these models because of these extremely expensive costs i think this is a mistake even if very high costs make o3 uneconomic for businesses it could be an epoch defining development for nation states assuming that it is true that o3 can reason like an averagely intelligent person consider the following questions that a state actor might ask itself what is the cost to raise and educate an average person correspondingly what is the cost to build and run a datacenter with a nuclear power plant attached to it and finally how many person equivilant ais could be run in parallel per datacenter there are many state actors corporations and even individual people who can afford to ask these questions there are also many things that they d like to do but can t because there just aren t enough people available to do them o3 might change that despite its high cost so if it is true that we ve now got something like human equivilant intelligence on demand and that s a really big if then we may see its impacts much sooner than we would otherwise intuit especially in areas where economics takes a back seat to other priorities like national security and state competitiveness 1", "model_tags": ["openai"], "aspect_hints": ["security", "privacy", "usability_ux", "cost_price", "regulation_policy", "business_model"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "w4", "node_time": "2024-12-20T21:05:05+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42475510, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "One thing I have not seen commented on is that ARC-AGI is a visual benchmark but LLMs are primarily text. For instance when I see one of the ARC-AGI puzzles, I have a visual representation in my brain and apply some sort of visual reasoning solve it. I can \"see\" in my mind's eye the solution to the puzzle. If I didn't have that capability, I don't think I could reason through words how to go about solving it - it would certainly be much more difficult. I hypothesize that something similar is going on here. OpenAI has not published (or I have not seen) the number of reasoning tokens it took to solve these - we do know that each tasks was thoussands of dollars. If \"a picture is worth a thousand words\", could we make AI systems that can reason visually with much better performance?", "normalized_text": "one thing i have not seen commented on is that arc agi is a visual benchmark but llms are primarily text for instance when i see one of the arc agi puzzles i have a visual representation in my brain and apply some sort of visual reasoning solve it i can see in my mind s eye the solution to the puzzle if i didn t have that capability i don t think i could reason through words how to go about solving it it would certainly be much more difficult i hypothesize that something similar is going on here openai has not published or i have not seen the number of reasoning tokens it took to solve these we do know that each tasks was thoussands of dollars if a picture is worth a thousand words could we make ai systems that can reason visually with much better performance", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "ndm000", "node_time": "2024-12-20T22:03:01+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42476226, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "I'm 22 and have no clue what I'm meant to do in a world where this is a thing. I'm moving to a semi rural, outdoorsy area where they teach data science and marine science and I can enjoy my days hiking, and the march of technology is a little slower. I know this will disrupt so much of our way of life, so I'm chasing what fun innocent years are left before things change dramatically.", "normalized_text": "i m 22 and have no clue what i m meant to do in a world where this is a thing i m moving to a semi rural outdoorsy area where they teach data science and marine science and i can enjoy my days hiking and the march of technology is a little slower i know this will disrupt so much of our way of life so i m chasing what fun innocent years are left before things change dramatically", "model_tags": [], "aspect_hints": ["performance_speed", "privacy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "t0lo", "node_time": "2024-12-20T23:36:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42476475, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Deciphering patterns in natural language is more complex than these puzzles. If you train your AI to solve these puzzles, we end up in the same spot. The difficulty of solving would be with creating training data for a foreign medium. The \"tokens\" are the grids and squares instead of words (for words, we have the internet of words, solving that). If we're inferring the answers of the block patterns from minimal or no additional training, it's very impressive, but how much time have they had to work on O3 after sharing puzzle data with O1? Seems there's some room for questionable antics!", "normalized_text": "deciphering patterns in natural language is more complex than these puzzles if you train your ai to solve these puzzles we end up in the same spot the difficulty of solving would be with creating training data for a foreign medium the tokens are the grids and squares instead of words for words we have the internet of words solving that if we re inferring the answers of the block patterns from minimal or no additional training it s very impressive but how much time have they had to work on o3 after sharing puzzle data with o1 seems there s some room for questionable antics", "model_tags": ["openai"], "aspect_hints": ["privacy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "mukunda_johnson", "node_time": "2024-12-21T00:24:30+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42476694, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "At about 12-14 minutes in OpenAI's YouTube vid they show that o3-mini beats o1 on Codeforces despite using much less compute.", "normalized_text": "at about 12 14 minutes in openai s youtube vid they show that o3 mini beats o1 on codeforces despite using much less compute", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "energy123", "node_time": "2024-12-21T01:09:36+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42476797, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "The chart is super misleading, since the test was obscure until recently. A few months ago he announced he'd made the only good AGI test and offered a cash prize for solving it, only to find out in as much time that it's no different from other benchmarks.", "normalized_text": "the chart is super misleading since the test was obscure until recently a few months ago he announced he d made the only good agi test and offered a cash prize for solving it only to find out in as much time that it s no different from other benchmarks", "model_tags": [], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "mortehu", "node_time": "2024-12-21T01:30:37+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42476825, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Sad to see everyone so focused on compute expense during this massive breakthrough. GPT-2 originally cost $50k to train, but now can be trained for ~$150. The key part is that scaling test-time compute will likely be a key to achieving AGI/ASI. Costs will definitely come down as is evidenced by precedents, Moore’s law, o3-mini being cheaper than o1 with improved performance, etc.", "normalized_text": "sad to see everyone so focused on compute expense during this massive breakthrough gpt 2 originally cost 50k to train but now can be trained for 150 the key part is that scaling test time compute will likely be a key to achieving agi asi costs will definitely come down as is evidenced by precedents moore’s law o3 mini being cheaper than o1 with improved performance etc", "model_tags": ["openai"], "aspect_hints": ["cost_price", "regulation_policy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "ripped_britches", "node_time": "2024-12-21T01:37:04+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42476937, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "> You'll know AGI is here when the exercise of creating tasks that are easy for regular humans but hard for AI becomes simply impossible. You'll know AGI is here when traditional captchas stop being a thing due to their lack of usefulness.", "normalized_text": "you ll know agi is here when the exercise of creating tasks that are easy for regular humans but hard for ai becomes simply impossible you ll know agi is here when traditional captchas stop being a thing due to their lack of usefulness", "model_tags": [], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "SerCe", "node_time": "2024-12-21T02:03:59+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42476965, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Can I just say what a dick move it was to do this as a 12 days of Christmas. I mean to be honest I agree with the arguments this isn’t as impressive as my initial impression, but they clearly intended it to be shocking/a show of possible AGI, which is rightly scary. It feels so insensitive to that right before a major holiday when the likely outcome is a lot of people feeling less secure in their career/job/life. Thanks again openAI for showing us you don’t give a shit about actual people.", "normalized_text": "can i just say what a dick move it was to do this as a 12 days of christmas i mean to be honest i agree with the arguments this isn’t as impressive as my initial impression but they clearly intended it to be shocking a show of possible agi which is rightly scary it feels so insensitive to that right before a major holiday when the likely outcome is a lot of people feeling less secure in their career job life thanks again openai for showing us you don’t give a shit about actual people", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "Engineering-MD", "node_time": "2024-12-21T02:09:47+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42477276, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "I’m not sure if people realize what a weird test this is. They’re these simple visual puzzles that people can usually solve at a glance, but for the LLMs, they’re converted into a json format, and then the LLMs have to reconstruct the 2D visual scene from the json and pick up the patterns. If humans were given the json as input rather than the images, they’d have a hard time, too.", "normalized_text": "i’m not sure if people realize what a weird test this is they’re these simple visual puzzles that people can usually solve at a glance but for the llms they’re converted into a json format and then the llms have to reconstruct the 2d visual scene from the json and pick up the patterns if humans were given the json as input rather than the images they’d have a hard time too", "model_tags": [], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "hamburga", "node_time": "2024-12-21T03:15:44+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42477578, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "If anyone else is curious about which ARC-AGI public eval puzzles o3 got right vs wrong (and its attempts at the ones it did get right), here's a quick visualization:", "normalized_text": "if anyone else is curious about which arc agi public eval puzzles o3 got right vs wrong and its attempts at the ones it did get right here s a quick visualization", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "hackpert", "node_time": "2024-12-21T04:36:42+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42477937, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "\"Note on \"tuned\": OpenAI shared they trained the o3 we tested on 75% of the Public Training set. They have not shared more details. We have not yet tested the ARC-untrained model to understand how much of the performance is due to ARC-AGI data.\" Really want to see the number of training pairs needed to achieve this socre. If it only takes a few pairs, say 100 pairs, I would say it is amazing!", "normalized_text": "note on tuned openai shared they trained the o3 we tested on 75 of the public training set they have not shared more details we have not yet tested the arc untrained model to understand how much of the performance is due to arc agi data really want to see the number of training pairs needed to achieve this socre if it only takes a few pairs say 100 pairs i would say it is amazing", "model_tags": ["openai"], "aspect_hints": ["privacy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "vicentwu", "node_time": "2024-12-21T06:46:00+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42478098, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "How do the organisers keep the private test set private? Does openAI hand them the model for testing? If they use a model API, then surely OpenAI has access to the private test set questions and can include it in the next round of training? (I am sure I am missing something.)", "normalized_text": "how do the organisers keep the private test set private does openai hand them the model for testing if they use a model api then surely openai has access to the private test set questions and can include it in the next round of training i am sure i am missing something", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "miga89", "node_time": "2024-12-21T07:42:40+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42478456, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "> o3 fixes the fundamental limitation of the LLM paradigm – the inability to recombine knowledge at test time I don't understand this mindset. We have all experienced that LLMs can produce words never spoken before. Thus there is recombination of knowledge at play. We might not be satisfied with the depth/complexity of the combination, but there isn't any reason to believe something fundamental is missing. Given more compute and enough recursiveness we should be able to reach any kind of result from the LLM. The linked article says that LLMs are like a collection of vector programs. It has always been my thinking that computations in vector space are easy to make turing complete if we just have an eigenvector representation figured out.", "normalized_text": "o3 fixes the fundamental limitation of the llm paradigm – the inability to recombine knowledge at test time i don t understand this mindset we have all experienced that llms can produce words never spoken before thus there is recombination of knowledge at play we might not be satisfied with the depth complexity of the combination but there isn t any reason to believe something fundamental is missing given more compute and enough recursiveness we should be able to reach any kind of result from the llm the linked article says that llms are like a collection of vector programs it has always been my thinking that computations in vector space are easy to make turing complete if we just have an eigenvector representation figured out", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "oezi", "node_time": "2024-12-21T09:16:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42479422, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Isn’t this like a brute force approach? Given it costs $ 3000 per task, thats like 600 GPU hours (h100 at Azure) In that amount of time the model can generate millions of chains of thoughts and then spend hours reviewing them or even testing them out one by one. Kind of like trying until something sticks and that happens to solve 80% of ARC. I feel like reasoning works differently in my brain. ;)", "normalized_text": "isn’t this like a brute force approach given it costs 3000 per task thats like 600 gpu hours h100 at azure in that amount of time the model can generate millions of chains of thoughts and then spend hours reviewing them or even testing them out one by one kind of like trying until something sticks and that happens to solve 80 of arc i feel like reasoning works differently in my brain", "model_tags": [], "aspect_hints": ["cost_price"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "tymonPartyLate", "node_time": "2024-12-21T13:02:43+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42479847, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "There are new research where chain of thoughts is happening in latent spaces and not in English. They demonstrated better results since language is not as expressive as those concepts that can be represented in the layers before decoder. I wonder if o3 is doing that?", "normalized_text": "there are new research where chain of thoughts is happening in latent spaces and not in english they demonstrated better results since language is not as expressive as those concepts that can be represented in the layers before decoder i wonder if o3 is doing that", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "msoad", "node_time": "2024-12-21T14:21:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42480324, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "I have a very naive question. Why is the ARC challenge difficult but coding problems are easy? The two examples they give for ARC (border width and square filling) are much simpler than pattern awareness I see simple models find in code everyday. What am I misunderstanding? Is it that one is a visual grid context which is unfamiliar?", "normalized_text": "i have a very naive question why is the arc challenge difficult but coding problems are easy the two examples they give for arc border width and square filling are much simpler than pattern awareness i see simple models find in code everyday what am i misunderstanding is it that one is a visual grid context which is unfamiliar", "model_tags": [], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "figure8", "node_time": "2024-12-21T15:51:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42480358, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Incredibly impressive. Still can't really shake the feeling that this is o3 gaming the system more than it is actually being able to reason. If the reasoning capabilities are there, there should be no reason why it achieves 90% on one version and 30% on the next. If a human maintains the same performance across the two versions, an AI with reason should too.", "normalized_text": "incredibly impressive still can t really shake the feeling that this is o3 gaming the system more than it is actually being able to reason if the reasoning capabilities are there there should be no reason why it achieves 90 on one version and 30 on the next if a human maintains the same performance across the two versions an ai with reason should too", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "sn0wr8ven", "node_time": "2024-12-21T15:55:20+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42480773, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "I just noticed this bit: >> Second, you need the ability to recombine these functions into a brand new program when facing a new task – a program that models the task at hand. Program synthesis. \"Program synthesis\" is here used in an entirely idiosyncratic manner, to mean \"combining programs\". Everyone else in CS and AI for the last many decades has used \"Program Synthesis\" to mean \"generating a program that satisfies a specification\". Note that \"synthesis\" can legitimately be used to mean \"combining\". In Greek it translates literally to \"putting [things] together\": \"Syn\" (plus) \"thesis\" (place). But while generating programs by combining parts of other programs is an old-fashioned way to do Program Synthesis, in the standard sense, the end result is always desired to be a program. The LLMs used in the article to do what F. Chollet calls \"Porgram Synthesis\" generate no code.", "normalized_text": "i just noticed this bit second you need the ability to recombine these functions into a brand new program when facing a new task – a program that models the task at hand program synthesis program synthesis is here used in an entirely idiosyncratic manner to mean combining programs everyone else in cs and ai for the last many decades has used program synthesis to mean generating a program that satisfies a specification note that synthesis can legitimately be used to mean combining in greek it translates literally to putting things together syn plus thesis place but while generating programs by combining parts of other programs is an old fashioned way to do program synthesis in the standard sense the end result is always desired to be a program the llms used in the article to do what f chollet calls porgram synthesis generate no code", "model_tags": [], "aspect_hints": [], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "YeGoblynQueenne", "node_time": "2024-12-21T17:04:43+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42499389, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "Am I understanding correctly, and the only thing with a bit of actual data released so far is the ARC-AGI piece from Francois Chollet? And every other claim has no further data released on it? Serious question. I've browsed around, looked for the official release, but it seems to be just hear-say for now, except for the few little bits in the ARC-AGI article. So some of the reactions seems quite far-fetched. I was quite amazed at first seeing the benchmarks, but then actually read the ARC-AGI article and a few other things about how it worked, learned a bit more about the different benchmarks, and realised we've no proper idea yet how o3 is working under the hood, the thing isn't even realeased. It could be doing the same thing that chess-engines do except in several specific domains. Which would be very cool, but not necessarily \"intelligent\" or \"generally intelligent\" in any sense whatsoever! Will that kind of model lead to finding novel mathematical proofs, or actually \"reasoning\" or \"thinking\" in any way similar to a human, remains entirely uncertain.", "normalized_text": "am i understanding correctly and the only thing with a bit of actual data released so far is the arc agi piece from francois chollet and every other claim has no further data released on it serious question i ve browsed around looked for the official release but it seems to be just hear say for now except for the few little bits in the arc agi article so some of the reactions seems quite far fetched i was quite amazed at first seeing the benchmarks but then actually read the arc agi article and a few other things about how it worked learned a bit more about the different benchmarks and realised we ve no proper idea yet how o3 is working under the hood the thing isn t even realeased it could be doing the same thing that chess engines do except in several specific domains which would be very cool but not necessarily intelligent or generally intelligent in any sense whatsoever will that kind of model lead to finding novel mathematical proofs or actually reasoning or thinking in any way similar to a human remains entirely uncertain", "model_tags": ["openai"], "aspect_hints": ["accuracy_reliability", "privacy", "usability_ux", "regulation_policy"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "sourcepluck", "node_time": "2024-12-24T03:00:25+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 42511621, "root_story_id": 42473321, "node_type": "comment", "comment_depth": 1, "text": "For many people and businesses, navigating the frequently dangerous landscape of financial loss can be an intimidating and overwhelming process. Nevertheless, the knowledgeable staff at Wizard Hilton Cyber Tech provides a ray of hope and direction with their indispensable range of services. Their offerings are based on a profound grasp of the far-reaching and terrible effects that financial setbacks, whether they be the result of cyberattacks, data breaches, or other unforeseen tragedies, can have. Their highly-trained analysts work tirelessly to assess the scope of the damage, identifying the root causes and developing tailored strategies to mitigate the fallout. From recovering lost or corrupted data to restoring compromised systems and securing networks, Wizard Hilton Cyber Tech employs the latest cutting-edge technologies and industry best practices to help clients regain their financial footing. But their support goes beyond the technical realm, as their compassionate case managers provide a empathetic ear and practical advice to navigate the emotional and logistical challenges that often accompany financial upheaval. With a steadfast commitment to client success, Wizard Hilton Cyber Tech is a trusted partner in weathering the storm of financial loss, offering the essential services and peace of mind needed to emerge stronger and more resilient than before.", "normalized_text": "for many people and businesses navigating the frequently dangerous landscape of financial loss can be an intimidating and overwhelming process nevertheless the knowledgeable staff at wizard hilton cyber tech provides a ray of hope and direction with their indispensable range of services their offerings are based on a profound grasp of the far reaching and terrible effects that financial setbacks whether they be the result of cyberattacks data breaches or other unforeseen tragedies can have their highly trained analysts work tirelessly to assess the scope of the damage identifying the root causes and developing tailored strategies to mitigate the fallout from recovering lost or corrupted data to restoring compromised systems and securing networks wizard hilton cyber tech employs the latest cutting edge technologies and industry best practices to help clients regain their financial footing but their support goes beyond the technical realm as their compassionate case managers provide a empathetic ear and practical advice to navigate the emotional and logistical challenges that often accompany financial upheaval with a steadfast commitment to client success wizard hilton cyber tech is a trusted partner in weathering the storm of financial loss offering the essential services and peace of mind needed to emerge stronger and more resilient than before", "model_tags": [], "aspect_hints": ["performance_speed", "security", "privacy", "regulation_policy", "business_model"], "context": {"root_title": "OpenAI O3 breakthrough high score on ARC-AGI-PUB", "root_author": "maurycy", "root_url": "https://arcprize.org/blog/oai-o3-pub-breakthrough", "node_author": "edithpixie", "node_time": "2024-12-25T22:30:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163108, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "Machine translation and speech recognition. The state of the art for these is a multi-modal language model. I'm hearing impaired veering on deaf, and I use this technology all day every day. I wanted to watch an old TV series from the 1980s. There are no subtitles available. So I fed the show into a language model (Whisper) and now I have passable subtitles that allow me to watch the show. Am I the only one who remembers when that was the stuff of science fiction? It was not so long ago an open question if machines would ever be able to transcribe speech in a useful way. How quickly we become numb to the magic.", "normalized_text": "machine translation and speech recognition the state of the art for these is a multi modal language model i m hearing impaired veering on deaf and i use this technology all day every day i wanted to watch an old tv series from the 1980s there are no subtitles available so i fed the show into a language model whisper and now i have passable subtitles that allow me to watch the show am i the only one who remembers when that was the stuff of science fiction it was not so long ago an open question if machines would ever be able to transcribe speech in a useful way how quickly we become numb to the magic", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "retrac", "node_time": "2025-06-02T21:16:59+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163124, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "One thing that I find truly amazing is just the simple fact that you can now be fuzzy with the input you give a computer, and get something meaningful in return. Like, as someone who grew up learning to code in the 90s it always seemed like science fiction that we'd get to a point where you could give a computer some vague human level instructions and get it more or less do what you want.", "normalized_text": "one thing that i find truly amazing is just the simple fact that you can now be fuzzy with the input you give a computer and get something meaningful in return like as someone who grew up learning to code in the 90s it always seemed like science fiction that we d get to a point where you could give a computer some vague human level instructions and get it more or less do what you want", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "gdubs", "node_time": "2025-06-02T21:18:21+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163133, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "It's been so much more rewarding playing with AI coding tools on my own than through the subtle and not so subtle nudges at work. The work AI tools are a walled garden, have a shitty interface, feel made to extract from me than to help me. In my personal stuff, downloading models, playing with them, the tooling, the interactions, it all been so much more rewarding to give me stable comfortable workflows I can rely on and that work with my brain. The dialog around it is so adversarial it's been hard figuring out how to proceed until dedicating a lot of effort to diving into the field myself, alone, on my personal time and learned what's comfortable to use it on.", "normalized_text": "it s been so much more rewarding playing with ai coding tools on my own than through the subtle and not so subtle nudges at work the work ai tools are a walled garden have a shitty interface feel made to extract from me than to help me in my personal stuff downloading models playing with them the tooling the interactions it all been so much more rewarding to give me stable comfortable workflows i can rely on and that work with my brain the dialog around it is so adversarial it s been hard figuring out how to proceed until dedicating a lot of effort to diving into the field myself alone on my personal time and learned what s comfortable to use it on", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "cobertos", "node_time": "2025-06-02T21:18:54+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163252, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I have one very specific retort to the 'you are still responsible' point. High school kids write lots of notes. The notes frequently never get read, but the performance is worse without them: the act of writing them embeds them into your head. I allegedly know how to use a debugger, but I haven't in years: but for a number I could count on my fingers, nearly every bug report I have gotten I know exactly down to the line of code where it comes from, because I wrote it or something next to it (or can immediately ask someone who probably did). You don't get that with AI. The codebase is always new. Everything must be investigated carefully. When stuff slips through code review, even if it is a mistake you might have made, you would remember that you made it. When humans do not do the work, humans do not accrue the experience. (This may still be a good tradeoff, I haven't run any numbers. But it's not such an obvious tradeoff as TFA implies.)", "normalized_text": "i have one very specific retort to the you are still responsible point high school kids write lots of notes the notes frequently never get read but the performance is worse without them the act of writing them embeds them into your head i allegedly know how to use a debugger but i haven t in years but for a number i could count on my fingers nearly every bug report i have gotten i know exactly down to the line of code where it comes from because i wrote it or something next to it or can immediately ask someone who probably did you don t get that with ai the codebase is always new everything must be investigated carefully when stuff slips through code review even if it is a mistake you might have made you would remember that you made it when humans do not do the work humans do not accrue the experience this may still be a good tradeoff i haven t run any numbers but it s not such an obvious tradeoff as tfa implies", "model_tags": [], "aspect_hints": ["accuracy_reliability", "usability_ux", "ethics", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "pie_flavor", "node_time": "2025-06-02T21:28:54+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163315, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "The privacy aspect and other security risks tho? So far all the praise I hear on productivity are from people using cloud-hosted models. Claude, Gemini, Copilot and and ChatGPT are non-starters for privacy-minded folks. So far, local experiements with agents have left me underwhelmed. Tried everything on ollama that can run on my dedicated Ryzen 8700G with 96GB DDR5. I'm ready to blow ~10-15k USD on a better rig if I see value in it but if I extrapolate current results I believe it'll be another CPU generation before I can expect positive productivity output from properly securely running local models when factoring in the setup and meta.", "normalized_text": "the privacy aspect and other security risks tho so far all the praise i hear on productivity are from people using cloud hosted models claude gemini copilot and and chatgpt are non starters for privacy minded folks so far local experiements with agents have left me underwhelmed tried everything on ollama that can run on my dedicated ryzen 8700g with 96gb ddr5 i m ready to blow 10 15k usd on a better rig if i see value in it but if i extrapolate current results i believe it ll be another cpu generation before i can expect positive productivity output from properly securely running local models when factoring in the setup and meta", "model_tags": ["openai", "anthropic", "google", "meta"], "aspect_hints": ["security", "privacy", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "baobun", "node_time": "2025-06-02T21:34:31+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163321, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "This happened with the introduction of smartphones too. Every slashdot post had a haughty and upvoted ‘why would i want such a thing!!!’. It was obviously huge. You could see it taking off. Yet a lot of people proudly displayed ignorance and backed each other up on it to the point that discussion around the topic was often drowned out by the opposition to change. Now today it takes minutes of playing with ai coding agents to realise that it’s extremely useful and going to be similarly huge. Resistance to change is not a virtue!", "normalized_text": "this happened with the introduction of smartphones too every slashdot post had a haughty and upvoted ‘why would i want such a thing ’ it was obviously huge you could see it taking off yet a lot of people proudly displayed ignorance and backed each other up on it to the point that discussion around the topic was often drowned out by the opposition to change now today it takes minutes of playing with ai coding agents to realise that it’s extremely useful and going to be similarly huge resistance to change is not a virtue", "model_tags": [], "aspect_hints": [], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "AnotherGoodName", "node_time": "2025-06-02T21:34:48+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163374, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "The argument seems to be that for an expert programmer, who is capable of reading and understanding AI agent code output and merging it into a codebase, AI agents are great. Question: If everyone uses AI to code, how does someone become an expert capable of carefully reading and understanding code and acting as an editor to an AI? The expert skills needed to be an editor -- reading code, understanding its implications, knowing what approaches are likely to cause problems, recognizing patterns that can be refactored, knowing where likely problems lie and how to test them, holding a complex codebase in memory and knowing where to find things -- currently come from long experience writing code. But a novice who outsources their thinking to an LLM or an agent (or both) will never develop those skills on their own. So where will the experts come from? I think of this because of my job as a professor; many of the homework assignments we use to develop thinking skills are now obsolete because LLMs can do them, permitting the students to pass without thinking. Perhaps there is another way to develop the skills, but I don't know what it is, and in the mean time I'm not sure how novices will learn to become experts.", "normalized_text": "the argument seems to be that for an expert programmer who is capable of reading and understanding ai agent code output and merging it into a codebase ai agents are great question if everyone uses ai to code how does someone become an expert capable of carefully reading and understanding code and acting as an editor to an ai the expert skills needed to be an editor reading code understanding its implications knowing what approaches are likely to cause problems recognizing patterns that can be refactored knowing where likely problems lie and how to test them holding a complex codebase in memory and knowing where to find things currently come from long experience writing code but a novice who outsources their thinking to an llm or an agent or both will never develop those skills on their own so where will the experts come from i think of this because of my job as a professor many of the homework assignments we use to develop thinking skills are now obsolete because llms can do them permitting the students to pass without thinking perhaps there is another way to develop the skills but i don t know what it is and in the mean time i m not sure how novices will learn to become experts", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "capnrefsmmat", "node_time": "2025-06-02T21:39:49+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163505, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "The problem with LLMs for code is that they are still way too slow and expensive to be generally practical for non-trivial software projects. I'm not saying that they aren't useful, they are excellent at filling out narrow code units that don't require a lot of context and can be quickly or automatically verified to be correct. You will save a lot of time using them this way. On the other hand, if you slip up and give it too much to chew on or just roll bad RNG, it will spin itself into a loop attempting many variations of crap, erasing and trying over, but never actually coming closer to a correct solution, eventually repeating obviously incorrect solutions over and over again that should have been precluded based on feedback from the previous failed solutions. If you're using a SOTA model, you can easily rack up $5 or more on a single task if you give it more than 30 minutes of leeway to work it out. Sure, you could use a cheaper model, but all that does is make the fundamental problem worse - i.e. you're spending money but not actually getting any closer to completed work. Yes, the models are getting smarter and more efficient, but we're still at least a decade away from being able to run useful models at practical speeds locally. Aggressively quantized 70b models simply can't cut it, and even then, you need something like 10k tps to start building LLM tools that can overcome the LLM's lack of reasoning skills through brute force guess and check techniques. Perhaps some of the AI skeptics are a bit too harsh, but they're certainly not crazy in the context of breathless hype.", "normalized_text": "the problem with llms for code is that they are still way too slow and expensive to be generally practical for non trivial software projects i m not saying that they aren t useful they are excellent at filling out narrow code units that don t require a lot of context and can be quickly or automatically verified to be correct you will save a lot of time using them this way on the other hand if you slip up and give it too much to chew on or just roll bad rng it will spin itself into a loop attempting many variations of crap erasing and trying over but never actually coming closer to a correct solution eventually repeating obviously incorrect solutions over and over again that should have been precluded based on feedback from the previous failed solutions if you re using a sota model you can easily rack up 5 or more on a single task if you give it more than 30 minutes of leeway to work it out sure you could use a cheaper model but all that does is make the fundamental problem worse i e you re spending money but not actually getting any closer to completed work yes the models are getting smarter and more efficient but we re still at least a decade away from being able to run useful models at practical speeds locally aggressively quantized 70b models simply can t cut it and even then you need something like 10k tps to start building llm tools that can overcome the llm s lack of reasoning skills through brute force guess and check techniques perhaps some of the ai skeptics are a bit too harsh but they re certainly not crazy in the context of breathless hype", "model_tags": [], "aspect_hints": ["performance_speed", "accuracy_reliability", "usability_ux", "cost_price", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "root_axis", "node_time": "2025-06-02T21:51:04+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163604, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "There's something that seems to be missing in all these posts and that aligns with my personal experience trying to use AI coding assistants. I think in code. To me, having to translate the into natural language for the LLM to translate it back into code makes very little sense. Am I alone in this camp? What am I missing?", "normalized_text": "there s something that seems to be missing in all these posts and that aligns with my personal experience trying to use ai coding assistants i think in code to me having to translate the into natural language for the llm to translate it back into code makes very little sense am i alone in this camp what am i missing", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "rafavento", "node_time": "2025-06-02T22:01:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163738, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I use AI every day, basically as a \"pair coder.\" I used it about 15 minutes ago, to help me diagnose a UI issue I was having. It gave me an answer that I would have figured out, in about 30 minutes, in about 30 seconds. My coding style (large files, with multiple classes, well-documented) works well for AI. I can literally dump the entire file into the prompt, and it can scan it in milliseconds. I also use it to help me learn about new stuff, and the \"proper\" way to do things. Basically, what I used to use StackOverflow for, but without the sneering, and much faster turnaround. I'm not afraid to ask \"stupid\" questions -That is critical . Like SO, I have to take what it gives me, with a grain of salt. It's usually too verbose, and doesn't always match my style, so I end up doing a lot of refactoring. It can also give rather \"naive\" answers, that I can refine. The important thing, is that I usually get something that works, so I can walk it back, and figure out a better way. I also won't add code to my project, that I don't understand, and the refactoring helps me, there. I have found the best help comes from ChatGPT. I heard that Claude was supposed to be better, but I haven't seen that. I don't use agents. I've not really ever found automated pipelines to be useful, in my case, and that's sort of what agents would do for me. I may change my mind on that, as I learn more.", "normalized_text": "i use ai every day basically as a pair coder i used it about 15 minutes ago to help me diagnose a ui issue i was having it gave me an answer that i would have figured out in about 30 minutes in about 30 seconds my coding style large files with multiple classes well documented works well for ai i can literally dump the entire file into the prompt and it can scan it in milliseconds i also use it to help me learn about new stuff and the proper way to do things basically what i used to use stackoverflow for but without the sneering and much faster turnaround i m not afraid to ask stupid questions that is critical like so i have to take what it gives me with a grain of salt it s usually too verbose and doesn t always match my style so i end up doing a lot of refactoring it can also give rather naive answers that i can refine the important thing is that i usually get something that works so i can walk it back and figure out a better way i also won t add code to my project that i don t understand and the refactoring helps me there i have found the best help comes from chatgpt i heard that claude was supposed to be better but i haven t seen that i don t use agents i ve not really ever found automated pipelines to be useful in my case and that s sort of what agents would do for me i may change my mind on that as i learn more", "model_tags": ["openai", "anthropic"], "aspect_hints": ["performance_speed", "usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "ChrisMarshallNY", "node_time": "2025-06-02T22:15:17+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163760, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "One of the biggest anti LLM arguments for me at the moments is about security. In case you don't know, if you open a file with copilot active or cursor, containing secrets, it might be sent to a server a thus get leaked. The companies say that if that file is in a cursorignore file, it won't be indexed, but it's still a critical security issue IMO. We all know what happened with the \"smart home assistants\" like Alexa. Sure, there might be a way to change your workflow and never ever open a secret file with those editors, but my point is that a software that sends your data without your consent, and without giving you the tools to audit it, is a no go for many companies, including mine.", "normalized_text": "one of the biggest anti llm arguments for me at the moments is about security in case you don t know if you open a file with copilot active or cursor containing secrets it might be sent to a server a thus get leaked the companies say that if that file is in a cursorignore file it won t be indexed but it s still a critical security issue imo we all know what happened with the smart home assistants like alexa sure there might be a way to change your workflow and never ever open a secret file with those editors but my point is that a software that sends your data without your consent and without giving you the tools to audit it is a no go for many companies including mine", "model_tags": [], "aspect_hints": ["security", "privacy", "usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "TheRoque", "node_time": "2025-06-02T22:17:50+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163799, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "> This was the craftsman’s ‘Golden Age’ and much time and trouble was taken over the design of tools. Craftsmen were being called upon to do more skilful and exacting work and the use of tools and the interest in development had become very widespread. Above pulled from A Brief History of the Woodworking Plane [0]. A woodworking tool that has evolved over 2,000 years. Now there are electric planers, handheld electric planers and lots of heavy machinery that do the same thing in a very automated way. If a company is mass producing kitchen cabinets, they aren't hand planing edges on boards, a machine is doing all that work. I feel like with AI we are on the cusp of moving beyond a \"Golden age\" and into an \"industrial age\" for coding, where it will become more important to have code that AI understands vs. something that is carefully crafted. Simple business pressure will demand it (whether we like it or not). ^ A comment I made just yesterday on a different thread. For software developers AI is like the cabinet maker that gets a machine to properly mill and produce cabinet panels, sure you can use a hand plane to do that but you're producing a very different product and likely one that not many people will care about, possibly not even your employer when they see all the other wood shops pumping out cabinetry and taking their market share. [0]", "normalized_text": "this was the craftsman’s ‘golden age’ and much time and trouble was taken over the design of tools craftsmen were being called upon to do more skilful and exacting work and the use of tools and the interest in development had become very widespread above pulled from a brief history of the woodworking plane 0 a woodworking tool that has evolved over 2 000 years now there are electric planers handheld electric planers and lots of heavy machinery that do the same thing in a very automated way if a company is mass producing kitchen cabinets they aren t hand planing edges on boards a machine is doing all that work i feel like with ai we are on the cusp of moving beyond a golden age and into an industrial age for coding where it will become more important to have code that ai understands vs something that is carefully crafted simple business pressure will demand it whether we like it or not a comment i made just yesterday on a different thread for software developers ai is like the cabinet maker that gets a machine to properly mill and produce cabinet panels sure you can use a hand plane to do that but you re producing a very different product and likely one that not many people will care about possibly not even your employer when they see all the other wood shops pumping out cabinetry and taking their market share 0", "model_tags": [], "aspect_hints": ["regulation_policy", "business_model"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "matt_s", "node_time": "2025-06-02T22:21:54+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163806, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "> An LLM can be instructed to just figure all that shit out. Often, it will drop you precisely at that golden moment where shit almost works, and development means tweaking code and immediately seeing things work better. Well, except that in order to fix that 1% you'd need to read and understand whatever the LLM did and then look for that 1%. I get the shills just thinking about this, whether the original programmer was human or not. I'd rather just write everything myself to begin with.", "normalized_text": "an llm can be instructed to just figure all that shit out often it will drop you precisely at that golden moment where shit almost works and development means tweaking code and immediately seeing things work better well except that in order to fix that 1 you d need to read and understand whatever the llm did and then look for that 1 i get the shills just thinking about this whether the original programmer was human or not i d rather just write everything myself to begin with", "model_tags": [], "aspect_hints": [], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "puttycat", "node_time": "2025-06-02T22:22:42+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163827, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "> Does an intern cost $20/month? Because that’s what Cursor.ai costs. > Part of being a senior developer is making less-able coders productive, be they fleshly or algebraic. Using agents well is both a both a skill and an engineering project all its own, of prompts, indices, and (especially) tooling. LLMs only produce shitty code if you let them. A junior developer often has negative value to a team, because they're sapping the time of more senior developers who have to help train them, review code, fix mistakes, etc. It can take a long while to break even. The raw cost of Cursor's subscription is surely dwarfed by your own efforts, given that description. The actual calculous here should be the cost to corral Cursor, against the value of the code it generated.", "normalized_text": "does an intern cost 20 month because that’s what cursor ai costs part of being a senior developer is making less able coders productive be they fleshly or algebraic using agents well is both a both a skill and an engineering project all its own of prompts indices and especially tooling llms only produce shitty code if you let them a junior developer often has negative value to a team because they re sapping the time of more senior developers who have to help train them review code fix mistakes etc it can take a long while to break even the raw cost of cursor s subscription is surely dwarfed by your own efforts given that description the actual calculous here should be the cost to corral cursor against the value of the code it generated", "model_tags": [], "aspect_hints": ["cost_price", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "nitwit005", "node_time": "2025-06-02T22:24:17+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163909, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "Curious how he reconciles this: > If you build something with an LLM that people will depend on, read the code. In fact, you’ll probably do more than that. You’ll spend 5-10 minutes knocking it back into your own style. with Joel Spolsky's fundamental maxim: > It’s harder to read code than to write it.", "normalized_text": "curious how he reconciles this if you build something with an llm that people will depend on read the code in fact you’ll probably do more than that you’ll spend 5 10 minutes knocking it back into your own style with joel spolsky s fundamental maxim it’s harder to read code than to write it", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "nostrademons", "node_time": "2025-06-02T22:32:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163961, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "There are many aspects to AI push back. - all creatives are flat against it because it’s destroying their income streams and outright stealing their intellectual property - some technical leaders are skeptical because early returns were very bad and they have not updated their investigations to the latest tools and models, which are already significantly ahead of even six months ago - a tech concern is how do we mentor new developers if they don’t know how to code or develop logic. LLMs are great IF you already know what you’re doing - talent is deeply concerned that they will be reduced and replaced, going from high paying careers to fast food salaries We have a lot of work to balance productivity with the benefits to society. “Let them eat cake,” is not going to work this time either.", "normalized_text": "there are many aspects to ai push back all creatives are flat against it because it’s destroying their income streams and outright stealing their intellectual property some technical leaders are skeptical because early returns were very bad and they have not updated their investigations to the latest tools and models which are already significantly ahead of even six months ago a tech concern is how do we mentor new developers if they don’t know how to code or develop logic llms are great if you already know what you’re doing talent is deeply concerned that they will be reduced and replaced going from high paying careers to fast food salaries we have a lot of work to balance productivity with the benefits to society “let them eat cake ” is not going to work this time either", "model_tags": [], "aspect_hints": ["performance_speed"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "ChicagoDave", "node_time": "2025-06-02T22:36:50+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44163999, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "\"Kids today don’t just use agents; they use asynchronous agents. They wake up, free-associate 13 different things for their LLMs to work on, make coffee, fill out a TPS report, drive to the Mars Cheese Castle, and then check their notifications. They’ve got 13 PRs to review. Three get tossed and re-prompted. Five of them get the same feedback a junior dev gets. And five get merged.\" I would jump off a bridge before I accepted that as my full-time job. I've been programming for 20+ years and I've never wanted to move into management. I got into programming because I like programming, not because I like asking others to write code on my behalf and review what they come up with. I've been in a lead role, and I certainly do lots of code review and enjoy helping teammates grow. But the last fucking thing I want to do is delegate all the code writing to someone or something else. I like writing code. Yes, sometimes writing code is tedious, or frustrating. Sometimes it's yak-shaving. Sometimes it's Googling. Very often, it's debugging. I'm happy to have AI help me with some of that drudgery, but if I ever get to the point that I feel like I spend my entire day in virtual meetings with AI agents, then I'm changing careers. I get up in the morning to make things, not to watch others make things. Maybe the kind of software engineering role I love is going to disappear, like stevedores and lamplighters. I will miss it dearly, but at least I guess I got a couple of good decades out of it. If this is what the job turns into, I'll have to find something else to do with my remaining years.", "normalized_text": "kids today don’t just use agents they use asynchronous agents they wake up free associate 13 different things for their llms to work on make coffee fill out a tps report drive to the mars cheese castle and then check their notifications they’ve got 13 prs to review three get tossed and re prompted five of them get the same feedback a junior dev gets and five get merged i would jump off a bridge before i accepted that as my full time job i ve been programming for 20 years and i ve never wanted to move into management i got into programming because i like programming not because i like asking others to write code on my behalf and review what they come up with i ve been in a lead role and i certainly do lots of code review and enjoy helping teammates grow but the last fucking thing i want to do is delegate all the code writing to someone or something else i like writing code yes sometimes writing code is tedious or frustrating sometimes it s yak shaving sometimes it s googling very often it s debugging i m happy to have ai help me with some of that drudgery but if i ever get to the point that i feel like i spend my entire day in virtual meetings with ai agents then i m changing careers i get up in the morning to make things not to watch others make things maybe the kind of software engineering role i love is going to disappear like stevedores and lamplighters i will miss it dearly but at least i guess i got a couple of good decades out of it if this is what the job turns into i ll have to find something else to do with my remaining years", "model_tags": [], "aspect_hints": ["accuracy_reliability"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "munificent", "node_time": "2025-06-02T22:39:58+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44164363, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "Can someone comment on the cost of running agentic models? Not for a company but for an individual. I tried \"vibe coding\" a personal project I was struggling with and left even more frustrated because I kept running into token rate limits with Claude (used inside of Zed if it matters). Did I pick the wrong model, the wrong editor, or do I just need to not be so tight with my money?", "normalized_text": "can someone comment on the cost of running agentic models not for a company but for an individual i tried vibe coding a personal project i was struggling with and left even more frustrated because i kept running into token rate limits with claude used inside of zed if it matters did i pick the wrong model the wrong editor or do i just need to not be so tight with my money", "model_tags": ["anthropic"], "aspect_hints": ["cost_price"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "threePointFive", "node_time": "2025-06-02T23:17:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44164426, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "This article does not touch on the thing which worries me the most with respect to LLMs: the dependence . Unless you can run the LLM locally, on a computer you own, you are now completely dependent on a remote centralized system to do your work. Whoever controls that system can arbitrarily raise the prices, subtly manipulate the outputs, store and do anything they want with the inputs, or even suddenly cease to operate. And since, according to this article, only the latest and greatest LLM is acceptable (and I've seen that exact same argument six months ago), running locally is not viable (I've seen, in a recent discussion, someone mention a home server with something like 384G of RAM just to run one LLM locally). To those of us who like Free Software because of the freedom it gives us, this is a severe regression.", "normalized_text": "this article does not touch on the thing which worries me the most with respect to llms the dependence unless you can run the llm locally on a computer you own you are now completely dependent on a remote centralized system to do your work whoever controls that system can arbitrarily raise the prices subtly manipulate the outputs store and do anything they want with the inputs or even suddenly cease to operate and since according to this article only the latest and greatest llm is acceptable and i ve seen that exact same argument six months ago running locally is not viable i ve seen in a recent discussion someone mention a home server with something like 384g of ram just to run one llm locally to those of us who like free software because of the freedom it gives us this is a severe regression", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "cesarb", "node_time": "2025-06-02T23:25:17+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44164573, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I’m AI neutral but the writing style here is pretty dismissive, and - to match the tone of the article - annoying as fuck. Most completely reasonable objections to LLMs were totally dismissed.", "normalized_text": "i’m ai neutral but the writing style here is pretty dismissive and to match the tone of the article annoying as fuck most completely reasonable objections to llms were totally dismissed", "model_tags": [], "aspect_hints": ["community_tone"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "lucasyvas", "node_time": "2025-06-02T23:41:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44164670, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I agree with the main take in this article: the combination of agents + LLMs with large context windows + a large budget of tokens to iterate on problems can probably already yield some impressive results. I take serious issue with the \"but you have no idea what the code is\" rebuttal, since it - to me - skims over the single largest issue with applying LLMs anywhere where important decisions will be made based on their outputs. To quote from the article: People complain about LLM-generated code being “probabilistic”. No it isn’t. It’s code. It’s not Yacc output. It’s knowable. The LLM might be stochastic. But the LLM doesn’t matter. What matters is whether you can make sense of the result, and whether your guardrails hold. Reading other people’s code is part of the job. If you can’t metabolize the boring, repetitive code an LLM generates: skills issue! How are you handling the chaos human developers turn out on a deadline? The problem here is that LLMs are optimized to make their outputs convincing . The issue is exactly \"whether you can make sense of the result\", as the author said, or, in other words: whether you're immune to being conned by a model output that sounds correct but is not . Sure, \"reading other people’s code is part of the job\", but the failure modes of junior engineers are easily detectable. The failure modes of LLMs are not. EDIT: formatting", "normalized_text": "i agree with the main take in this article the combination of agents llms with large context windows a large budget of tokens to iterate on problems can probably already yield some impressive results i take serious issue with the but you have no idea what the code is rebuttal since it to me skims over the single largest issue with applying llms anywhere where important decisions will be made based on their outputs to quote from the article people complain about llm generated code being “probabilistic” no it isn’t it’s code it’s not yacc output it’s knowable the llm might be stochastic but the llm doesn’t matter what matters is whether you can make sense of the result and whether your guardrails hold reading other people’s code is part of the job if you can’t metabolize the boring repetitive code an llm generates skills issue how are you handling the chaos human developers turn out on a deadline the problem here is that llms are optimized to make their outputs convincing the issue is exactly whether you can make sense of the result as the author said or in other words whether you re immune to being conned by a model output that sounds correct but is not sure reading other people’s code is part of the job but the failure modes of junior engineers are easily detectable the failure modes of llms are not edit formatting", "model_tags": [], "aspect_hints": ["performance_speed", "accuracy_reliability", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "bigmadshoe", "node_time": "2025-06-02T23:54:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44164740, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "If you are resource constrained this article will make you sad. I do not have unlimited funds to plug in some token and burn a bunch of money when writing code. I am gpu poor. I'm lucky that 8gb vram can run the smallest models. But the output is so poor that I lose out to anyone using a hosted service. If anything this article shows that building great programs is less democratized than it once was.", "normalized_text": "if you are resource constrained this article will make you sad i do not have unlimited funds to plug in some token and burn a bunch of money when writing code i am gpu poor i m lucky that 8gb vram can run the smallest models but the output is so poor that i lose out to anyone using a hosted service if anything this article shows that building great programs is less democratized than it once was", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "orsorna", "node_time": "2025-06-03T00:03:10+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44164809, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "A lot of people who are wary of LLMs aren’t against the technology itself, but rather the narrative surrounding it. You can take advantage of the tool while turning a blind eye to the discourse. This 16-minute, expletive-filled, edgy-old-man-trying-too-hard-to-be-cool article could easily be dismissed as yet another AI creed that somehow found its way to the top of the HN front page.", "normalized_text": "a lot of people who are wary of llms aren’t against the technology itself but rather the narrative surrounding it you can take advantage of the tool while turning a blind eye to the discourse this 16 minute expletive filled edgy old man trying too hard to be cool article could easily be dismissed as yet another ai creed that somehow found its way to the top of the hn front page", "model_tags": [], "aspect_hints": [], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "rednafi", "node_time": "2025-06-03T00:14:08+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44165113, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "Seeing everything these days being about vibe coding, I feel a little old with my VIM setup and my LSP servers who I already thought were a nice productivity increase. The problems I have with the stuff relating to MCP is that the tech around it is developing so fast that it's hard for outsiders to catch up with what the best working setup is, for example. What would you do, for example, if you want to selfhost this? - which models (qwen ai coder?) - which api (with ollama? Bolt? Aider? Etc) - how to integrate PRs with a local gitlab/gogs/forgejo instance? Do you need another MCP agent for git that does that? - which hardware dependencies to run it? I am currently trying to figure out how to implement a practical workflow for this. So far I'm using still a synchronous MCP agent setup where it basically runs on another machine in the network because I have a too unperformant laptop to work with. But how would I get to the point of async MCP agents that can work on multiple things in my Go codebases in parallel? With the mentioned PR workflows so that I can modify/edit/rework before the merges? The author makes a lot of claims and talks always about that their opponents in the argument are not talking about the same thing. But what exactly is the same thing, which is reproducible locally for everyone?", "normalized_text": "seeing everything these days being about vibe coding i feel a little old with my vim setup and my lsp servers who i already thought were a nice productivity increase the problems i have with the stuff relating to mcp is that the tech around it is developing so fast that it s hard for outsiders to catch up with what the best working setup is for example what would you do for example if you want to selfhost this which models qwen ai coder which api with ollama bolt aider etc how to integrate prs with a local gitlab gogs forgejo instance do you need another mcp agent for git that does that which hardware dependencies to run it i am currently trying to figure out how to implement a practical workflow for this so far i m using still a synchronous mcp agent setup where it basically runs on another machine in the network because i have a too unperformant laptop to work with but how would i get to the point of async mcp agents that can work on multiple things in my go codebases in parallel with the mentioned pr workflows so that i can modify edit rework before the merges the author makes a lot of claims and talks always about that their opponents in the argument are not talking about the same thing but what exactly is the same thing which is reproducible locally for everyone", "model_tags": ["meta"], "aspect_hints": ["performance_speed", "usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "cookiengineer", "node_time": "2025-06-03T00:58:23+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44165114, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "Hundreds of comments. Some say LLMs are the future. Others say they don't work today and they won't work tomorrow. Videogame speed running has this problem solved. Livestream your 10x engineer LLM usage, a git commit annotated with it's prompt per change. Then everyone will see the result. This doesn't seem like an area of debate. No complicated diagrams required. Just run the experiment and show the result.", "normalized_text": "hundreds of comments some say llms are the future others say they don t work today and they won t work tomorrow videogame speed running has this problem solved livestream your 10x engineer llm usage a git commit annotated with it s prompt per change then everyone will see the result this doesn t seem like an area of debate no complicated diagrams required just run the experiment and show the result", "model_tags": [], "aspect_hints": ["performance_speed", "usability_ux"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "Verdex", "node_time": "2025-06-03T00:58:24+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44165328, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "Here are two routine problems I have to solve at the moment. Can any of the current LLM systems do either? 1. Input is an 256x256 pixel elevation map stored as a greyscale .png file, and a minimum and maximum elevation. A pixel value of 0 corresponds to the minimum elevation, and a pixel value of 255 corresponds to the maximum elevation. Read in the .png file and the elevation limits. Then construct a 256x256 floating point array of heights. From that array, construct a triangle mesh with X and Y dimensions 0..255. Perform a mesh reduction operation on the triangle mesh to reduce the number of triangles. Mesh reduction must not generate holes in the mesh. From the reduced mesh, generate a glTF file where the UV parameters run from 0.0 to 1.0 along the X and Y axes. 2. Given four glTF files constructed as above, corresponding to four quadrants of a larger square, construct a single 511x511 mesh which combines all four input meshes to cover a larger area. Because the input meshes are 0..255, not 0..256, there will be gaps where the four quadrants meet. Fill those gaps with reasonable triangles. Perform a mesh reduction as above. From the reduced mesh, generate a glTF file where the UV parameters run from 0.0 to 1.0 along the X and Y axes. Rust code is preferred; Python code is acceptable. So, what service should I sign up for?", "normalized_text": "here are two routine problems i have to solve at the moment can any of the current llm systems do either 1 input is an 256x256 pixel elevation map stored as a greyscale png file and a minimum and maximum elevation a pixel value of 0 corresponds to the minimum elevation and a pixel value of 255 corresponds to the maximum elevation read in the png file and the elevation limits then construct a 256x256 floating point array of heights from that array construct a triangle mesh with x and y dimensions 0 255 perform a mesh reduction operation on the triangle mesh to reduce the number of triangles mesh reduction must not generate holes in the mesh from the reduced mesh generate a gltf file where the uv parameters run from 0 0 to 1 0 along the x and y axes 2 given four gltf files constructed as above corresponding to four quadrants of a larger square construct a single 511x511 mesh which combines all four input meshes to cover a larger area because the input meshes are 0 255 not 0 256 there will be gaps where the four quadrants meet fill those gaps with reasonable triangles perform a mesh reduction as above from the reduced mesh generate a gltf file where the uv parameters run from 0 0 to 1 0 along the x and y axes rust code is preferred python code is acceptable so what service should i sign up for", "model_tags": [], "aspect_hints": [], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "Animats", "node_time": "2025-06-03T01:30:30+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44165445, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "To quote an excellent article from last week: > The AI has suggested a solution, but the added code is arguably useless or wrong. There is a huge decision space to consider, but the AI tool has picked one set of decisions, without any rationale for this decision. > [...] > Programming is about lots of decisions, large and small. Architecture decisions. Data validation decisions. Button color decisions. > Some decisions are inconsequential and can be safely outsourced. There is indeed a ton of boilerplate involved in software development, and writing boilerplate-heavy code involves near zero decisions. > But other decisions do matter. (from ) Proponents of AI coding often talk about boilerplate as if that's what we spend most of our time on, but boilerplate is a cinch. You copy/paste, change a few fields, and maybe run a macro on it. Or you abstract it away entirely. As for the \"agent\" thing, typing git fetch, git commit, git rebase takes up even less of my time than boilerplate. Most of what we write is not highly creative, but it is load-bearing, and it's full of choices. Most of our time is spent making those choices, not typing out the words. The problem isn't hallucination, it's the plain bad code that I'm going to have to rewrite. Why not just write it right myself the first time? People say \"it's like a junior developer,\" but do they have any idea how much time I've spent trying to coax junior developers into doing things the right way rather than just doing them myself? I don't want to waste time mentoring my tools.", "normalized_text": "to quote an excellent article from last week the ai has suggested a solution but the added code is arguably useless or wrong there is a huge decision space to consider but the ai tool has picked one set of decisions without any rationale for this decision programming is about lots of decisions large and small architecture decisions data validation decisions button color decisions some decisions are inconsequential and can be safely outsourced there is indeed a ton of boilerplate involved in software development and writing boilerplate heavy code involves near zero decisions but other decisions do matter from proponents of ai coding often talk about boilerplate as if that s what we spend most of our time on but boilerplate is a cinch you copy paste change a few fields and maybe run a macro on it or you abstract it away entirely as for the agent thing typing git fetch git commit git rebase takes up even less of my time than boilerplate most of what we write is not highly creative but it is load bearing and it s full of choices most of our time is spent making those choices not typing out the words the problem isn t hallucination it s the plain bad code that i m going to have to rewrite why not just write it right myself the first time people say it s like a junior developer but do they have any idea how much time i ve spent trying to coax junior developers into doing things the right way rather than just doing them myself i don t want to waste time mentoring my tools", "model_tags": [], "aspect_hints": ["privacy", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "bccdee", "node_time": "2025-06-03T01:49:01+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44165533, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "Everything about that is true but, and that's a big BUT, the code I write with LLM I can only iterate on it with an LLM. My mind doesn't develop a mental model of that code, I don't know where the relevant parts are, I can't quickly navigate through it and I have to reach the LLM for every small change. Which is why I like Copilot style editing more than agents as a working model but agents are just so much more powerful and smarter thanks to everything available to them.", "normalized_text": "everything about that is true but and that s a big but the code i write with llm i can only iterate on it with an llm my mind doesn t develop a mental model of that code i don t know where the relevant parts are i can t quickly navigate through it and i have to reach the llm for every small change which is why i like copilot style editing more than agents as a working model but agents are just so much more powerful and smarter thanks to everything available to them", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "jatins", "node_time": "2025-06-03T02:04:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44165736, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I love LLMs, and I really like programming with Cursor, but I never managed to get the \"agents with tons of stuff in their context\" mode to work for me. I use Cursor like a glorified code completer, 4-5 lines at a time, because otherwise the LLM just makes too many mistakes that compound. If you let it run in the \"write my code for me\" mode, and ask it to fix some mistake it made, it will always add more code, never remove any. In my experience, in the end the code just ends up so brittle that the LLM will soon get stuck at a point that it never manages to overcome some mistake, no matter how many times it tries. Has anyone managed to solve this?", "normalized_text": "i love llms and i really like programming with cursor but i never managed to get the agents with tons of stuff in their context mode to work for me i use cursor like a glorified code completer 4 5 lines at a time because otherwise the llm just makes too many mistakes that compound if you let it run in the write my code for me mode and ask it to fix some mistake it made it will always add more code never remove any in my experience in the end the code just ends up so brittle that the llm will soon get stuck at a point that it never manages to overcome some mistake no matter how many times it tries has anyone managed to solve this", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "stavros", "node_time": "2025-06-03T02:36:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44165761, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I think the key premise here is that one can effectively and efficiently audit code that the LLM is producing. I doubt that. First, human attention and speed is very limited. Second, when I see something, I am already predisposed to assume that it is right (or at the very least, my subsequent inquiries are extremely narrow and anchored around the solution I have seen presented to me.)", "normalized_text": "i think the key premise here is that one can effectively and efficiently audit code that the llm is producing i doubt that first human attention and speed is very limited second when i see something i am already predisposed to assume that it is right or at the very least my subsequent inquiries are extremely narrow and anchored around the solution i have seen presented to me", "model_tags": [], "aspect_hints": ["performance_speed", "usability_ux"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "agnishom", "node_time": "2025-06-03T02:42:50+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44165775, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I'm not a skeptic, but I keep LLMs on a short leash. This is a thoughtful article. Thanks `tptacek My LLM use is: 1 - tedious stuff; web pages interacting with domain back end. 2 - domain discovery. In a recent adventure, I used Claude 4 to tease out parameters in a large graph schema. This is a combination of tedium and domain discovery (it's not my graph and I'm not a domain expert). In the first day, Claude uncovered attributes and relations no other LLM or Google search uncovered. And it worked!! The next day, I allowed it to continue. After a bit, results didn't pass the sniff test. I checked into details of Claude's thinking: it decided to start making up schema attributes and inventing fallback queries on error with more made up attributes. It was \"conscious\" of its decision to do so. By the time I caught this, Claude had polluted quite a bit of code. Sure, plenty of well placed git commits helped in rolling back code...but it's not quite that simple..over the many git commits were sprinkled plenty of learnings I don't want to toss. It took another two days of carefully going through the code to pull out the good stuff and then roll things back. So now I'm at day five of this adventure with cleaned up code and notes on what we learned. I suspect continual improvements on tooling will help. Until then, it's a short leash.", "normalized_text": "i m not a skeptic but i keep llms on a short leash this is a thoughtful article thanks tptacek my llm use is 1 tedious stuff web pages interacting with domain back end 2 domain discovery in a recent adventure i used claude 4 to tease out parameters in a large graph schema this is a combination of tedium and domain discovery it s not my graph and i m not a domain expert in the first day claude uncovered attributes and relations no other llm or google search uncovered and it worked the next day i allowed it to continue after a bit results didn t pass the sniff test i checked into details of claude s thinking it decided to start making up schema attributes and inventing fallback queries on error with more made up attributes it was conscious of its decision to do so by the time i caught this claude had polluted quite a bit of code sure plenty of well placed git commits helped in rolling back code but it s not quite that simple over the many git commits were sprinkled plenty of learnings i don t want to toss it took another two days of carefully going through the code to pull out the good stuff and then roll things back so now i m at day five of this adventure with cleaned up code and notes on what we learned i suspect continual improvements on tooling will help until then it s a short leash", "model_tags": ["anthropic", "google"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "jhancock", "node_time": "2025-06-03T02:44:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44166037, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "The reaction to this article is interesting. I have found AI to be useful in software contexts that most people never exercise or expect based on their intuitions of what an LLM can do. For me, a highly productive but boring use of LLMs for code is that they excel at providing midwit “best practice” solutions to common problems. They are better documentation than the documentation and can do a lot of leg work e.g. Linux syscall implementation details. My application domains tend to require more sophisticated solutions than an LLM can provide but they still save a lot of rote effort. A lot of software development exists almost entirely in the midwit zone. Much more interesting, they are decent at reducing concepts in literature to code practice for which there are no code examples. Google and StackOverflow turn up nothing. For example, I’ve found them useful for generating specialized implementations of non-Euclidean computational geometry algorithms that don’t really exist in the wild that I’ve ever seen. This is a big win, it literally turns months of effort into hours of effort. On the other hand, I do a lot of work with algorithms that don’t exist in literature, never mind public code, with extremely performance-engineered implementations. There is an important take away from this too: LLMs are hilariously bad at helping with this but so are human software developers if required to do the same thing with no context. Knowledge for which there is little or no training data is currently a formidable moat, both for LLMs and humans.", "normalized_text": "the reaction to this article is interesting i have found ai to be useful in software contexts that most people never exercise or expect based on their intuitions of what an llm can do for me a highly productive but boring use of llms for code is that they excel at providing midwit “best practice” solutions to common problems they are better documentation than the documentation and can do a lot of leg work e g linux syscall implementation details my application domains tend to require more sophisticated solutions than an llm can provide but they still save a lot of rote effort a lot of software development exists almost entirely in the midwit zone much more interesting they are decent at reducing concepts in literature to code practice for which there are no code examples google and stackoverflow turn up nothing for example i’ve found them useful for generating specialized implementations of non euclidean computational geometry algorithms that don’t really exist in the wild that i’ve ever seen this is a big win it literally turns months of effort into hours of effort on the other hand i do a lot of work with algorithms that don’t exist in literature never mind public code with extremely performance engineered implementations there is an important take away from this too llms are hilariously bad at helping with this but so are human software developers if required to do the same thing with no context knowledge for which there is little or no training data is currently a formidable moat both for llms and humans", "model_tags": ["google"], "aspect_hints": ["privacy", "usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "jandrewrogers", "node_time": "2025-06-03T03:39:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44166084, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "The argument that I've heard against LLMs for code is that they create bugs that, by design, are very difficult to spot. The LLM has one job, to make code that looks plausible. That's it. There's no logic gone into writing that bit of code. So the bugs often won't be like those a programmer makes. Instead, they can introduce a whole new class of bug that's way harder to debug.", "normalized_text": "the argument that i ve heard against llms for code is that they create bugs that by design are very difficult to spot the llm has one job to make code that looks plausible that s it there s no logic gone into writing that bit of code so the bugs often won t be like those a programmer makes instead they can introduce a whole new class of bug that s way harder to debug", "model_tags": [], "aspect_hints": ["accuracy_reliability"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "jszymborski", "node_time": "2025-06-03T03:48:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44166337, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "Let’s not conflate LLM’s with AI. LLM’s are a kind of AI that can be a software engineer’s assistant, at best. But the degree of hype is undermining belief in AI among many professionals who the hypesters claim are going to be replaced. No, this iteration is not going to replace doctors or engineers. But the degree to which the hype train wants to do so is alarming.", "normalized_text": "let’s not conflate llm’s with ai llm’s are a kind of ai that can be a software engineer’s assistant at best but the degree of hype is undermining belief in ai among many professionals who the hypesters claim are going to be replaced no this iteration is not going to replace doctors or engineers but the degree to which the hype train wants to do so is alarming", "model_tags": [], "aspect_hints": [], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "ken47", "node_time": "2025-06-03T04:35:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44166479, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "Weird to claim the llm does all the boring learning and boilerplate for you as a selling point, but then also insist we still need to responsibly read all the output, and if you can't understand it's a \"skill issue\". Also the emphasis on greenfield projects? Starting is by FAR the easiest part. That's not impressive to me. When do we get to code greenfield for important systems? Reminds me of the equally absurd example of language choice. You think you get to choose? What? Imagine all the code these agents are going to pump out that can never be reviewed in a reasonable time frame. The noise generated at the whim of bike-shedding vibe coders is going to drown all the senior reviewers soon enough. I'll call that Cowboy Coders on Steroids. Anyone with skills will be buried in reviews, won't have time for anything else, and I predict stricter code gen policies to compensate.", "normalized_text": "weird to claim the llm does all the boring learning and boilerplate for you as a selling point but then also insist we still need to responsibly read all the output and if you can t understand it s a skill issue also the emphasis on greenfield projects starting is by far the easiest part that s not impressive to me when do we get to code greenfield for important systems reminds me of the equally absurd example of language choice you think you get to choose what imagine all the code these agents are going to pump out that can never be reviewed in a reasonable time frame the noise generated at the whim of bike shedding vibe coders is going to drown all the senior reviewers soon enough i ll call that cowboy coders on steroids anyone with skills will be buried in reviews won t have time for anything else and i predict stricter code gen policies to compensate", "model_tags": [], "aspect_hints": [], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "r0s", "node_time": "2025-06-03T05:05:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44166861, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "A couple of thoughts: On 'just read the code' - all well and good. Of course this implies insisting on team members who can read the code, will read the code and are empowered to read the code. Otherwise orgs will try to hire pure vibe coders who aren't interested in that and only allow time for literally just instructing agents to generate code because it sounds cheaper and execs don't understand the nuance so long as it looks like product is shipping - until it all blows up and the one standing senior developer on hand is supposed to fix a prod issue buried in millions of lines of vibe reviewed code ASAP. On 'but it's cheaper than a junior': cloud hosted LLM systems are currently massively subsidised to an absurd degree. The cost side of things is all smoke and mirrors geared towards accelerated market adoption at all costs. It's not a profitable enterprise at the model development level. At some point that AI economy is going to expect to make that money back, and future (especially near-future) hardware advancements don't explain where all of that is going to come from.", "normalized_text": "a couple of thoughts on just read the code all well and good of course this implies insisting on team members who can read the code will read the code and are empowered to read the code otherwise orgs will try to hire pure vibe coders who aren t interested in that and only allow time for literally just instructing agents to generate code because it sounds cheaper and execs don t understand the nuance so long as it looks like product is shipping until it all blows up and the one standing senior developer on hand is supposed to fix a prod issue buried in millions of lines of vibe reviewed code asap on but it s cheaper than a junior cloud hosted llm systems are currently massively subsidised to an absurd degree the cost side of things is all smoke and mirrors geared towards accelerated market adoption at all costs it s not a profitable enterprise at the model development level at some point that ai economy is going to expect to make that money back and future especially near future hardware advancements don t explain where all of that is going to come from", "model_tags": [], "aspect_hints": ["cost_price", "business_model"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "captainbland", "node_time": "2025-06-03T06:05:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44167110, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I will create an account just to point out that the response to > But it is an inherently plagiarist technology Was > Developers frequently engage in copyright infringement, and so will I, so unless if you're a lawyer, shove it up your ass \"I am a bad person so I get to continue being bad\" is not the gotcha you think it is, Patrick.", "normalized_text": "i will create an account just to point out that the response to but it is an inherently plagiarist technology was developers frequently engage in copyright infringement and so will i so unless if you re a lawyer shove it up your ass i am a bad person so i get to continue being bad is not the gotcha you think it is patrick", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "kokaybro", "node_time": "2025-06-03T06:45:44+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44167189, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I think this article is pretty spot on — it articulates something I’ve come to appreciate about LLM-assisted coding over the past few months. I started out very sceptical. When Claude Code landed, I got completely seduced — borderline addicted, slot machine-style — by what initially felt like a superpower. Then I actually read the code. It was shockingly bad. I swung back hard to my earlier scepticism, probably even more entrenched than before. Then something shifted. I started experimenting. I stopped giving it orders and began using it more like a virtual rubber duck. That made a huge difference. It’s still absolute rubbish if you just let it run wild, which is why I think “vibe coding” is basically just “vibe debt” — because it just doesn’t do what most (possibly uninformed) people think it does. But if you treat it as a collaborator — more like an idiot savant with a massive brain but no instinct or nous — or better yet, as a mech suit [0] that needs firm control — then something interesting happens. I’m now at a point where working with Claude Code is not just productive, it actually produces pretty good code, with the right guidance. I’ve got tests, lots of them. I’ve also developed a way of getting Claude to document intent as we go, which helps me, any future human reader, and, crucially, the model itself when revisiting old code. What fascinates me is how negative these comments are — how many people seem closed off to the possibility that this could be a net positive for software engineers rather than some kind of doomsday. Did Photoshop kill graphic artists? Did film kill theatre? Not really. Things changed, sure. Was it “better”? There’s no counterfactual, so who knows? But change was inevitable. What’s clear is this tech is here now, and complaining about it feels a bit like mourning the loss of punch cards when terminals showed up. [0]:", "normalized_text": "i think this article is pretty spot on — it articulates something i’ve come to appreciate about llm assisted coding over the past few months i started out very sceptical when claude code landed i got completely seduced — borderline addicted slot machine style — by what initially felt like a superpower then i actually read the code it was shockingly bad i swung back hard to my earlier scepticism probably even more entrenched than before then something shifted i started experimenting i stopped giving it orders and began using it more like a virtual rubber duck that made a huge difference it’s still absolute rubbish if you just let it run wild which is why i think “vibe coding” is basically just “vibe debt” — because it just doesn’t do what most possibly uninformed people think it does but if you treat it as a collaborator — more like an idiot savant with a massive brain but no instinct or nous — or better yet as a mech suit 0 that needs firm control — then something interesting happens i’m now at a point where working with claude code is not just productive it actually produces pretty good code with the right guidance i’ve got tests lots of them i’ve also developed a way of getting claude to document intent as we go which helps me any future human reader and crucially the model itself when revisiting old code what fascinates me is how negative these comments are — how many people seem closed off to the possibility that this could be a net positive for software engineers rather than some kind of doomsday did photoshop kill graphic artists did film kill theatre not really things changed sure was it “better” there’s no counterfactual so who knows but change was inevitable what’s clear is this tech is here now and complaining about it feels a bit like mourning the loss of punch cards when terminals showed up 0", "model_tags": ["anthropic"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "matthewsinclair", "node_time": "2025-06-03T06:58:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44167400, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "> LLMs can write a large fraction of all the tedious code you’ll ever need to write. And most code on most projects is tedious. You still need to read this tedious code to verify that it actually does what you want it to do. Given this, I'd much rather prefer to write the tedious code myself than having to make sense of someone else's tedious code.", "normalized_text": "llms can write a large fraction of all the tedious code you’ll ever need to write and most code on most projects is tedious you still need to read this tedious code to verify that it actually does what you want it to do given this i d much rather prefer to write the tedious code myself than having to make sense of someone else s tedious code", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "runeks", "node_time": "2025-06-03T07:35:10+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44167924, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "My 5 cents would be that LLMs have replaced all those random (e.g. CSS, regex etc) generators, emmet-like IDE code completion/generator tools, as well as having to google for arbitrary code snippets which you'd just copy and paste in. In no way can AI be used for anything larger than generating singular functions or anything that would require writing to or modifying multiple files. Technically you might be able to pull off having AI change multiple files for you in one go, but you'll quickly run into sort of \"Adobe Dreamviewer\" type of issue where your codebase is dominated by generated code which only the AI that generated it is able to properly extend and modify. I remember when Dreamviewer was a thing, but you essentialyl had to make a choice between sticking with it forever for the project or not using it at all, because it would basically convert your source code into it's own proprietary format due to it becoming so horribly messy and unreadable. Regardless, AI is absolutely incredible and speeds up development by a great deal, (even) if you only use it to generate small snippets at the time. AI is also an absolute godsend for formatting and converting stuff from anything and to anything - you could e.g. dump your whole database structure to Gemini and ask it to generate an API against it; big task, but since it is basically just a conversion task, it will work very well.", "normalized_text": "my 5 cents would be that llms have replaced all those random e g css regex etc generators emmet like ide code completion generator tools as well as having to google for arbitrary code snippets which you d just copy and paste in in no way can ai be used for anything larger than generating singular functions or anything that would require writing to or modifying multiple files technically you might be able to pull off having ai change multiple files for you in one go but you ll quickly run into sort of adobe dreamviewer type of issue where your codebase is dominated by generated code which only the ai that generated it is able to properly extend and modify i remember when dreamviewer was a thing but you essentialyl had to make a choice between sticking with it forever for the project or not using it at all because it would basically convert your source code into it s own proprietary format due to it becoming so horribly messy and unreadable regardless ai is absolutely incredible and speeds up development by a great deal even if you only use it to generate small snippets at the time ai is also an absolute godsend for formatting and converting stuff from anything and to anything you could e g dump your whole database structure to gemini and ask it to generate an api against it big task but since it is basically just a conversion task it will work very well", "model_tags": ["google"], "aspect_hints": ["performance_speed", "privacy", "usability_ux"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "Swiffy0", "node_time": "2025-06-03T09:05:47+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44167994, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I'm on the side of AI is a huge productivity booster (by my guess... 10x) But I don't want to make the claim lightly, so I did an experiment. I signed up for copilot pro, and have been using their 'edit' feature. This is more than just their auto complete. I set myself a goal to create a playable web game of classic frogger. It took 4 hours with copilot \"edit\" and my full attention. I didn't write a single line of code, but I did ask it to refactor and gave it a project description. I suspect this would have taken me 4 days full time to get to this level. Try it out:", "normalized_text": "i m on the side of ai is a huge productivity booster by my guess 10x but i don t want to make the claim lightly so i did an experiment i signed up for copilot pro and have been using their edit feature this is more than just their auto complete i set myself a goal to create a playable web game of classic frogger it took 4 hours with copilot edit and my full attention i didn t write a single line of code but i did ask it to refactor and gave it a project description i suspect this would have taken me 4 days full time to get to this level try it out", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "Voltage", "node_time": "2025-06-03T09:19:20+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44168128, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I'm working with python and it does not work very well, LLMs usually generates at least an order of magnitude more code than what I would write. That code often uses outdated practices, does poor design choices and does not understand hints like writing code in a way that reduce cognitive load, even when we explain that it means, i.e. keep the number of classes and functions small. It's the complete opposite of OP's main language GO, as he says: > Go has just enough type safety, an extensive standard library, and a culture that prizes (often repetitive) idiom. LLMs kick ass generating it. Python is an interpreted dynamically typed language and the static type checkers are not there yet (most popular 3rd parties libraries have no type hints for example). Also it allows for many different programming styles that the LLMs struggle to choose from. 1. Every extra line of code is much more risky. 2. It's much harder to verify the LLM's code. On the other hand I think rust will be in a good place in regards to LLMs in the next few years thanks to the robustness of the language and the quality of its diagnostic messages. Those 2 attributes should compound very well.", "normalized_text": "i m working with python and it does not work very well llms usually generates at least an order of magnitude more code than what i would write that code often uses outdated practices does poor design choices and does not understand hints like writing code in a way that reduce cognitive load even when we explain that it means i e keep the number of classes and functions small it s the complete opposite of op s main language go as he says go has just enough type safety an extensive standard library and a culture that prizes often repetitive idiom llms kick ass generating it python is an interpreted dynamically typed language and the static type checkers are not there yet most popular 3rd parties libraries have no type hints for example also it allows for many different programming styles that the llms struggle to choose from 1 every extra line of code is much more risky 2 it s much harder to verify the llm s code on the other hand i think rust will be in a good place in regards to llms in the next few years thanks to the robustness of the language and the quality of its diagnostic messages those 2 attributes should compound very well", "model_tags": [], "aspect_hints": ["regulation_policy", "community_tone"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "HenriTEL", "node_time": "2025-06-03T09:41:51+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44168514, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "The author defends mediocore code, yet wrote this piece: Where he dunks on how SSH access works in VSCode. I don't know. The code and architecture behind this feature may well be bananas, but gets the work done. Sounds like a clear case of mediocority. I wonder how does he reconcile those two articles together. For me this is more of a clickbait. Both of the articles. With that in mind, if I am nuts for being sceptical of LLMs, I think it is fair to call the author a clickbaiter.", "normalized_text": "the author defends mediocore code yet wrote this piece where he dunks on how ssh access works in vscode i don t know the code and architecture behind this feature may well be bananas but gets the work done sounds like a clear case of mediocority i wonder how does he reconcile those two articles together for me this is more of a clickbait both of the articles with that in mind if i am nuts for being sceptical of llms i think it is fair to call the author a clickbaiter", "model_tags": [], "aspect_hints": [], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "rotis", "node_time": "2025-06-03T10:49:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44168583, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "My main concern is not even mentioned in this article and there are hardly any comments here addressing it: Privacy / allowing 3rd parties to read and potentially train on your proprietary source code. I've used LLMs to crank out code for tedious things (like generating C-APIs and calling into poorly documented libraries) but I'm not letting them touch my code until I can run it 100% locally offline. Would love to use the agentic stuff but from what I've heard it's still too slow to run on a high end workstation with a single 4080. Or have things got better lately, and crucially is there good VisualStudio integration for running local agents / LLMs?", "normalized_text": "my main concern is not even mentioned in this article and there are hardly any comments here addressing it privacy allowing 3rd parties to read and potentially train on your proprietary source code i ve used llms to crank out code for tedious things like generating c apis and calling into poorly documented libraries but i m not letting them touch my code until i can run it 100 locally offline would love to use the agentic stuff but from what i ve heard it s still too slow to run on a high end workstation with a single 4080 or have things got better lately and crucially is there good visualstudio integration for running local agents llms", "model_tags": [], "aspect_hints": ["performance_speed", "privacy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "Fredkin", "node_time": "2025-06-03T10:58:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44168769, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "It's fascinating how over the past year we have had almost daily posts like this one, yet from the outside everything looks exactly the same, isn't that very weird? Why haven't we seen an explosion of new start-ups, products or features? Why do we still see hundreds of bug tickets on every issue tracking page? Have you noticed anything different on any changelog? I invite tptacek, or any other chatbot enthusiast around, to publish project metrics and show some actual numbers.", "normalized_text": "it s fascinating how over the past year we have had almost daily posts like this one yet from the outside everything looks exactly the same isn t that very weird why haven t we seen an explosion of new start ups products or features why do we still see hundreds of bug tickets on every issue tracking page have you noticed anything different on any changelog i invite tptacek or any other chatbot enthusiast around to publish project metrics and show some actual numbers", "model_tags": [], "aspect_hints": ["accuracy_reliability", "privacy", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "pera", "node_time": "2025-06-03T11:23:32+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44168874, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "The one main claim the article makes: Senior developers should not ignore the productivity gains from LLMs. Best use of evidence is deductive: Lots of code is tedious and uninteresting -> LLMs are fast at generating lots of tedious code -> LLMs help productivity. Weakest part of the argument: The list of rebuttals doesn't have an obvious organization to it. What exactly is the main argument they're arguing against? It's not stated outright but because the post is bookended by references to 'those smarter than me', I think this is an argument against the shaming of developers using (and loving) LLM tools. Which I think is fair. Overall, the post did not add anything to the general discussion. But the popularity of the author (and fly.io posts) may make it a beacon for some.", "normalized_text": "the one main claim the article makes senior developers should not ignore the productivity gains from llms best use of evidence is deductive lots of code is tedious and uninteresting llms are fast at generating lots of tedious code llms help productivity weakest part of the argument the list of rebuttals doesn t have an obvious organization to it what exactly is the main argument they re arguing against it s not stated outright but because the post is bookended by references to those smarter than me i think this is an argument against the shaming of developers using and loving llm tools which i think is fair overall the post did not add anything to the general discussion but the popularity of the author and fly io posts may make it a beacon for some", "model_tags": [], "aspect_hints": ["performance_speed", "usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "nilirl", "node_time": "2025-06-03T11:36:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44171335, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "When I made a mid career change to Cobol programming in 1981 my first manager (a suit as programmers referred to them then) pointed to a book on his desk; the title,as I can best recall was Programming Without Programmers. He \"You got in too late,\" he said. I retired from programming in 2010. The hype has a long history. I hope I'm around long enough to see how this plays out.", "normalized_text": "when i made a mid career change to cobol programming in 1981 my first manager a suit as programmers referred to them then pointed to a book on his desk the title as i can best recall was programming without programmers he you got in too late he said i retired from programming in 2010 the hype has a long history i hope i m around long enough to see how this plays out", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "roncar", "node_time": "2025-06-03T15:51:26+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44172069, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "The reason that I personally don't use LLMs was not addressed by the article: I haven't found a way to use it that makes me develop faster. The articles talks about \"tedious code.\" If you need to generate a large static value table or something, then OK an LLM might give you a really fast result and cut through the tedium. Most of us were already writing short scripts to do that. I'm open to the possibility that an LLM can do it faster. But it's such a rare requirement that the productivity gains are truly negligible here even if they can. And in those cases, it's obvious what the repetitive task needs to be. I often find myself writing the code by hand to be quicker than coming up with a prompt to get it to write the code that I then need to review for correctness. The article then mentions scaffolding. Things like \"bookkeeping\" when it comes to creating and setting up a new repo (whatever he means by that). This is why I have, historically, been a big fan of frameworks and generators. Point being, this is already a solved problem and I haven't found a way to further improve the state of this world with LLMs. LLMs might be an alternate tool that work just as well. But they haven't made my existing daily workflow any faster. Setting up new repos is also something that is done so rarely that even if an LLM netted a 100% increase in efficiency, it wouldn't really impact much. I am an AI \"skeptic\" but I'm not a naysayer. I do use LLMs regularly. I just don't use them for developing code because I have yet to find a problem that they solve for me. Don't get me wrong, there are problems that they can solve... I just haven't come across any solutions to previously-unsolved problems. Meaning I can swap an existing solution for an LLM-based one... and it is a valid solution... but I don't observe any increase in productivity from doing so. The existing solution was already working fine. I am genuinely looking forward to the day when this changes. When I identify a single existing problem without an existing solution that LLMs solve for me when developing software. I just have yet to come across one.", "normalized_text": "the reason that i personally don t use llms was not addressed by the article i haven t found a way to use it that makes me develop faster the articles talks about tedious code if you need to generate a large static value table or something then ok an llm might give you a really fast result and cut through the tedium most of us were already writing short scripts to do that i m open to the possibility that an llm can do it faster but it s such a rare requirement that the productivity gains are truly negligible here even if they can and in those cases it s obvious what the repetitive task needs to be i often find myself writing the code by hand to be quicker than coming up with a prompt to get it to write the code that i then need to review for correctness the article then mentions scaffolding things like bookkeeping when it comes to creating and setting up a new repo whatever he means by that this is why i have historically been a big fan of frameworks and generators point being this is already a solved problem and i haven t found a way to further improve the state of this world with llms llms might be an alternate tool that work just as well but they haven t made my existing daily workflow any faster setting up new repos is also something that is done so rarely that even if an llm netted a 100 increase in efficiency it wouldn t really impact much i am an ai skeptic but i m not a naysayer i do use llms regularly i just don t use them for developing code because i have yet to find a problem that they solve for me don t get me wrong there are problems that they can solve i just haven t come across any solutions to previously unsolved problems meaning i can swap an existing solution for an llm based one and it is a valid solution but i don t observe any increase in productivity from doing so the existing solution was already working fine i am genuinely looking forward to the day when this changes when i identify a single existing problem without an existing solution that llms solve for me when developing software i just have yet to come across one", "model_tags": [], "aspect_hints": ["performance_speed", "accuracy_reliability", "usability_ux", "regulation_policy"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "gspencley", "node_time": "2025-06-03T16:54:52+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44173272, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "I tend to agree with the gist of this, namely that the change is here and \"AI\" presents some huge potential to save me from having to do the tedious stuff. But we do need a bit of a sanity check. I'm in the middle of trying to convince any of the AIs that I have access to to write me some simple Lua. Specifically, I'm trying to write a query that returns a certain subset of pages from the Silverbullet V2 note tool. This isn't particularly difficult, but it's become this hilarious journey to try to get the AI to figure this problem out. Silverbullet is a niche use case, v2 even more so, but a reasonably skilled developer could peruse the API documentation and come up with a pretty good starting point. AI tools? Absolutely insane wrong answers. I finally specifically asked one or two of them not to guess with their answers and they just straight up said \"nah, we don't know how to do this.\" Point being: there's some real power in these tools, but if the ground is not already well-trodden, they risk creating a huge time sink that could be better served just learning to do the thing yourself.", "normalized_text": "i tend to agree with the gist of this namely that the change is here and ai presents some huge potential to save me from having to do the tedious stuff but we do need a bit of a sanity check i m in the middle of trying to convince any of the ais that i have access to to write me some simple lua specifically i m trying to write a query that returns a certain subset of pages from the silverbullet v2 note tool this isn t particularly difficult but it s become this hilarious journey to try to get the ai to figure this problem out silverbullet is a niche use case v2 even more so but a reasonably skilled developer could peruse the api documentation and come up with a pretty good starting point ai tools absolutely insane wrong answers i finally specifically asked one or two of them not to guess with their answers and they just straight up said nah we don t know how to do this point being there s some real power in these tools but if the ground is not already well trodden they risk creating a huge time sink that could be better served just learning to do the thing yourself", "model_tags": [], "aspect_hints": [], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "flkiwi", "node_time": "2025-06-03T18:46:47+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44173753, "root_story_id": 44163063, "node_type": "comment", "comment_depth": 1, "text": "Title nitpick: The amount is people who care about AI for coding assistance is a relative minority. For everyone else, there's 'AI', which has a huge branding problem. 'AI' is filling all search results with trash, and creating trash websites full of trash to fill up the rest of the search results. It's generating trash images to put at the top of every blog post. It's eating up all the server load with scraping. It's what's been fooling my dad every day on Facebook. When people are sick of AI, this is what they are talking about. AI hype people ignore this perspective each and every time. It doesn't matter how great your paper Mill's paper is, if you're dumping PCBs in the river, people are going to quite rightly get pissed off.", "normalized_text": "title nitpick the amount is people who care about ai for coding assistance is a relative minority for everyone else there s ai which has a huge branding problem ai is filling all search results with trash and creating trash websites full of trash to fill up the rest of the search results it s generating trash images to put at the top of every blog post it s eating up all the server load with scraping it s what s been fooling my dad every day on facebook when people are sick of ai this is what they are talking about ai hype people ignore this perspective each and every time it doesn t matter how great your paper mill s paper is if you re dumping pcbs in the river people are going to quite rightly get pissed off", "model_tags": ["meta"], "aspect_hints": ["usability_ux"], "context": {"root_title": "My AI skeptic friends are all nuts", "root_author": "tabletcorry", "root_url": "https://fly.io/blog/youre-all-nuts/", "node_author": "nancyminusone", "node_time": "2025-06-03T19:34:19+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226285, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Thanks for working on this guys. The current tax code is fairly crazy: you could spend a few million in salaries, sell 200k of software in a year and possibly owe taxes on that. Even if the company would otherwise be shutting down. The traditional capital asset treatment applied to software leaves a lot to be desired. Some software is a capital asset, but much just isn’t. Or at least should be considered to depreciate rapidly.", "normalized_text": "thanks for working on this guys the current tax code is fairly crazy you could spend a few million in salaries sell 200k of software in a year and possibly owe taxes on that even if the company would otherwise be shutting down the traditional capital asset treatment applied to software leaves a lot to be desired some software is a capital asset but much just isn’t or at least should be considered to depreciate rapidly", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "vessenes", "node_time": "2025-06-09T16:41:46+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226340, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "> but this issue has as close to a community consensus as HN gets Curious how this is assessed of you could share?", "normalized_text": "but this issue has as close to a community consensus as hn gets curious how this is assessed of you could share", "model_tags": [], "aspect_hints": ["community_tone"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "vasco", "node_time": "2025-06-09T16:46:10+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226383, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Signed. That said, here's my perspective on 174 (which should be reverted to full deduction on the year the expense is incurred). You do not have to amortize 100% of your engineering costs. Not even close. Here's the key: Development costs incurred to remove uncertainty are amortized. All other costs are deductible during the tax year where they are incurred. How does this work? You are going to design a new robot arm. In January, you spend $100K to \"remove uncertainty\". In rough strokes, this means discovering all the things you don't know and need to know for this robot arm to become a product. This amount will be amortized over five years under 174. Now, with uncertainty removed, you spend an additional $1.1MM from January until December for engineering implementation. No uncertainty being removed. Just building a product. This is 100% deductible that tax year. Analogy: You want to build a new brick wall with specific properties. You spend $100K to develop a new type of brick and $1.1MM to build the wall using that brick. The $100K is amortized, the $1.1MM is deductible in one shot. BTW, at year 6 the amortization schedule reaches steady-state and you are amortizing the full $100K every year. In other words, the impact of 174, if treated intelligently, is the time value of money until steady state is reached for the engineering costs incurred to remove uncertainty.", "normalized_text": "signed that said here s my perspective on 174 which should be reverted to full deduction on the year the expense is incurred you do not have to amortize 100 of your engineering costs not even close here s the key development costs incurred to remove uncertainty are amortized all other costs are deductible during the tax year where they are incurred how does this work you are going to design a new robot arm in january you spend 100k to remove uncertainty in rough strokes this means discovering all the things you don t know and need to know for this robot arm to become a product this amount will be amortized over five years under 174 now with uncertainty removed you spend an additional 1 1mm from january until december for engineering implementation no uncertainty being removed just building a product this is 100 deductible that tax year analogy you want to build a new brick wall with specific properties you spend 100k to develop a new type of brick and 1 1mm to build the wall using that brick the 100k is amortized the 1 1mm is deductible in one shot btw at year 6 the amortization schedule reaches steady state and you are amortizing the full 100k every year in other words the impact of 174 if treated intelligently is the time value of money until steady state is reached for the engineering costs incurred to remove uncertainty", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price", "regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "robomartin", "node_time": "2025-06-09T16:48:54+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226496, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "As a business owner, I've been adversely impacted by this. I still can't wrap my head around how this is legal or sustainable. If I buy $1MM of plant and equipment, I may not be able to expense it all in year 1, but I can relatively easily get a loan to finance the purchase of such--and manage my cashflows. The same is not for devs. I cannot easily get a loan for $1MM in dev salaries. In my own case, I don't need the loan to pay the salaries. I need the loan to pay the taxes for the portion of the salaries I cannot deduct as an expense. It's just insane.", "normalized_text": "as a business owner i ve been adversely impacted by this i still can t wrap my head around how this is legal or sustainable if i buy 1mm of plant and equipment i may not be able to expense it all in year 1 but i can relatively easily get a loan to finance the purchase of such and manage my cashflows the same is not for devs i cannot easily get a loan for 1mm in dev salaries in my own case i don t need the loan to pay the salaries i need the loan to pay the taxes for the portion of the salaries i cannot deduct as an expense it s just insane", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy", "business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "jgalt212", "node_time": "2025-06-09T16:57:53+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226503, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Happy to support this, desperately needs to be changed.", "normalized_text": "happy to support this desperately needs to be changed", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "silverlight", "node_time": "2025-06-09T16:58:21+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226571, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "A lot of people don't know what this Section 174 is about, so here's a brief explainer. Normally, when you have expenses, you deduct them off your revenue to find your taxable profit. If you have $1 million in sales, and $900k in costs, you have $100k in profit, and the government taxes you on that profit. Section 174 says you can't do this for software engineers. If you pay a software engineer, that's not \"really\" an \"expense\", regardless of the fact that you paid them. What you've actually done, Congress said, is bought a capital good, like a machine. And for calculating tax owed, you have to depreciate that over several years (5 in this case). Depreciating means that if you pay an engineer $200k in a year, in tax-world you only had $40k of real expense that year, even though you paid them $200k. So the effect is that it makes engineers much more expensive, because normally when a company hires an engineer, like they spend on any other expense, they can at least think \"well, they will reduce our profit, which reduces our tax obligation,\" but in this case software engineers are special and aren't deductible in the same way. In the case of the $200k engineer, you deduct the first $40k in the first year, then you can expense another $40k from that first year in the second year, the third $40k in the third year, and so on through the fifth year. So eventually you get to expense the entire first year of the engineer's pay, but only after five years. The effect is that companies wind up using their scarce capital to loan the federal government money for five years, and so engineers become a heavy financial burden. If a company hires too many engineers, they will owe the federal government income tax even in years in which they were unprofitable. These rules, by the way, don't apply to other personnel costs. If you hire an HR person or a corporate executive, you expense them in the year you paid them. It's a special rule for software engineers. It was passed by Congress during the first Trump administration in order to offset the costs of other corporate tax rate cuts, due to budgeting rules.", "normalized_text": "a lot of people don t know what this section 174 is about so here s a brief explainer normally when you have expenses you deduct them off your revenue to find your taxable profit if you have 1 million in sales and 900k in costs you have 100k in profit and the government taxes you on that profit section 174 says you can t do this for software engineers if you pay a software engineer that s not really an expense regardless of the fact that you paid them what you ve actually done congress said is bought a capital good like a machine and for calculating tax owed you have to depreciate that over several years 5 in this case depreciating means that if you pay an engineer 200k in a year in tax world you only had 40k of real expense that year even though you paid them 200k so the effect is that it makes engineers much more expensive because normally when a company hires an engineer like they spend on any other expense they can at least think well they will reduce our profit which reduces our tax obligation but in this case software engineers are special and aren t deductible in the same way in the case of the 200k engineer you deduct the first 40k in the first year then you can expense another 40k from that first year in the second year the third 40k in the third year and so on through the fifth year so eventually you get to expense the entire first year of the engineer s pay but only after five years the effect is that companies wind up using their scarce capital to loan the federal government money for five years and so engineers become a heavy financial burden if a company hires too many engineers they will owe the federal government income tax even in years in which they were unprofitable these rules by the way don t apply to other personnel costs if you hire an hr person or a corporate executive you expense them in the year you paid them it s a special rule for software engineers it was passed by congress during the first trump administration in order to offset the costs of other corporate tax rate cuts due to budgeting rules", "model_tags": [], "aspect_hints": ["cost_price", "regulation_policy", "business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "mediaman", "node_time": "2025-06-09T17:05:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226583, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "For folks that don't know the background on this, here's a layperson summary: - A business is usually taxed on its profits: you deduct your revenue from the cost of producing that revenue, and the delta is what you are taxed on. - In software businesses, this usually means if you spend $1M in software development to develop a web app, and it makes $1.1M in that year, you'd get taxed on the $100K profits. - However, a few years ago, the IRS stopped allowing the $1M to be deducted in the year it was incurred. Instead, the $1M was to be amortized over 5 years, so now the business can only count $200K as the deductible expense for that year. So now it's going to be taxed on \"profits\" of $900K. Assuming the tax rate is 20%, that means the business owes $180K in taxes, even though it has a total of $100K in the bank after the actual expenses were paid. So it would have to either borrow to pay taxes or raise venture capital, meaning that VC-funded companies would be advantaged over bootstrapped ones! - The letter's goal is to bring things back to how they were (and how they are for all other businesses): let businesses deduct their actual expenses from their actual revenue, and tax that actual profit. I am neither a lawyer nor an accountant, this is just my understanding of this issue. Edit: Switched the tax rate to 20%. The logic is still the same.", "normalized_text": "for folks that don t know the background on this here s a layperson summary a business is usually taxed on its profits you deduct your revenue from the cost of producing that revenue and the delta is what you are taxed on in software businesses this usually means if you spend 1m in software development to develop a web app and it makes 1 1m in that year you d get taxed on the 100k profits however a few years ago the irs stopped allowing the 1m to be deducted in the year it was incurred instead the 1m was to be amortized over 5 years so now the business can only count 200k as the deductible expense for that year so now it s going to be taxed on profits of 900k assuming the tax rate is 20 that means the business owes 180k in taxes even though it has a total of 100k in the bank after the actual expenses were paid so it would have to either borrow to pay taxes or raise venture capital meaning that vc funded companies would be advantaged over bootstrapped ones the letter s goal is to bring things back to how they were and how they are for all other businesses let businesses deduct their actual expenses from their actual revenue and tax that actual profit i am neither a lawyer nor an accountant this is just my understanding of this issue edit switched the tax rate to 20 the logic is still the same", "model_tags": [], "aspect_hints": ["cost_price", "regulation_policy", "business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "jsherwani", "node_time": "2025-06-09T17:06:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226604, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Signed. As a US-based developer, I fully support restoring the deductibility of software development expenses. This policy change quietly gutted countless startups and engineering teams—it’s long past time we fix it. Appreciate YC and folks like @itsluther pushing this forward. This isn’t just a tax issue—it’s about keeping innovation and talent thriving in the US. Let’s get it done.", "normalized_text": "signed as a us based developer i fully support restoring the deductibility of software development expenses this policy change quietly gutted countless startups and engineering teams—it’s long past time we fix it appreciate yc and folks like itsluther pushing this forward this isn’t just a tax issue—it’s about keeping innovation and talent thriving in the us let’s get it done", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "atxtechbro", "node_time": "2025-06-09T17:08:48+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226663, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "What's particularly wild about the choice to tax software development in this way is that it assumes that code is always asset. For companies that are pre product market fit, it's often a liability!", "normalized_text": "what s particularly wild about the choice to tax software development in this way is that it assumes that code is always asset for companies that are pre product market fit it s often a liability", "model_tags": [], "aspect_hints": ["business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "arturocamembert", "node_time": "2025-06-09T17:14:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226667, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "This is where it's really important to use a bug tracker that can distinguish between bugs/maintenance and feature development. The former can be deducted but the latter has to be amortized.", "normalized_text": "this is where it s really important to use a bug tracker that can distinguish between bugs maintenance and feature development the former can be deducted but the latter has to be amortized", "model_tags": [], "aspect_hints": ["accuracy_reliability", "usability_ux"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "siliconc0w", "node_time": "2025-06-09T17:14:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226680, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Forgive me if this has already been answered in one of the other threads (I haven't been following them), but: How does this work in other countries?", "normalized_text": "forgive me if this has already been answered in one of the other threads i haven t been following them but how does this work in other countries", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "cesarb", "node_time": "2025-06-09T17:15:38+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226773, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "I wonder if something like this could also help the hardware industry, thus encouraging more manufacturing in the US.", "normalized_text": "i wonder if something like this could also help the hardware industry thus encouraging more manufacturing in the us", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "analog31", "node_time": "2025-06-09T17:24:40+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226797, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Luther et al, would you be willing to share some high level statistics about the submissions, such as how many signatures it gets?", "normalized_text": "luther et al would you be willing to share some high level statistics about the submissions such as how many signatures it gets", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "freedomben", "node_time": "2025-06-09T17:26:47+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44226808, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "This US tax code change directly impacted my small business in a very real way that was directly felt by my household. In the past, it was a big boon for us and helped me afford to pay for some open source work and experimental things that helped our customers in the long run. Now we are back to mostly doing work-for-hire consulting. Even the experimental work I am doing, I am just paying for it and writing it off as typical business expenses. I cannot afford to take the credit because that means no deduction for this year. I don't have the cash in this small business context.", "normalized_text": "this us tax code change directly impacted my small business in a very real way that was directly felt by my household in the past it was a big boon for us and helped me afford to pay for some open source work and experimental things that helped our customers in the long run now we are back to mostly doing work for hire consulting even the experimental work i am doing i am just paying for it and writing it off as typical business expenses i cannot afford to take the credit because that means no deduction for this year i don t have the cash in this small business context", "model_tags": [], "aspect_hints": ["regulation_policy", "business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "rietta", "node_time": "2025-06-09T17:27:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44227044, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Thank you for helping to tackle this. The silence on this issue for the past few years from smaller software companies and their affiliates was surprising to me. The recent \"time bomb\" article was one of the few media pieces that actually took the time to describe it as anything other than a \"tax cut for huge tech companies\", which was refreshing. My current favorite theory as to why there hasn't been more of an outcry is that many companies ignored the rule change (either out of ignorance or as an alternative to going out of business), and are forced to remain silent.", "normalized_text": "thank you for helping to tackle this the silence on this issue for the past few years from smaller software companies and their affiliates was surprising to me the recent time bomb article was one of the few media pieces that actually took the time to describe it as anything other than a tax cut for huge tech companies which was refreshing my current favorite theory as to why there hasn t been more of an outcry is that many companies ignored the rule change either out of ignorance or as an alternative to going out of business and are forced to remain silent", "model_tags": [], "aspect_hints": ["regulation_policy", "business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "TheTaytay", "node_time": "2025-06-09T17:48:52+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44227073, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Signing a letter is fine, but will not have the same impact as phone calls made to your representatives. You don't need to use that site - the point is that if you want to have the loudest voice, make some calls.", "normalized_text": "signing a letter is fine but will not have the same impact as phone calls made to your representatives you don t need to use that site the point is that if you want to have the loudest voice make some calls", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "codingdave", "node_time": "2025-06-09T17:50:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44227496, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "the real question is why is r&d for startups in general amortized in the first place? doesn't this discourage startups pursuing risky hard science ventures?", "normalized_text": "the real question is why is r d for startups in general amortized in the first place doesn t this discourage startups pursuing risky hard science ventures", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "throwawaymaths", "node_time": "2025-06-09T18:22:59+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44227606, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "I seem to remember people being broadly in favor of this change at the time it was first proposed because it would elevade software development and create more long-term stability, but in a world where the primary focus is on quarterly funding rounded and acquisitions it obviously skews the numbers and thus the potential founded/early investor upside. There are two possible motivations for the impending change. One is the argument that deducting 100% of developer labor isn't ideal because developers create IP whose value can compound as an asset, rather than the labor being 'consumed' in production as with manufacturing (where any long-term benefit after the initial sale goes to the consumer). The other is that it's a legislative stick designed to herd a powerful investor/donor lobby into supporting budget legislation in exchange for turning the favorable tax treatment faucet back on.", "normalized_text": "i seem to remember people being broadly in favor of this change at the time it was first proposed because it would elevade software development and create more long term stability but in a world where the primary focus is on quarterly funding rounded and acquisitions it obviously skews the numbers and thus the potential founded early investor upside there are two possible motivations for the impending change one is the argument that deducting 100 of developer labor isn t ideal because developers create ip whose value can compound as an asset rather than the labor being consumed in production as with manufacturing where any long term benefit after the initial sale goes to the consumer the other is that it s a legislative stick designed to herd a powerful investor donor lobby into supporting budget legislation in exchange for turning the favorable tax treatment faucet back on", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "anigbrowl", "node_time": "2025-06-09T18:30:38+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44227699, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Possibly dumb question... For a medium/large company, is this really a big deal? Their payroll is relatively stable year-over-year, so after a few years, it all evens out (very roughly). Or am I missing something? IE, is this really an anti-competition law, designed to protect entrenched tech industry players and prevent up-starts from, well, starting?", "normalized_text": "possibly dumb question for a medium large company is this really a big deal their payroll is relatively stable year over year so after a few years it all evens out very roughly or am i missing something ie is this really an anti competition law designed to protect entrenched tech industry players and prevent up starts from well starting", "model_tags": [], "aspect_hints": ["regulation_policy", "business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "alistairSH", "node_time": "2025-06-09T18:39:14+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44227780, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "I've heard that many of the big tech layoffs where actually just moved / converting them to contracting groups, so they lose the direct head count but kept the developer via the intermediary. Have others heard this too and could this have been a way to label contractors differently so they don't fall under this tax code?", "normalized_text": "i ve heard that many of the big tech layoffs where actually just moved converting them to contracting groups so they lose the direct head count but kept the developer via the intermediary have others heard this too and could this have been a way to label contractors differently so they don t fall under this tax code", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "murdockq", "node_time": "2025-06-09T18:44:35+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44227788, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "I built a lightweight grassroots advocacy tool for this. It figures out who your reps are and sends them a pre-filled note based on what matters to you (you can edit/customize it before it sends). Includes a call script too if you're up for calling...", "normalized_text": "i built a lightweight grassroots advocacy tool for this it figures out who your reps are and sends them a pre filled note based on what matters to you you can edit customize it before it sends includes a call script too if you re up for calling", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "processing", "node_time": "2025-06-09T18:44:56+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44227864, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "What inspired working to reverse this now? I'm all for it, just curious as the law has existed for 8 years and been in effect for 3. Seemingly little interest from anyone in the tech world to put lobbying behind reversing it until this point. What changed?", "normalized_text": "what inspired working to reverse this now i m all for it just curious as the law has existed for 8 years and been in effect for 3 seemingly little interest from anyone in the tech world to put lobbying behind reversing it until this point what changed", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "garrickvanburen", "node_time": "2025-06-09T18:49:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44228054, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Doesnt this new law inhibit rapid turnover tho? Since it takes 5 years to get the full deduction of an employee’s salary, there is an incentive to keep the employee around. OTOH, the souless bean counters who want quarterly (if not shorter) time horizons, will simply decrease starting salaries and use other methods to be net zero. If they do shaft the software engineers, then the converse is true-no employee should stay at a job more than a year because only the corp will benefit as the deduction grows", "normalized_text": "doesnt this new law inhibit rapid turnover tho since it takes 5 years to get the full deduction of an employee’s salary there is an incentive to keep the employee around otoh the souless bean counters who want quarterly if not shorter time horizons will simply decrease starting salaries and use other methods to be net zero if they do shaft the software engineers then the converse is true no employee should stay at a job more than a year because only the corp will benefit as the deduction grows", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "bawana", "node_time": "2025-06-09T19:02:00+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44228085, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "@dang (and others). If you want a groundswell of support have you consider have you considered reaching out to game devs and indie game devs? It seems like they'd all be negatively affected. They'd spread the word to players.", "normalized_text": "dang and others if you want a groundswell of support have you consider have you considered reaching out to game devs and indie game devs it seems like they d all be negatively affected they d spread the word to players", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "socalgal2", "node_time": "2025-06-09T19:03:51+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44228273, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Signed and called my representative and senators. I ask simply \"If I have $1m of revenue and $1m of expenses that is entirely software dev salaries, what do you think my profit is for that year? How much should I be taxed on that?\"", "normalized_text": "signed and called my representative and senators i ask simply if i have 1m of revenue and 1m of expenses that is entirely software dev salaries what do you think my profit is for that year how much should i be taxed on that", "model_tags": [], "aspect_hints": ["business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "n_u", "node_time": "2025-06-09T19:19:20+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44228414, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Wish someone in EU do similar signing / votes for lobbying EU for taxing US Tech companies or applying 15 years amortization for all US products as a revenge - sorry US but 15 years amortization for everyone outside US is just worldwide tariff for any other software producers, freelancers, etc.", "normalized_text": "wish someone in eu do similar signing votes for lobbying eu for taxing us tech companies or applying 15 years amortization for all us products as a revenge sorry us but 15 years amortization for everyone outside us is just worldwide tariff for any other software producers freelancers etc", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "pzo", "node_time": "2025-06-09T19:31:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44228614, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Does Section 175 apply to other professions? For example, if I hire a full-time handyman for my office, does their salary count as a deductible cost? Sorry if this sounds naive—I'm genuinely struggling to understand why the labor of software engineers would be treated differently from other kinds of work. It seems logical that either all labor costs should count as costs, or none should. If different types of jobs are treated differently, what's the reasoning behind that?", "normalized_text": "does section 175 apply to other professions for example if i hire a full time handyman for my office does their salary count as a deductible cost sorry if this sounds naive—i m genuinely struggling to understand why the labor of software engineers would be treated differently from other kinds of work it seems logical that either all labor costs should count as costs or none should if different types of jobs are treated differently what s the reasoning behind that", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "hintymad", "node_time": "2025-06-09T19:46:24+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44228741, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "The SSBA (Small Software Business Alliance) was set up by Michele Hansen -- co-founder of Geocodio, (and the SSBA is now run by another person) for this reason -- to raise awareness in Washington DC of the issue with the Section 174 Capitalization changes and the efforts to repeal it. She has also spoken about it on podcasts:", "normalized_text": "the ssba small software business alliance was set up by michele hansen co founder of geocodio and the ssba is now run by another person for this reason to raise awareness in washington dc of the issue with the section 174 capitalization changes and the efforts to repeal it she has also spoken about it on podcasts", "model_tags": [], "aspect_hints": ["business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "gortok", "node_time": "2025-06-09T19:57:02+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44228813, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "The Small Software Business Alliance has been actively working on this issue since day one. And Michelle Hansen was an early organizer If you work at all in energy, the Clean Energy Business Network is also proactive in fighting for change. A couple of years ago they put me touch with Ron Wyden's staff. The Democrats are almost universally opposed to what was added to Section 174. Fight this thing - it is terrible. Not just for software but any innovative business in the USA.", "normalized_text": "the small software business alliance has been actively working on this issue since day one and michelle hansen was an early organizer if you work at all in energy the clean energy business network is also proactive in fighting for change a couple of years ago they put me touch with ron wyden s staff the democrats are almost universally opposed to what was added to section 174 fight this thing it is terrible not just for software but any innovative business in the usa", "model_tags": [], "aspect_hints": ["regulation_policy", "business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "jweir", "node_time": "2025-06-09T20:04:12+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44229124, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Salaries aren't a one-time expense, so is the amortization rolling? Like, year 1, you pay me $200k and deduct $40k. In year 2, you pay me another $200k, do you get to deduct $40k for year 1's salary and $40k for year 2's salary? I guess another way to ask is, does this mean that if you keep someone for 5 years and don't change my wages, is their yearly salary effectively fully deductible? If so, does that create incentives to try to keep employees longer-term in order to make them more cost-efficient?", "normalized_text": "salaries aren t a one time expense so is the amortization rolling like year 1 you pay me 200k and deduct 40k in year 2 you pay me another 200k do you get to deduct 40k for year 1 s salary and 40k for year 2 s salary i guess another way to ask is does this mean that if you keep someone for 5 years and don t change my wages is their yearly salary effectively fully deductible if so does that create incentives to try to keep employees longer term in order to make them more cost efficient", "model_tags": [], "aspect_hints": ["cost_price"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "flambojones", "node_time": "2025-06-09T20:31:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44229362, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "This will stay because it’s a barrier to smaller companies and nothing significant for larger companies that make political donations", "normalized_text": "this will stay because it’s a barrier to smaller companies and nothing significant for larger companies that make political donations", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "matt3210", "node_time": "2025-06-09T20:55:00+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44229609, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Does not restoring the tax deduction for software dev in the US help solo founders who don't draw salary to compete with large businesses?", "normalized_text": "does not restoring the tax deduction for software dev in the us help solo founders who don t draw salary to compete with large businesses", "model_tags": [], "aspect_hints": ["business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "nextn", "node_time": "2025-06-09T21:18:17+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44229785, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "My understanding is that the current \"Big Beautiful Bill\" reverses this", "normalized_text": "my understanding is that the current big beautiful bill reverses this", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "droptablemain", "node_time": "2025-06-09T21:35:49+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44230998, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "The tech community, correctly or incorrectly, is broadly seen as \"anti-tax cuts\", so - regardless of the actual merits of this particular tax cut - I'm not sure how well-received this campaign will be. I'd brace for some rather heavy sarcasm on social media for anyone brave enough to tread those waters.", "normalized_text": "the tech community correctly or incorrectly is broadly seen as anti tax cuts so regardless of the actual merits of this particular tax cut i m not sure how well received this campaign will be i d brace for some rather heavy sarcasm on social media for anyone brave enough to tread those waters", "model_tags": [], "aspect_hints": ["accuracy_reliability", "regulation_policy", "community_tone"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "MyPasswordSucks", "node_time": "2025-06-09T23:57:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44231217, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "I would not use section 174 as a reason not to startup but rather as a way to ensure you are running a lean ship. It’s very possible the rule change could be retroactive. Thats just my poker take on this bluff. It may not be retrospective or it may not happen at all. But indecision will kill some startups, the ones who don’t will be a year or three ahead.", "normalized_text": "i would not use section 174 as a reason not to startup but rather as a way to ensure you are running a lean ship it’s very possible the rule change could be retroactive thats just my poker take on this bluff it may not be retrospective or it may not happen at all but indecision will kill some startups the ones who don’t will be a year or three ahead", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "grepfru_it", "node_time": "2025-06-10T00:32:05+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44231537, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "I think people are missing the actual process used by Finance teams relating to this issue. I am a former CFO and spent a fair amount of time with this issue in my last role. The firm had a significant amount of software engineering expense related to its core operating system that was the backbone of the company. The FASB accounting rules drive the capitalization of software expenses, not the tax rules. The FASB definition of GAAP (Generally Accepted Accounting Principals) for US firms is very specific and requires significant detailed tracking to comply. As noted in one of the other posts, many companies want to capitalize as much software engineering expense as possible as that leads to higher operating income and net income. Bonuses, option grants and stock prices tend to be tied to those metrics. The argument is that building a piece of software should be treated like purchasing it off the shelf. If a firm pays $1M to implement SAP, it does not have to expense it all in one year, but rather depreciates it over its “expected life.” Since “expected life” is difficult to define for every piece of software, there are default lifetimes (similar to saying motor vehicles default to a 5 year depreciation schedule). Tax then generally follows the GAAP accounting except when the government intervenes to try and increase capital spending. Periodically the government will allow accelerated depreciation which increases operating expenses for tax purposes only which reduces current period cash taxes. Note total taxes do not change, only when they get paid. The Section 174 under discussion here is simply the same idea then applied to software development in an effort to juice hiring. For the people discussing whether the IRS is effectively tracking and enforcing this - the IRS really does not matter. A companies auditors enforce it. Without all of the necessary paperwork/digital audit trail, a firm in not permitted by the auditors to capitalize the expense. The same auditors have to sign off on the tax treatment as well. Finally, with respect to maintenance, the idea is meant to be similar to the treatment for machinery ( i.e. traditional capital expenditures). When a firm puts gas in the company truck or replaces tires or fixes a windshield, they do not capitalize those expenses. The idea is the expense do not fundamentally improve the item or meaningful extend the life beyond the initial expectations. Following that line of thought, maintenance releases are not thought to extend the life of the software while significant improvements to the software do and therefore can be capitalized. DISCLAIMER - while I was a CFO, I was not a Certified Accountant. What I have described above is what the accountants and my audit firms described to me as I worked through this issue in preparing financial statements.", "normalized_text": "i think people are missing the actual process used by finance teams relating to this issue i am a former cfo and spent a fair amount of time with this issue in my last role the firm had a significant amount of software engineering expense related to its core operating system that was the backbone of the company the fasb accounting rules drive the capitalization of software expenses not the tax rules the fasb definition of gaap generally accepted accounting principals for us firms is very specific and requires significant detailed tracking to comply as noted in one of the other posts many companies want to capitalize as much software engineering expense as possible as that leads to higher operating income and net income bonuses option grants and stock prices tend to be tied to those metrics the argument is that building a piece of software should be treated like purchasing it off the shelf if a firm pays 1m to implement sap it does not have to expense it all in one year but rather depreciates it over its “expected life ” since “expected life” is difficult to define for every piece of software there are default lifetimes similar to saying motor vehicles default to a 5 year depreciation schedule tax then generally follows the gaap accounting except when the government intervenes to try and increase capital spending periodically the government will allow accelerated depreciation which increases operating expenses for tax purposes only which reduces current period cash taxes note total taxes do not change only when they get paid the section 174 under discussion here is simply the same idea then applied to software development in an effort to juice hiring for the people discussing whether the irs is effectively tracking and enforcing this the irs really does not matter a companies auditors enforce it without all of the necessary paperwork digital audit trail a firm in not permitted by the auditors to capitalize the expense the same auditors have to sign off on the tax treatment as well finally with respect to maintenance the idea is meant to be similar to the treatment for machinery i e traditional capital expenditures when a firm puts gas in the company truck or replaces tires or fixes a windshield they do not capitalize those expenses the idea is the expense do not fundamentally improve the item or meaningful extend the life beyond the initial expectations following that line of thought maintenance releases are not thought to extend the life of the software while significant improvements to the software do and therefore can be capitalized disclaimer while i was a cfo i was not a certified accountant what i have described above is what the accountants and my audit firms described to me as i worked through this issue in preparing financial statements", "model_tags": [], "aspect_hints": ["privacy", "usability_ux", "regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "andrewlgood", "node_time": "2025-06-10T01:26:48+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44232079, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Note that this letter's requests DO NOT include voting against the reconciliation bill, just modifying it to add a carve-out to fix Section 174. While I agree that Section 174 desperately needs reform and is harmful to the tech industry, the bill as a whole must be opposed, not tweaked. There are many, many things wrong with the \"Big Beautiful Bill\", too many to fix through piecemeal efforts like this. It must be resolutely opposed, not endorsed with minor changes.", "normalized_text": "note that this letter s requests do not include voting against the reconciliation bill just modifying it to add a carve out to fix section 174 while i agree that section 174 desperately needs reform and is harmful to the tech industry the bill as a whole must be opposed not tweaked there are many many things wrong with the big beautiful bill too many to fix through piecemeal efforts like this it must be resolutely opposed not endorsed with minor changes", "model_tags": [], "aspect_hints": ["ethics", "regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "matthberg", "node_time": "2025-06-10T03:10:21+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44232125, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Japan has required amortization of capitalized software over five years for qualifying internal-use software since at least 2000. Correct me if I’m wrong, but I believe most other countries have similar rules. Until 2022, U.S. companies had a real competitive advantage. Software developer salaries in Japan are depressed—other roles too, but especially engineers. Without digging too deep, perhaps the previously unfavorable (now roughly equal) tax treatment of was perhaps a contributing factor.", "normalized_text": "japan has required amortization of capitalized software over five years for qualifying internal use software since at least 2000 correct me if i’m wrong but i believe most other countries have similar rules until 2022 u s companies had a real competitive advantage software developer salaries in japan are depressed—other roles too but especially engineers without digging too deep perhaps the previously unfavorable now roughly equal tax treatment of was perhaps a contributing factor", "model_tags": [], "aspect_hints": ["accuracy_reliability", "usability_ux", "regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "dwg", "node_time": "2025-06-10T03:20:57+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44233021, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Doesn't this incentivize outsourcing or fractional work to some degree, because that would still be counted as regular expenses?", "normalized_text": "doesn t this incentivize outsourcing or fractional work to some degree because that would still be counted as regular expenses", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "rubenvanwyk", "node_time": "2025-06-10T05:51:39+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44234536, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "As I understood it, it makes a difference between R&D on one hand, and \"maintenance\" on the other hand. This has resulted in that my US corporate overlords are shifting maintenance work to the US (better for taxes) and doing greenfield development where I am in the EU. This must be excellent for morale in the US office, but I'm not complaining.", "normalized_text": "as i understood it it makes a difference between r d on one hand and maintenance on the other hand this has resulted in that my us corporate overlords are shifting maintenance work to the us better for taxes and doing greenfield development where i am in the eu this must be excellent for morale in the us office but i m not complaining", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "alkonaut", "node_time": "2025-06-10T09:29:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44234551, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "By forcing software wages to be amortized over 5 years (15 for foreign devs), Section 174 has sapped cash flow, prompting layoffs and project cancellations totaling $3–4 M for some firms. Reinstating immediate expensing could unlock roughly $240 B in stuck deductions and supercharge R&D credits, materially bolstering hiring and keeping IP onshore. Has anyone modeled the macroeconomic gains of full expensing versus the budgetary trade-offs in the current $4.5 T tax proposal?", "normalized_text": "by forcing software wages to be amortized over 5 years 15 for foreign devs section 174 has sapped cash flow prompting layoffs and project cancellations totaling 3–4 m for some firms reinstating immediate expensing could unlock roughly 240 b in stuck deductions and supercharge r d credits materially bolstering hiring and keeping ip onshore has anyone modeled the macroeconomic gains of full expensing versus the budgetary trade offs in the current 4 5 t tax proposal", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "rajeshpatel15", "node_time": "2025-06-10T09:30:38+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44235785, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": ">We therefore urge Congress to include a retroactive carve-out from Section 174’s amortization requirements What if I'm in favor of restoring the previous deduction behavior, but not of doing it retroactively?", "normalized_text": "we therefore urge congress to include a retroactive carve out from section 174’s amortization requirements what if i m in favor of restoring the previous deduction behavior but not of doing it retroactively", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "Thorrez", "node_time": "2025-06-10T12:08:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44237221, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "I don't favor any tax breaks for big tech until they actually start paying meaningful taxes. There have been far too many giveaways. The country is running a massive deficit, and the current \"solution\" is to balloon the deficit and throw the poor under a bus.", "normalized_text": "i don t favor any tax breaks for big tech until they actually start paying meaningful taxes there have been far too many giveaways the country is running a massive deficit and the current solution is to balloon the deficit and throw the poor under a bus", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "adamc", "node_time": "2025-06-10T14:28:53+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44237348, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "I think the most impactful thing you can say about Section 174 is that if it continues, I will be starting my startups outside the US. An employee should be taxed like an employee, not a panel truck. There is no guarantee the software developer will produce anything of great value, so this is a tax on unrealized gains.", "normalized_text": "i think the most impactful thing you can say about section 174 is that if it continues i will be starting my startups outside the us an employee should be taxed like an employee not a panel truck there is no guarantee the software developer will produce anything of great value so this is a tax on unrealized gains", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "panny", "node_time": "2025-06-10T14:37:25+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44238384, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "I am writing my member of Congress right now. --- I'm writing to express my urgent concern regarding the negative impact of the 2022 Section 174 tax code changes on small businesses like mine. As owner of Rietta, Inc., a small cybersecurity firm, I still do much of the technical work. My wife and I have three young children under 6. My family and I have been directly negatively impacted by these changes from the 2017 act. Previously, the tax code helped us afford open-source and experimental work that benefited customers. For example, modernizing applications to run on Docker improved testing and deployment. Our State government clients now benefit, but this was once experimental. Now we're largely back to just work-for-hire consulting, treated as cost of goods sold. I don't have the cash to pay for experimental software development only to then amortize it over five years. If I have $100k revenue and spend $100k, the current code allows only a $20k deduction. I owe taxes on the other $80k despite no cash or documented asset value. Experimental software doesn't work like that in this field. I started this business 26 years ago. We provide important long-term custom programming and update work for private sector and State government clients (\"STATE A\" and \"STATE B\" judicial branches). Often, we work with code we didn't originally write. As a professional computer scientist and business owner, I rely on my CPA for tax compliance. If I've erred in my example, that's on me. But I can tell you this amortization requirement particularly cripples small businesses like Rietta, Inc., where cash flow is critical, severely limiting the quality of services I can afford to provide. I support undoing this tax change.", "normalized_text": "i am writing my member of congress right now i m writing to express my urgent concern regarding the negative impact of the 2022 section 174 tax code changes on small businesses like mine as owner of rietta inc a small cybersecurity firm i still do much of the technical work my wife and i have three young children under 6 my family and i have been directly negatively impacted by these changes from the 2017 act previously the tax code helped us afford open source and experimental work that benefited customers for example modernizing applications to run on docker improved testing and deployment our state government clients now benefit but this was once experimental now we re largely back to just work for hire consulting treated as cost of goods sold i don t have the cash to pay for experimental software development only to then amortize it over five years if i have 100k revenue and spend 100k the current code allows only a 20k deduction i owe taxes on the other 80k despite no cash or documented asset value experimental software doesn t work like that in this field i started this business 26 years ago we provide important long term custom programming and update work for private sector and state government clients state a and state b judicial branches often we work with code we didn t originally write as a professional computer scientist and business owner i rely on my cpa for tax compliance if i ve erred in my example that s on me but i can tell you this amortization requirement particularly cripples small businesses like rietta inc where cash flow is critical severely limiting the quality of services i can afford to provide i support undoing this tax change", "model_tags": [], "aspect_hints": ["security", "usability_ux", "cost_price", "regulation_policy", "business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "rietta", "node_time": "2025-06-10T15:58:24+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44238923, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "I am not sure I understand how amortizing these expenses benefits the government at all, as it is. I won't speak to the methods the government is using to value software, because others have made those points better than I could. First, I think the impact on large businesses has diminished greatly since 2022 anyway, so restoring the tax deduction would essentially give those businesses a 1-year \"bump\" in their deductions (since they'd be able to expense the previous 4 years of left-over deductions all at once, plus the current year in full). As far as I can tell, the expense isn't tied to individual workers, just the combined salary expense. So hiring/firing shouldn't be largely impacted. And, any benefit the government would have gotten from large corporations has (again, since 2022) now expired. For small businesses and start-ups, there is of course a much greater impact. And, ironically, I think the government is actually collecting less from small businesses in the long term, because the businesses that needed the full deduction to survive can't be collected from, having gone out of business. So the government isn't collecting any more taxes today than it used to. It is probably collecting less, depending on how much revenue has shifted from small (and now failing) businesses to large ones. And we're basically encouraging all of those more entrepreneurial technologists among us to go work for larger corporations instead of striking out on their own. I guess my question then, is, who does this tax code even benefit? Edit: looks like it was just a victim of the TCJA, meant to make TCJA look less expensive. I don't think it had its intended effect.", "normalized_text": "i am not sure i understand how amortizing these expenses benefits the government at all as it is i won t speak to the methods the government is using to value software because others have made those points better than i could first i think the impact on large businesses has diminished greatly since 2022 anyway so restoring the tax deduction would essentially give those businesses a 1 year bump in their deductions since they d be able to expense the previous 4 years of left over deductions all at once plus the current year in full as far as i can tell the expense isn t tied to individual workers just the combined salary expense so hiring firing shouldn t be largely impacted and any benefit the government would have gotten from large corporations has again since 2022 now expired for small businesses and start ups there is of course a much greater impact and ironically i think the government is actually collecting less from small businesses in the long term because the businesses that needed the full deduction to survive can t be collected from having gone out of business so the government isn t collecting any more taxes today than it used to it is probably collecting less depending on how much revenue has shifted from small and now failing businesses to large ones and we re basically encouraging all of those more entrepreneurial technologists among us to go work for larger corporations instead of striking out on their own i guess my question then is who does this tax code even benefit edit looks like it was just a victim of the tcja meant to make tcja look less expensive i don t think it had its intended effect", "model_tags": [], "aspect_hints": ["cost_price", "regulation_policy", "business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "twodave", "node_time": "2025-06-10T16:51:17+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44238929, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Is HN/YC going to submit the google form submissions to the relevant committee members on the signers' behalf?", "normalized_text": "is hn yc going to submit the google form submissions to the relevant committee members on the signers behalf", "model_tags": ["google"], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "ryanisnan", "node_time": "2025-06-10T16:51:54+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44239798, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "If the software written in a one year period of time for $100k is an asset then I, as a small business owner, can go to the local credit union and take out a loan on favorable terms with the that asset as collateral. No, of course not! They would laugh me out of the branch or the loan would be credit card interest rates. Software is demonstrably NOT AN ASSET like a major piece of equipment.", "normalized_text": "if the software written in a one year period of time for 100k is an asset then i as a small business owner can go to the local credit union and take out a loan on favorable terms with the that asset as collateral no of course not they would laugh me out of the branch or the loan would be credit card interest rates software is demonstrably not an asset like a major piece of equipment", "model_tags": [], "aspect_hints": ["usability_ux", "business_model"], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "rietta", "node_time": "2025-06-10T18:28:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44270503, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "As an international founder, I'd like the section 174 to be fully restored as it was before – not just for domestic R&D but offshore one as well, so we're not hit with 15 years deprecitation (it is as good as \"infinity\") I also own section174.com and sec174.com Would these help with visibility?", "normalized_text": "as an international founder i d like the section 174 to be fully restored as it was before – not just for domestic r d but offshore one as well so we re not hit with 15 years deprecitation it is as good as infinity i also own section174 com and sec174 com would these help with visibility", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "yrashk", "node_time": "2025-06-13T17:37:52+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44325662, "root_story_id": 44226145, "node_type": "comment", "comment_depth": 1, "text": "Discussion from beginning of 2023:", "normalized_text": "discussion from beginning of 2023", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Tell HN: Help restore the tax deduction for software dev in the US (Section 174)", "root_author": "dang", "root_url": NaN, "node_author": "EnnEmmEss", "node_time": "2025-06-20T08:18:31+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44567913, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "If in 2009 you claimed that the dominance of the smartphone was inevitable, it would have been because you were using one and understood its power, not because you were reframing away our free choice for some agenda. In 2025 I don't think you can really be taking advantage of AI to do real work and still see its mass adaptation as evitable. It's coming faster and harder than any tech in history. As scary as that is we can't wish it away.", "normalized_text": "if in 2009 you claimed that the dominance of the smartphone was inevitable it would have been because you were using one and understood its power not because you were reframing away our free choice for some agenda in 2025 i don t think you can really be taking advantage of ai to do real work and still see its mass adaptation as evitable it s coming faster and harder than any tech in history as scary as that is we can t wish it away", "model_tags": [], "aspect_hints": ["performance_speed"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "delichon", "node_time": "2025-07-15T04:49:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44567960, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "I hate AI. I'm so sick of it. I read a story about 14 year olds that are adopting AI boyfriends. They spend 18 hours a day in conversation with chatbots. Their parents are worried because they are withdrawing from school and losing their friends. I hate second guessing emails that I've read, wondering if my colleagues are even talking to me or if they are using AI. I hate the idea that AI will replace my job. Even if it unlocks \"economic value\" -- what does that even mean? We'll live in fucking blade runner but at least we'll all have a ton of money? I agree, nobody asked what I wanted. But if they did I'd tell them, I don't want it, I don't want any of it. Excuse me, I'll go outside now and play with my dogs and stare at a tree.", "normalized_text": "i hate ai i m so sick of it i read a story about 14 year olds that are adopting ai boyfriends they spend 18 hours a day in conversation with chatbots their parents are worried because they are withdrawing from school and losing their friends i hate second guessing emails that i ve read wondering if my colleagues are even talking to me or if they are using ai i hate the idea that ai will replace my job even if it unlocks economic value what does that even mean we ll live in fucking blade runner but at least we ll all have a ton of money i agree nobody asked what i wanted but if they did i d tell them i don t want it i don t want any of it excuse me i ll go outside now and play with my dogs and stare at a tree", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "mlsu", "node_time": "2025-07-15T05:02:44+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44567976, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "I think you are confusing \"I don't like it\" with \"It's not going to happen\". Just because you don't like it, it doesn't mean it's not going to happen. Observe the world without prejudice. Think rationally without prejudice.", "normalized_text": "i think you are confusing i don t like it with it s not going to happen just because you don t like it it doesn t mean it s not going to happen observe the world without prejudice think rationally without prejudice", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "paradite", "node_time": "2025-07-15T05:05:35+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568011, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "If someone invested a lot of money in something, they probably are convinced that something is inevitable. Otherwise they would not invest their money. However, sometimes they may be a little bit helping their luck", "normalized_text": "if someone invested a lot of money in something they probably are convinced that something is inevitable otherwise they would not invest their money however sometimes they may be a little bit helping their luck", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "p0w3n3d", "node_time": "2025-07-15T05:13:31+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568045, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "> I’m certainly not convinced that they’re the future I want. But what I’m most certain of is that we have choices about what our future should look like, and how we choose to use machines to build it. While I must admit we have some choice here, it is limited. No matter what, there will be models of language, we know how they work, there is no turning back from it. We might wish many things but one thing we can't do is to revert time to a moment when these discoveries did not exist.", "normalized_text": "i’m certainly not convinced that they’re the future i want but what i’m most certain of is that we have choices about what our future should look like and how we choose to use machines to build it while i must admit we have some choice here it is limited no matter what there will be models of language we know how they work there is no turning back from it we might wish many things but one thing we can t do is to revert time to a moment when these discoveries did not exist", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "visarga", "node_time": "2025-07-15T05:21:30+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568075, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Wasn’t crypto supposed to have replaced fiat currency by now, or something?", "normalized_text": "wasn’t crypto supposed to have replaced fiat currency by now or something", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "mbgerring", "node_time": "2025-07-15T05:26:24+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568076, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "There may be an \"LLM Winter\" as people discover that LLMs can't be trusted to do anything. Look for frantic efforts by companies to offload responsibility for LLM mistakes onto consumers. We've got to have something that has solid \"I don't know\" and \"I don't know how to do this\" outputs. We're starting to see reports of LLM usage having negative value for programmers, even though they think it's helping. Too much effort goes into cleaning up LLM messes.", "normalized_text": "there may be an llm winter as people discover that llms can t be trusted to do anything look for frantic efforts by companies to offload responsibility for llm mistakes onto consumers we ve got to have something that has solid i don t know and i don t know how to do this outputs we re starting to see reports of llm usage having negative value for programmers even though they think it s helping too much effort goes into cleaning up llm messes", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "Animats", "node_time": "2025-07-15T05:26:42+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568080, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "I do agree that those who claim AI is inevitable are essentially threatening you.", "normalized_text": "i do agree that those who claim ai is inevitable are essentially threatening you", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "anothernewdude", "node_time": "2025-07-15T05:27:18+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568111, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "This concept is closely reated to politics of inevitability coined by Timothy Snyder. \"...the politics of inevitability – a sense that the future is just more of the present, that the laws of progress are known, that there are no alternatives, and therefore nothing really to be done.\"[0] [0] This article in question obviously applied it within the commercial world but at the end it has to do with language that takes away agency.", "normalized_text": "this concept is closely reated to politics of inevitability coined by timothy snyder the politics of inevitability – a sense that the future is just more of the present that the laws of progress are known that there are no alternatives and therefore nothing really to be done 0 0 this article in question obviously applied it within the commercial world but at the end it has to do with language that takes away agency", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "trash_cat", "node_time": "2025-07-15T05:33:02+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568114, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "I think two things can be true simultaneously: 1. LLMs are a new technology and it's hard to put the genie back in the bottle with that. It's difficult to imagine a future where they don't continue to exist in some form, with all the timesaving benefits and social issues that come with them. 2. Almost three years in, companies investing in LLMs have not yet discovered a business model that justifies the massive expenditure of training and hosting them, the majority of consumer usage is at the free tier, the industry is seeing the first signs of pulling back investments, and model capabilities are plateauing at a level where most people agree that the output is trite and unpleasant to consume. There are many technologies that have seemed inevitable and seen retreats under the lack of commensurate business return (the supersonic jetliner), and several that seemed poised to displace both old tech and labor but have settled into specific use cases (the microwave oven). Given the lack of a sufficiently profitable business model, it feels as likely as not that LLMs settle somewhere a little less remarkable, and hopefully less annoying, than today's almost universally disliked attempts to cram it everywhere.", "normalized_text": "i think two things can be true simultaneously 1 llms are a new technology and it s hard to put the genie back in the bottle with that it s difficult to imagine a future where they don t continue to exist in some form with all the timesaving benefits and social issues that come with them 2 almost three years in companies investing in llms have not yet discovered a business model that justifies the massive expenditure of training and hosting them the majority of consumer usage is at the free tier the industry is seeing the first signs of pulling back investments and model capabilities are plateauing at a level where most people agree that the output is trite and unpleasant to consume there are many technologies that have seemed inevitable and seen retreats under the lack of commensurate business return the supersonic jetliner and several that seemed poised to displace both old tech and labor but have settled into specific use cases the microwave oven given the lack of a sufficiently profitable business model it feels as likely as not that llms settle somewhere a little less remarkable and hopefully less annoying than today s almost universally disliked attempts to cram it everywhere", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price", "business_model"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "lsy", "node_time": "2025-07-15T05:33:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568158, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "In the 90s a friend told me about the internet. And that he knows someone who is in a university and has access to it and can show us. An hour later, we were sitting in front of a computer in that university and watched his friend surfing the web. Clicking on links, receiving pages of text. Faster than one could read. In a nice layout. Even with images. And links to other pages. We were shocked. No printing, no shipping, no waiting. This was the future. It was inevitable. Yesterday I wanted to rewrite a program to use a large library that would have required me to dive deep down into the documentation or read its code to tackle my use case. As a first try, I just copy+pasted the whole library and my whole program into GPT 4.1 and told it to rewrite it using the library. It succeeded at the first attempt. The rewrite itself was small enough that I could read all code changes in 15 minutes and make a few stylistic changes. Done. Hours of time saved. This is the future. It is inevitable. PS: Most replies seem to compare my experience to experiences that the responders have with agentic coding, where the developer is iteratively changing the code by chatting with an LLM. I am not doing that. I use a \"One prompt one file. No code edits.\" approach, which I describe here:", "normalized_text": "in the 90s a friend told me about the internet and that he knows someone who is in a university and has access to it and can show us an hour later we were sitting in front of a computer in that university and watched his friend surfing the web clicking on links receiving pages of text faster than one could read in a nice layout even with images and links to other pages we were shocked no printing no shipping no waiting this was the future it was inevitable yesterday i wanted to rewrite a program to use a large library that would have required me to dive deep down into the documentation or read its code to tackle my use case as a first try i just copy pasted the whole library and my whole program into gpt 4 1 and told it to rewrite it using the library it succeeded at the first attempt the rewrite itself was small enough that i could read all code changes in 15 minutes and make a few stylistic changes done hours of time saved this is the future it is inevitable ps most replies seem to compare my experience to experiences that the responders have with agentic coding where the developer is iteratively changing the code by chatting with an llm i am not doing that i use a one prompt one file no code edits approach which i describe here", "model_tags": ["openai"], "aspect_hints": ["performance_speed", "usability_ux"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "mg", "node_time": "2025-07-15T05:41:36+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568164, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "LLM is an almost complete waste of time. Advocates of LLM are not accurately measuring their time and productivity, and comparing that to LLM-free alternative approaches.", "normalized_text": "llm is an almost complete waste of time advocates of llm are not accurately measuring their time and productivity and comparing that to llm free alternative approaches", "model_tags": [], "aspect_hints": ["accuracy_reliability"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "kazinator", "node_time": "2025-07-15T05:42:08+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568202, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "It's inevitable because it's here. LLMs aren't the \"future\" anymore, they're the present. They're unseating Google as the SOTA method of finding information on the internet. People have been trying to do that for decades. The future probably holds even bigger things, but even if it plateaus for a while, showing real ability to defeat traditional search is a crazy start and just one example.", "normalized_text": "it s inevitable because it s here llms aren t the future anymore they re the present they re unseating google as the sota method of finding information on the internet people have been trying to do that for decades the future probably holds even bigger things but even if it plateaus for a while showing real ability to defeat traditional search is a crazy start and just one example", "model_tags": ["google"], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "nperez", "node_time": "2025-07-15T05:50:04+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568250, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Two things are very clearly true: 1) LLMs can do a lot of things that previous computing techniques could not do and we need time to figure out how best to harness and utilize those capabilities; but also 2) there is a wide range of powerful people who have tons of incentive to ride the hype wave regardless of where things will actually land. To the article's point—I don't think it's useful to accept the tech CEO framing and engage on their terms at all. They are mostly talking to the markets anyway. We are the ones who understand how technology works, so we're best positioned to evaluate LLMs more objectively, and we should decide our own framing. My framing is that LLMs are just another tool in a long line of software tooling improvements. Sure, it feels sort of miraculous and perhaps threatening that LLMs can write working code so easily. But when you think of all the repetitive CRUD and business logic that has been written over the decades to address myriad permutations and subtly varying contexts of the many human organizations that are willing to pay for software to be written, it's not surprising that we could figure out how to make a giant stochastic generator that can do an adequate job generating new permutations based on the right context and prompts. As a technologist I want to understand what LLMs can do and how they can serve my personal goals. If I don't want to use them I won't, but I also owe it to myself to understand how their capabilities evolve so I can make an informed decision. I am not going to start a crusade against them out of nostalgia or wishful thinking as I can think of nothing so futile as positioning myself in direct opposition to a massive hype tsunami.", "normalized_text": "two things are very clearly true 1 llms can do a lot of things that previous computing techniques could not do and we need time to figure out how best to harness and utilize those capabilities but also 2 there is a wide range of powerful people who have tons of incentive to ride the hype wave regardless of where things will actually land to the article s point—i don t think it s useful to accept the tech ceo framing and engage on their terms at all they are mostly talking to the markets anyway we are the ones who understand how technology works so we re best positioned to evaluate llms more objectively and we should decide our own framing my framing is that llms are just another tool in a long line of software tooling improvements sure it feels sort of miraculous and perhaps threatening that llms can write working code so easily but when you think of all the repetitive crud and business logic that has been written over the decades to address myriad permutations and subtly varying contexts of the many human organizations that are willing to pay for software to be written it s not surprising that we could figure out how to make a giant stochastic generator that can do an adequate job generating new permutations based on the right context and prompts as a technologist i want to understand what llms can do and how they can serve my personal goals if i don t want to use them i won t but i also owe it to myself to understand how their capabilities evolve so i can make an informed decision i am not going to start a crusade against them out of nostalgia or wishful thinking as i can think of nothing so futile as positioning myself in direct opposition to a massive hype tsunami", "model_tags": [], "aspect_hints": ["regulation_policy", "business_model"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "dasil003", "node_time": "2025-07-15T05:58:58+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568304, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "One of the negative consequences of the “modern secular age” is that many very intelligent, thoughtful people feel justified in brushing away millennia of philosophical and religious thought because they deem it outdated or no longer relevant. (The book A Secular Age is a great read on this, btw, I think I’ve recommended it here on HN at least half a dozen times.) And so a result of this is that they fail to notice the same recurring psychological patterns that underly thoughts about how the world is, and how it will be in the future - and then adjust their positions because of this awareness. For example - this AI inevitabilism stuff is not dissimilar to many ideas originally from the Reformation, like predestination. The notion that history is just on some inevitable pre-planned path is not a new idea, except now the actor has changed from God to technology. On a psychological level it’s the same thing: an offloading of freedom and responsibility to a powerful, vaguely defined force that may or may not exist outside the collective minds of human society.", "normalized_text": "one of the negative consequences of the “modern secular age” is that many very intelligent thoughtful people feel justified in brushing away millennia of philosophical and religious thought because they deem it outdated or no longer relevant the book a secular age is a great read on this btw i think i’ve recommended it here on hn at least half a dozen times and so a result of this is that they fail to notice the same recurring psychological patterns that underly thoughts about how the world is and how it will be in the future and then adjust their positions because of this awareness for example this ai inevitabilism stuff is not dissimilar to many ideas originally from the reformation like predestination the notion that history is just on some inevitable pre planned path is not a new idea except now the actor has changed from god to technology on a psychological level it’s the same thing an offloading of freedom and responsibility to a powerful vaguely defined force that may or may not exist outside the collective minds of human society", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "keiferski", "node_time": "2025-07-15T06:08:46+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568455, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Earlier today I was scrolling at the “work at a startup” posts. Seems like everyone is doing LLM stuff. We are back at the “uber for X” but now it is “ChatGPT for X”. I get it, but I’ve never felt more uninspired looking at what yc startups are working on today. For the first time they all feel incredibly generic", "normalized_text": "earlier today i was scrolling at the “work at a startup” posts seems like everyone is doing llm stuff we are back at the “uber for x” but now it is “chatgpt for x” i get it but i’ve never felt more uninspired looking at what yc startups are working on today for the first time they all feel incredibly generic", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "ccortes", "node_time": "2025-07-15T06:35:31+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568562, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "The hardest part about inevitablism here is that the people who are making the argument this is inevitable are the same people who are the people who are shoveling hundreds of millions of dollars into it. Into the development, the use, the advertisement. The foxes are building doors into the hen houses and saying there’s nothing to be done, foxes are going to get in so we might as well make it something that works for everyone.", "normalized_text": "the hardest part about inevitablism here is that the people who are making the argument this is inevitable are the same people who are the people who are shoveling hundreds of millions of dollars into it into the development the use the advertisement the foxes are building doors into the hen houses and saying there’s nothing to be done foxes are going to get in so we might as well make it something that works for everyone", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "sircastor", "node_time": "2025-07-15T06:48:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568688, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Did anyone even read the article? Maybe you should get an LLM to bullet point it for you. The author isn't arguing about whether LLMs (or AI) is inevitable or not. They are saying you don't have to operate within their framing. You should be thinking about whether this thing is really good for us and not just jumping on the wagon and toeing the line because you're told it's inevitable. I've noticed more and more the go to technique for marketing anything now is FOMO. It works. Don't let it work on you. Don't buy into a thing just because everyone else is. Most of the time you aren't missing out on anything at all. Some of the time the thing is actively harmful to the participants and society.", "normalized_text": "did anyone even read the article maybe you should get an llm to bullet point it for you the author isn t arguing about whether llms or ai is inevitable or not they are saying you don t have to operate within their framing you should be thinking about whether this thing is really good for us and not just jumping on the wagon and toeing the line because you re told it s inevitable i ve noticed more and more the go to technique for marketing anything now is fomo it works don t let it work on you don t buy into a thing just because everyone else is most of the time you aren t missing out on anything at all some of the time the thing is actively harmful to the participants and society", "model_tags": [], "aspect_hints": ["usability_ux", "ethics", "regulation_policy", "business_model"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "globular-toast", "node_time": "2025-07-15T07:06:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568754, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Language is not knowledge and knowledge when reduced to a language becomes here say until it is redone and implemented in our context. Both of them have nothing to do with wisdom. LLM's hash out our language and art to death but AI doesn't mind what they mean to us. Without our constraints and use, they would stop running. We should be building guardian angels to save us from ourselves and not evil demons to conquer the world. - John Eischen © adagp paris art humanitarian use is authorized except for any Al uses", "normalized_text": "language is not knowledge and knowledge when reduced to a language becomes here say until it is redone and implemented in our context both of them have nothing to do with wisdom llm s hash out our language and art to death but ai doesn t mind what they mean to us without our constraints and use they would stop running we should be building guardian angels to save us from ourselves and not evil demons to conquer the world john eischen © adagp paris art humanitarian use is authorized except for any al uses", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "jeisc", "node_time": "2025-07-15T07:17:49+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568772, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "How do you differentiate between an effective debater using inevitabilism as a technique to win a debate, and an effective thinker making a convincing argument that something is likely to be inevitable? How do you differentiate between an effective debater \"controlling the framing of a conversation\" and an effective thinker providing a new perspective on a shared experience? How do you differentiate between a good argument and a good idea? I don't think you can really? You could say intent plays a part -- that someone with an intent to manipulate can use debating tools as tricks. But still, even if someone with bad intentions makes a good argument, isn't it still a good argument?", "normalized_text": "how do you differentiate between an effective debater using inevitabilism as a technique to win a debate and an effective thinker making a convincing argument that something is likely to be inevitable how do you differentiate between an effective debater controlling the framing of a conversation and an effective thinker providing a new perspective on a shared experience how do you differentiate between a good argument and a good idea i don t think you can really you could say intent plays a part that someone with an intent to manipulate can use debating tools as tricks but still even if someone with bad intentions makes a good argument isn t it still a good argument", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "cdrini", "node_time": "2025-07-15T07:21:05+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44568784, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "I really like what is hidden between the lines of this text, it is only something a human can understand. The entire comment section over here reflects the uncanny valley. This blog post is a work of art LOL", "normalized_text": "i really like what is hidden between the lines of this text it is only something a human can understand the entire comment section over here reflects the uncanny valley this blog post is a work of art lol", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "mawadev", "node_time": "2025-07-15T07:22:50+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44569257, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Disclaimer - I am building an AI web retriever (Linkup.so) so I have a natural bias - LLMs aren’t just a better Google, they’re a redefinition of search itself. Traditional search is an app: you type, scroll through ads and 10 blue links, and dig for context. That model worked when the web was smaller, but now it’s overwhelming. LLMs shift search to an infrastructure, a way to get contextualized, synthesized answers directly, tailored to your specific need. Yes, they can hallucinate, but so can the web. It’s not about replacing Google—it’s about replacing the experience of searching (actually they probably will less and less 'experience' of searching)", "normalized_text": "disclaimer i am building an ai web retriever linkup so so i have a natural bias llms aren’t just a better google they’re a redefinition of search itself traditional search is an app you type scroll through ads and 10 blue links and dig for context that model worked when the web was smaller but now it’s overwhelming llms shift search to an infrastructure a way to get contextualized synthesized answers directly tailored to your specific need yes they can hallucinate but so can the web it’s not about replacing google—it’s about replacing the experience of searching actually they probably will less and less experience of searching", "model_tags": ["google"], "aspect_hints": ["accuracy_reliability", "usability_ux", "ethics", "regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "Boristoledano", "node_time": "2025-07-15T08:54:30+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44569261, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "AI is not inevitable, because technological progress in general is not inevitable. It is shapeable by economic incentives just like everything else. It can be ground into powder by resource starvation. We've long known that certain forms of financial bounties levied upon scientists working at the frontier of sciences we want to freeze in place work effectively with a minimum of policing and international cooperation. If a powerful country is willing to be a jerk (heavens!) and allow these kinds of bounties to be turned in even on extranationals, you don't need the international cooperation. But you do get a way to potentially kickstart a new Nash equilibrium that keeps itself going as soon as other countries adopt the same bounty-based policy. This mechanism has been floating around for at least a decade now. It's not news. Even the most inevitable seeming scientific developments can be effectively rerouted around using it. The question is whether you genuinely, earnestly believe what lies beyond the frontier is too dangerous to be let out, and in almost all cases the answer to that should be no. I post this mostly because inevitabilist arguments will always retain their power so long as you can come up with a coherent profit motive for something to be pursued. You don't get far with good-feeling spiels that amount to plaintive cries in a tornado. You need actual object level proposals on how to make the inevitable evitable.", "normalized_text": "ai is not inevitable because technological progress in general is not inevitable it is shapeable by economic incentives just like everything else it can be ground into powder by resource starvation we ve long known that certain forms of financial bounties levied upon scientists working at the frontier of sciences we want to freeze in place work effectively with a minimum of policing and international cooperation if a powerful country is willing to be a jerk heavens and allow these kinds of bounties to be turned in even on extranationals you don t need the international cooperation but you do get a way to potentially kickstart a new nash equilibrium that keeps itself going as soon as other countries adopt the same bounty based policy this mechanism has been floating around for at least a decade now it s not news even the most inevitable seeming scientific developments can be effectively rerouted around using it the question is whether you genuinely earnestly believe what lies beyond the frontier is too dangerous to be let out and in almost all cases the answer to that should be no i post this mostly because inevitabilist arguments will always retain their power so long as you can come up with a coherent profit motive for something to be pursued you don t get far with good feeling spiels that amount to plaintive cries in a tornado you need actual object level proposals on how to make the inevitable evitable", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price", "regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "hiAndrewQuinn", "node_time": "2025-07-15T08:55:10+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44569518, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "My belief is that whatever technology can be invented by humans (under the constraints of the laws of physics, etc) will eventually be invented. I don't have a strong argument for this; it's just what makes sense to me. If true, then an immediate corollary is that if it is possible for humans to create LLMs (or other AI systems) which can program, or do some other tasks, better than humans can, that will happen. Inevitabilism? I don't think so. If that comes to pass, then what people will do with that technology, and what will change as a result, will be up to the people who are alive at the time. But not creating the technology is not an option, if it's within the realm of what humans can possibly create.", "normalized_text": "my belief is that whatever technology can be invented by humans under the constraints of the laws of physics etc will eventually be invented i don t have a strong argument for this it s just what makes sense to me if true then an immediate corollary is that if it is possible for humans to create llms or other ai systems which can program or do some other tasks better than humans can that will happen inevitabilism i don t think so if that comes to pass then what people will do with that technology and what will change as a result will be up to the people who are alive at the time but not creating the technology is not an option if it s within the realm of what humans can possibly create", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "alexdowad", "node_time": "2025-07-15T09:42:49+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44569631, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Not sure I get the author of this piece. The tech leaders are clearly saying AI is inevitable, they're not saying LLMs are inevitable. Big tech is constantly working on new types of AI such as world models.", "normalized_text": "not sure i get the author of this piece the tech leaders are clearly saying ai is inevitable they re not saying llms are inevitable big tech is constantly working on new types of ai such as world models", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "miscend", "node_time": "2025-07-15T10:06:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44569716, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "This is a fantastic framing method. Anyone who sees the future differently to you can be brushed aside as “an inevitablist,” and the only conversations worth engaging are those that already accept your premise. --- This argument so easily commits sudoku that I couldn't help myself. It's philosophical relativism, and self-immolates for the same reason -- it's inconsistent. It eats itself.", "normalized_text": "this is a fantastic framing method anyone who sees the future differently to you can be brushed aside as “an inevitablist ” and the only conversations worth engaging are those that already accept your premise this argument so easily commits sudoku that i couldn t help myself it s philosophical relativism and self immolates for the same reason it s inconsistent it eats itself", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "a_wild_dandan", "node_time": "2025-07-15T10:24:40+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44569762, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "I don't think it's inevitable, for very few things are really inevitable. However, I find LLM-s good and useful. First the chat bots, now the coding agents. Looks to me medical consultation, 2nd opinion and the like - are not far behind. Enough people already use them for that. I give my lab tests results to ChatGPT. Tbh can't fault the author for motivated reasoning. Looks to me it goes like: this is not a future I want -> therefore it should not happen -> therefore it will not happen. Because by the same motivated reasoning: for me it is the future I want. To be able to interact with a computer via language, speech and more. For the computer to be smart, instead of dumb, as it is now. If I can have the computer enhance my smarts, my information processing power, my memory - the way writing allows me to off-load from my head onto paper, a calculator allows me to manipulate numbers, and computer toils for days instead myself - then I will probably want for the AI to complement, enhance me too.", "normalized_text": "i don t think it s inevitable for very few things are really inevitable however i find llm s good and useful first the chat bots now the coding agents looks to me medical consultation 2nd opinion and the like are not far behind enough people already use them for that i give my lab tests results to chatgpt tbh can t fault the author for motivated reasoning looks to me it goes like this is not a future i want therefore it should not happen therefore it will not happen because by the same motivated reasoning for me it is the future i want to be able to interact with a computer via language speech and more for the computer to be smart instead of dumb as it is now if i can have the computer enhance my smarts my information processing power my memory the way writing allows me to off load from my head onto paper a calculator allows me to manipulate numbers and computer toils for days instead myself then i will probably want for the ai to complement enhance me too", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "ljosifov", "node_time": "2025-07-15T10:36:38+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44569887, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "The company name was changed from Facebook to Meta because Mark thought the metaverse was inevitable, it's ironic that you use a quote from him", "normalized_text": "the company name was changed from facebook to meta because mark thought the metaverse was inevitable it s ironic that you use a quote from him", "model_tags": ["meta"], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "ojr", "node_time": "2025-07-15T11:02:31+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44570035, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "I was going to make an argument that it's inevitable, because at some point compute will get so cheap that someone could just train one at home, and since the knowledge of how to do it is out there, people will do it. But seeing that a company like Meta is using >100k GPUs to train these models, even at 25% yearly improvement it would still take until the year ~2060 before someone could buy 50 GPUs and have the equivalent power to train one privately. So I suppose if society decided to outlaw LLM training, or a market crash put off companies from continuing to do it, it might be possible to put the genie back in the bottle for a few decades. I wouldn't be surprised however if there are still 10x algorithmic improvements to be found too...", "normalized_text": "i was going to make an argument that it s inevitable because at some point compute will get so cheap that someone could just train one at home and since the knowledge of how to do it is out there people will do it but seeing that a company like meta is using 100k gpus to train these models even at 25 yearly improvement it would still take until the year 2060 before someone could buy 50 gpus and have the equivalent power to train one privately so i suppose if society decided to outlaw llm training or a market crash put off companies from continuing to do it it might be possible to put the genie back in the bottle for a few decades i wouldn t be surprised however if there are still 10x algorithmic improvements to be found too", "model_tags": [], "aspect_hints": ["usability_ux", "cost_price", "regulation_policy", "business_model"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "bemmu", "node_time": "2025-07-15T11:26:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44570150, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Things which are both powerful and possible become inevitable. We know that LLMs are powerful, but we aren't sure how powerful yet, and there's a large range this might eventually land in. We know they're possible in their current form, of course, but we don't know if actual GAI is possible. At this time, humanity seems to be estimating that both power and possibility will be off the charts. Why? Because getting this wrong can be so negatively impactful that it makes sense to move forward as if GAI will inevitably exist. Imagine supposing that this will all turn out to be fluff and GAI will never work, so you stop investing in it. Now imagine what happens if you're wrong and your enemy gets it to work first. This isn't some arguing device for AI-inevitabilists. It's knowledge of human nature, and it's been repeating itself for millennia. If the author believes that's going to suddenly change, they really should back that up with what, exactly, has changed in human nature.", "normalized_text": "things which are both powerful and possible become inevitable we know that llms are powerful but we aren t sure how powerful yet and there s a large range this might eventually land in we know they re possible in their current form of course but we don t know if actual gai is possible at this time humanity seems to be estimating that both power and possibility will be off the charts why because getting this wrong can be so negatively impactful that it makes sense to move forward as if gai will inevitably exist imagine supposing that this will all turn out to be fluff and gai will never work so you stop investing in it now imagine what happens if you re wrong and your enemy gets it to work first this isn t some arguing device for ai inevitabilists it s knowledge of human nature and it s been repeating itself for millennia if the author believes that s going to suddenly change they really should back that up with what exactly has changed in human nature", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "IAmGraydon", "node_time": "2025-07-15T11:45:49+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44570476, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "“The ultimate hidden truth of the world is that it is something that we make, and could just as easily make differently.” David Graeber", "normalized_text": "“the ultimate hidden truth of the world is that it is something that we make and could just as easily make differently ” david graeber", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "hermitcrab", "node_time": "2025-07-15T12:32:52+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44570551, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "A few days ago I saw a nice tweet being shared and it wend something like: I am not allowed to use my airco as it eats to much power and we must think about the environment. Meanwhile: people non-stop generating rule 34 images using AI...", "normalized_text": "a few days ago i saw a nice tweet being shared and it wend something like i am not allowed to use my airco as it eats to much power and we must think about the environment meanwhile people non stop generating rule 34 images using ai", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "ivolimmen", "node_time": "2025-07-15T12:43:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44570646, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "People like communicating in natural language. LLMs are the first step in the movement away from the \"early days\" of computing where you needed to learn the logic based language and interface of computers to interact with them. That is where the inevitabilism comes from. No one* wants to learn how to use a computer, they want it to be another entity that they can just talk to. *I'm rounding off the <5% who deeply love computers.", "normalized_text": "people like communicating in natural language llms are the first step in the movement away from the early days of computing where you needed to learn the logic based language and interface of computers to interact with them that is where the inevitabilism comes from no one wants to learn how to use a computer they want it to be another entity that they can just talk to i m rounding off the 5 who deeply love computers", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "Workaccount2", "node_time": "2025-07-15T12:54:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44570982, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "> \"AI ...\" > I’m not convinced that LLMs are the future. Was this an intentional bait/switch? LLM != AI. I'm quite sure LLMs are not the future. It's merely the step after AlexNet, AlphaGo, and before the next major advancement.", "normalized_text": "ai i’m not convinced that llms are the future was this an intentional bait switch llm ai i m quite sure llms are not the future it s merely the step after alexnet alphago and before the next major advancement", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "karmakaze", "node_time": "2025-07-15T13:32:39+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44571157, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "The author seems to imply that the \"framing\" of an argument is done so in bad faith in order to win an argument but only provides one-line quotes where there is no contextual argument. This tactic by the author is a straw-man argument - he's framing the position of tech leaders and our acceptance of it as the reason AI exists, instead of being honest, which is that they were simply right in their predictions: AI was inevitable. The IT industry is full of pride and arrogance. We deny the power of AI and LLMs. I think that's fair, I welcome the pushback. But the real word the IT crowd needs to learn is \"denialism\" - if you still don't see how LLMs is changing our entire industry, you haven't been paying attention. Edit: Lots of denialists using false dichotomy arguments that my opinion is invalid because I'm not producing examples and proof. I guess I'll just leave this:", "normalized_text": "the author seems to imply that the framing of an argument is done so in bad faith in order to win an argument but only provides one line quotes where there is no contextual argument this tactic by the author is a straw man argument he s framing the position of tech leaders and our acceptance of it as the reason ai exists instead of being honest which is that they were simply right in their predictions ai was inevitable the it industry is full of pride and arrogance we deny the power of ai and llms i think that s fair i welcome the pushback but the real word the it crowd needs to learn is denialism if you still don t see how llms is changing our entire industry you haven t been paying attention edit lots of denialists using false dichotomy arguments that my opinion is invalid because i m not producing examples and proof i guess i ll just leave this", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "JimmaDaRustla", "node_time": "2025-07-15T13:50:04+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44571271, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "I think what scares people who code for a living the most is the loss of their craft. Many of you have spent years or decades honing the craft of producing clear, fast, beautiful code. Now there is something that can spit out (often) beautiful code in seconds. An existential threat to your self worth and livelihood. A perfectly reasonable thing to react to. I do think, however, that this is an inevitable change. Industries and crafts being massively altered by technology is a tale as old as time. In a world that constantly changes, adaptation is key. I also think that almost all of you who have this craft should have no problem pivoting to higher level software architecture design. Work with an llm and produce things it would have taken a small team to do in 2019. I find it to be a very exciting time.", "normalized_text": "i think what scares people who code for a living the most is the loss of their craft many of you have spent years or decades honing the craft of producing clear fast beautiful code now there is something that can spit out often beautiful code in seconds an existential threat to your self worth and livelihood a perfectly reasonable thing to react to i do think however that this is an inevitable change industries and crafts being massively altered by technology is a tale as old as time in a world that constantly changes adaptation is key i also think that almost all of you who have this craft should have no problem pivoting to higher level software architecture design work with an llm and produce things it would have taken a small team to do in 2019 i find it to be a very exciting time", "model_tags": [], "aspect_hints": ["performance_speed", "regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "megaloblasto", "node_time": "2025-07-15T14:02:09+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44571437, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "The argument doesn't work because whatever you think of where generative AI is taking us or not taking us - it is 100% demonstrably better at doing a wide range of tasks than other technologies we have available to us - even in its current exact form. Once computers started to be connected could we have stopped the development of the world wide web. If there's a way of getting humanity to collectively agree on things - please let's start by using it to stop climate change and create world peace before moving on to getting rid of LLM's.", "normalized_text": "the argument doesn t work because whatever you think of where generative ai is taking us or not taking us it is 100 demonstrably better at doing a wide range of tasks than other technologies we have available to us even in its current exact form once computers started to be connected could we have stopped the development of the world wide web if there s a way of getting humanity to collectively agree on things please let s start by using it to stop climate change and create world peace before moving on to getting rid of llm s", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "castigatio", "node_time": "2025-07-15T14:20:57+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44571660, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "People and companies that use LLMs will be seen as tacky and cheap. They already are. Eew you have an ai generated profile photo? You write (code) with ai? You use ai to create marketing and graphics? You use non deterministic LLMs to brute force instead of paying humans to write efficient algorithms? Yuck yuck yuck", "normalized_text": "people and companies that use llms will be seen as tacky and cheap they already are eew you have an ai generated profile photo you write code with ai you use ai to create marketing and graphics you use non deterministic llms to brute force instead of paying humans to write efficient algorithms yuck yuck yuck", "model_tags": [], "aspect_hints": ["cost_price", "business_model"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "i_love_retros", "node_time": "2025-07-15T14:44:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44571695, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Most of us that are somewhat into the tech behind AI know that it's all based on simple matrix math... and anyone can do that... So \"inevitibalism\" is how we sound because we see that if OpenAI doesn't do it, someone else will. Even if all the countries in the world agree to ban AI, its not based on something with actual scarcity (like purified uranium, or gold) so someone somewhere will keep moving this tech forward...", "normalized_text": "most of us that are somewhat into the tech behind ai know that it s all based on simple matrix math and anyone can do that so inevitibalism is how we sound because we see that if openai doesn t do it someone else will even if all the countries in the world agree to ban ai its not based on something with actual scarcity like purified uranium or gold so someone somewhere will keep moving this tech forward", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "dicroce", "node_time": "2025-07-15T14:47:09+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44572407, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "(commenting late in the game, so the point may have been made already) I personally believe that \"AI\" is mostly marketing for the current shiny LLM thing that will end up finding some sort of actual useful niche (or two) once the dust has settled. But for now, it's more of a solution being carpet-bombed for problems, most of them inappropriate IMHO (e.g, replacing HR). For now there'll be collateral damage as carbon-based lifeforms are displaced, with an inevitable shortage of pesky humans to do cleanup once the limitations of \"AI\" are realized. Any the humans will probably be contract/gig at half their previous rates to do the cleanup.", "normalized_text": "commenting late in the game so the point may have been made already i personally believe that ai is mostly marketing for the current shiny llm thing that will end up finding some sort of actual useful niche or two once the dust has settled but for now it s more of a solution being carpet bombed for problems most of them inappropriate imho e g replacing hr for now there ll be collateral damage as carbon based lifeforms are displaced with an inevitable shortage of pesky humans to do cleanup once the limitations of ai are realized any the humans will probably be contract gig at half their previous rates to do the cleanup", "model_tags": [], "aspect_hints": ["regulation_policy", "business_model"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "scioto", "node_time": "2025-07-15T15:50:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44572686, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "These articles kill me. The reason LLMs (or next-gen AI architecture) is inevitably going to take over the world in one way or another is simple: recursive self-improvement. 3 years ago they could barely write a coherent poem and today they're performing at at least graduate student level across most tasks. As of today, AI is writing a significant chunk of the code around itself. Once AI crosses that threshold of consistently being above senior-level engineer level at coding it will reach a tipping point where it can improve itself faster than the best human expert. That's core technological recursive self-improvement but we have another avenue of recursive self-improvement as well: Agentic recursive self-improvement. First there was LLMs, then there was LLMs with tool usage, then we abstracted the tool usage to MCP servers. Next, we will create agents that autodiscover remote MCP servers, then we will create agents which can autodiscover tools as well as write their own. Final stage of agents are generalized agents similar to Claude Code which can find remote MCP servers, perform a task, then analyze their first run of completing a task to figure out how to improve the process. Then write its own tools to use to complete the task faster than they did before. Agentic recursive self-improvement. As an agent engineer, I suspect this pattern will become viable in about 2 years.", "normalized_text": "these articles kill me the reason llms or next gen ai architecture is inevitably going to take over the world in one way or another is simple recursive self improvement 3 years ago they could barely write a coherent poem and today they re performing at at least graduate student level across most tasks as of today ai is writing a significant chunk of the code around itself once ai crosses that threshold of consistently being above senior level engineer level at coding it will reach a tipping point where it can improve itself faster than the best human expert that s core technological recursive self improvement but we have another avenue of recursive self improvement as well agentic recursive self improvement first there was llms then there was llms with tool usage then we abstracted the tool usage to mcp servers next we will create agents that autodiscover remote mcp servers then we will create agents which can autodiscover tools as well as write their own final stage of agents are generalized agents similar to claude code which can find remote mcp servers perform a task then analyze their first run of completing a task to figure out how to improve the process then write its own tools to use to complete the task faster than they did before agentic recursive self improvement as an agent engineer i suspect this pattern will become viable in about 2 years", "model_tags": ["anthropic"], "aspect_hints": ["performance_speed", "regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "DanMcInerney", "node_time": "2025-07-15T16:13:35+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44572755, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "It seemed inevitable that the Internet would allow understanding of other cultures and make future war impossible, as the people united and stood in opposition to oppression and stupidity the world over. Reality worked out differently. I suspect the same is about to happen with our LLM overlords.", "normalized_text": "it seemed inevitable that the internet would allow understanding of other cultures and make future war impossible as the people united and stood in opposition to oppression and stupidity the world over reality worked out differently i suspect the same is about to happen with our llm overlords", "model_tags": [], "aspect_hints": ["community_tone"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "mikewarot", "node_time": "2025-07-15T16:17:45+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44572963, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Absolutely perfect blog post. You provoked some new thoughts, convinced me of your position, taught me something concrete and practical about debating, had a human narrative, gave me a good book recommendation, didn't feel manipulative or formulaic, wrote something that an employed person can read in a reasonable amount of time AND most importantly made a solid Matrix reference. You're my blog hero, thank you for being cool and setting a good example. Also really important LLM hype reminder.", "normalized_text": "absolutely perfect blog post you provoked some new thoughts convinced me of your position taught me something concrete and practical about debating had a human narrative gave me a good book recommendation didn t feel manipulative or formulaic wrote something that an employed person can read in a reasonable amount of time and most importantly made a solid matrix reference you re my blog hero thank you for being cool and setting a good example also really important llm hype reminder", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "pkdpic", "node_time": "2025-07-15T16:33:48+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44573627, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Right now, I’m noticing how my colleagues who aren’t very comfortable using LLMs for most of their work are getting sidelined. It's a bit sad seeing them struggle by not keeping pace with everyone else who is using it for ~90% of our tasks. They seem to really care about writing code themselves, but, if they don't pivot, things are probably not going to end well for them. So is LLM inevitable? Pretty much if you want to remain competitive.", "normalized_text": "right now i’m noticing how my colleagues who aren’t very comfortable using llms for most of their work are getting sidelined it s a bit sad seeing them struggle by not keeping pace with everyone else who is using it for 90 of our tasks they seem to really care about writing code themselves but if they don t pivot things are probably not going to end well for them so is llm inevitable pretty much if you want to remain competitive", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "rafaelero", "node_time": "2025-07-15T17:24:42+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44573764, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "This inevitabilist framing rests on an often unspoken assumption: that LLM's will decisively outperform human capabilities in myriad domains. If that assumption holds true, then the inevitabilist quotes featured in the article are convincing to me. If LLM's turn out to be less worthwhile at scale than many people assume, the inevitabilist interpretation is another dream of AI summer. Burying the core assumption and focusing on its implication is indeed a fantastic way of framing the argument to win some sort of debate.", "normalized_text": "this inevitabilist framing rests on an often unspoken assumption that llm s will decisively outperform human capabilities in myriad domains if that assumption holds true then the inevitabilist quotes featured in the article are convincing to me if llm s turn out to be less worthwhile at scale than many people assume the inevitabilist interpretation is another dream of ai summer burying the core assumption and focusing on its implication is indeed a fantastic way of framing the argument to win some sort of debate", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "bloppe", "node_time": "2025-07-15T17:36:56+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44575115, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "I have a foreboding of an America in my children's or grandchildren's time -- when the United States is a service and information economy; when nearly all the manufacturing industries have slipped away to other countries; when awesome technological powers are in the hands of a very few, and no one representing the public interest can even grasp the issues; when the people have lost the ability to set their own agendas or knowledgeably question those in authority; when, clutching our crystals and nervously consulting our horoscopes, our critical faculties in decline, unable to distinguish between what feels good and what's true, we slide, almost without noticing, back into superstition and darkness...", "normalized_text": "i have a foreboding of an america in my children s or grandchildren s time when the united states is a service and information economy when nearly all the manufacturing industries have slipped away to other countries when awesome technological powers are in the hands of a very few and no one representing the public interest can even grasp the issues when the people have lost the ability to set their own agendas or knowledgeably question those in authority when clutching our crystals and nervously consulting our horoscopes our critical faculties in decline unable to distinguish between what feels good and what s true we slide almost without noticing back into superstition and darkness", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "tines", "node_time": "2025-07-15T19:49:05+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44576520, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "The article talks about being thrown off-balance by debating tricks and then proceed to do just that with a kind of bait and switch from talking about AI to talking about LLMs. Eg. it quotes >“AI is the new electricity.” – Andrew Ng as framing AI as kind of inevitable and then flips to >I’m not convinced that LLMs are the future. It seems to me AI is inevitable and LLMs will be replaced soon with some better algorithm. It's like video is inevitable but betamax wasn't. Two different things.", "normalized_text": "the article talks about being thrown off balance by debating tricks and then proceed to do just that with a kind of bait and switch from talking about ai to talking about llms eg it quotes “ai is the new electricity ” – andrew ng as framing ai as kind of inevitable and then flips to i’m not convinced that llms are the future it seems to me ai is inevitable and llms will be replaced soon with some better algorithm it s like video is inevitable but betamax wasn t two different things", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "tim333", "node_time": "2025-07-15T22:27:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44578483, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "Like a lot of blog posts, this feels like a premise worth exploring, lacking a critical exploration of that premise. Yes, \"inevitabilism\" is a thing, both in tech and in politics. But, crucially, it's not always wrong! Other comments have pointed out examples, such as the internet in the 90s. But when considering new cultural and technological developments that seem like a glimpse of the future, how do we know if they're an inevitability or not? The post says: > what I’m most certain of is that we have choices about what our future should look like, and how we choose to use machines to build it. To me, that sounds like mere wishful thinking. Yeah, sometimes society can turn back the tide of harmful developments; for instance, the ozone layer is well on its way to complete recovery. Other times, even when public opinion is mixed, such as with bitcoin, the technology does become quite successful, but doesn't seem to become quite as ubiquitous as its most fervent adherents expect. So how do we know which category LLM usage falls into? I don't know the answer, because I think it's a difficult thing to know in advance.", "normalized_text": "like a lot of blog posts this feels like a premise worth exploring lacking a critical exploration of that premise yes inevitabilism is a thing both in tech and in politics but crucially it s not always wrong other comments have pointed out examples such as the internet in the 90s but when considering new cultural and technological developments that seem like a glimpse of the future how do we know if they re an inevitability or not the post says what i’m most certain of is that we have choices about what our future should look like and how we choose to use machines to build it to me that sounds like mere wishful thinking yeah sometimes society can turn back the tide of harmful developments for instance the ozone layer is well on its way to complete recovery other times even when public opinion is mixed such as with bitcoin the technology does become quite successful but doesn t seem to become quite as ubiquitous as its most fervent adherents expect so how do we know which category llm usage falls into i don t know the answer because i think it s a difficult thing to know in advance", "model_tags": [], "aspect_hints": ["usability_ux", "ethics"], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "BatmanAoD", "node_time": "2025-07-16T03:43:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44579487, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "This is a sharp dissection of ‘inevitabilism’ as a rhetorical strategy. I’ve noticed it too: the moment someone says ‘X is inevitable’, the burden of proof disappears and dissent becomes ‘denial’. But isn’t that framing itself... fragile? We’ve seen plenty of ‘inevitable’ futures (crypto, the Metaverse, even Web3) collapse under public pushback or internal rot. The question I’m left with: if inevitabilism is so effective rhetorically, how do we counter it without sounding naïve or regressive?", "normalized_text": "this is a sharp dissection of ‘inevitabilism’ as a rhetorical strategy i’ve noticed it too the moment someone says ‘x is inevitable’ the burden of proof disappears and dissent becomes ‘denial’ but isn’t that framing itself fragile we’ve seen plenty of ‘inevitable’ futures crypto the metaverse even web3 collapse under public pushback or internal rot the question i’m left with if inevitabilism is so effective rhetorically how do we counter it without sounding naïve or regressive", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "pi_22by7", "node_time": "2025-07-16T06:59:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44649764, "root_story_id": 44567857, "node_type": "comment", "comment_depth": 1, "text": "I wish I can show my gratitude more than this but i'm truly grateful thank you for restoring my happiness and hopes back and more than i could even ask for, my marriage of 2 years crashed out of no good reason but i'm grateful Dr Alfred helped me restore everything back and now my husband even loves me more than he ever used to love me , I can't repay you Dr Alfred, I just want to say thank you and let everyone know that you are truly amazing, and indeed your love spell is powerful, you can reach him on dralfredspellhome@gmail.com or on whatsapp +2348134653457", "normalized_text": "i wish i can show my gratitude more than this but i m truly grateful thank you for restoring my happiness and hopes back and more than i could even ask for my marriage of 2 years crashed out of no good reason but i m grateful dr alfred helped me restore everything back and now my husband even loves me more than he ever used to love me i can t repay you dr alfred i just want to say thank you and let everyone know that you are truly amazing and indeed your love spell is powerful you can reach him on dralfredspellhome gmail com or on whatsapp 2348134653457", "model_tags": [], "aspect_hints": [], "context": {"root_title": "LLM Inevitabilism", "root_author": "SwoopsFromAbove", "root_url": "https://tomrenner.com/posts/llm-inevitabilism/", "node_author": "malinda1", "node_time": "2025-07-22T16:47:36+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44800818, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Open weight models from OpenAI with performance comparable to that of o3 and o4-mini in benchmarks… well, I certainly wasn’t expecting that. What’s the catch?", "normalized_text": "open weight models from openai with performance comparable to that of o3 and o4 mini in benchmarks… well i certainly wasn’t expecting that what’s the catch", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "thimabi", "node_time": "2025-08-05T17:06:28+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44800850, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Listed performance of ~5 points less than o3 on benchmarks is pretty impressive. Wonder if they feel the bar will be raised soon (GPT-5) and feel more comfortable releasing something this strong.", "normalized_text": "listed performance of 5 points less than o3 on benchmarks is pretty impressive wonder if they feel the bar will be raised soon gpt 5 and feel more comfortable releasing something this strong", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "IceHegel", "node_time": "2025-08-05T17:08:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44800859, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Wow, today is a crazy AI release day: - OAI open source - Opus 4.1 - Genie 3 - ElevenLabs Music", "normalized_text": "wow today is a crazy ai release day oai open source opus 4 1 genie 3 elevenlabs music", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "Workaccount2", "node_time": "2025-08-05T17:08:51+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44800858, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Wow, this will eat Meta's lunch", "normalized_text": "wow this will eat meta s lunch", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "johntiger1", "node_time": "2025-08-05T17:08:51+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44800874, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "So this confirms a best-in-class model release within the next few days? From a strategic perspective, I can't think of any reason they'd release this unless they were about to announce something which totally eclipses it?", "normalized_text": "so this confirms a best in class model release within the next few days from a strategic perspective i can t think of any reason they d release this unless they were about to announce something which totally eclipses it", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "deviation", "node_time": "2025-08-05T17:10:04+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44800876, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Disclamer: probably dumb questions so, the 20b model. Can someone explain to me what I would need to do in terms of resources (GPU, I assume) if I want to run 20 concurrent processes, assuming I need 1k tokens/second throughput (on each, so 20 x 1k) Also, is this model better/comparable for information extraction compared to gpt-4.1-nano, and would it be cheaper to host myself 20b?", "normalized_text": "disclamer probably dumb questions so the 20b model can someone explain to me what i would need to do in terms of resources gpu i assume if i want to run 20 concurrent processes assuming i need 1k tokens second throughput on each so 20 x 1k also is this model better comparable for information extraction compared to gpt 4 1 nano and would it be cheaper to host myself 20b", "model_tags": ["openai"], "aspect_hints": ["performance_speed", "cost_price", "regulation_policy"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "artembugara", "node_time": "2025-08-05T17:10:11+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44800988, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Running a model comparable to o3 on a 24GB Mac Mini is absolutely wild. Seems like yesterday the idea of running frontier (at the time) models locally or on a mobile device was 5+ years out. At this rate, we'll be running such models in the next phone cycle.", "normalized_text": "running a model comparable to o3 on a 24gb mac mini is absolutely wild seems like yesterday the idea of running frontier at the time models locally or on a mobile device was 5 years out at this rate we ll be running such models in the next phone cycle", "model_tags": ["openai"], "aspect_hints": ["cost_price"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "x187463", "node_time": "2025-08-05T17:16:09+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801016, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "GPQA Diamond: gpt-oss-120b: 80.1%, Qwen3-235B-A22B-Thinking-2507: 81.1% Humanity’s Last Exam: gpt-oss-120b (tools): 19.0%, gpt-oss-120b (no tools): 14.9%, Qwen3-235B-A22B-Thinking-2507: 18.2%", "normalized_text": "gpqa diamond gpt oss 120b 80 1 qwen3 235b a22b thinking 2507 81 1 humanity’s last exam gpt oss 120b tools 19 0 gpt oss 120b no tools 14 9 qwen3 235b a22b thinking 2507 18 2", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "Leary", "node_time": "2025-08-05T17:18:00+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801024, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Shameless plug: if someone wants to try it in a nice ui, you could give Msty[1] a try. It's private and local. [1]:", "normalized_text": "shameless plug if someone wants to try it in a nice ui you could give msty 1 a try it s private and local 1", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "chown", "node_time": "2025-08-05T17:18:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801032, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Does anyone get the demos at to work, or are the servers down immediately after launch? I'm only getting the spinner after prompting.", "normalized_text": "does anyone get the demos at to work or are the servers down immediately after launch i m only getting the spinner after prompting", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "dsco", "node_time": "2025-08-05T17:18:56+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801063, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Looks like Groq (at 1k+ tokens/second) and Fireworks are already live on openrouter: $0.15M in / $0.6-0.75M out edit: Now Cerebras too at 3,815 tps for $0.25M / $0.69M out.", "normalized_text": "looks like groq at 1k tokens second and fireworks are already live on openrouter 0 15m in 0 6 0 75m out edit now cerebras too at 3 815 tps for 0 25m 0 69m out", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "sadiq", "node_time": "2025-08-05T17:20:35+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801090, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Can't wait to see third party benchmarks. The ones in the blog post are quite sparse and it doesn't seem possible to fully compare to other open models yet. But the few numbers available seem to suggest that this release will make all other non-multimodal open models obsolete.", "normalized_text": "can t wait to see third party benchmarks the ones in the blog post are quite sparse and it doesn t seem possible to fully compare to other open models yet but the few numbers available seem to suggest that this release will make all other non multimodal open models obsolete", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "modeless", "node_time": "2025-08-05T17:22:02+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801118, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "I dont see the unsloth files yet but they'll be here: Super excited to test these out. The benchmarks from 20B are blowing away major >500b models. Insane. On my hardware. 43 tokens/sec. I got an error with flash attention turning on. Cant run it with flash attention? 31,000 context is max it will allow or model wont load. no kv or v quantization.", "normalized_text": "i dont see the unsloth files yet but they ll be here super excited to test these out the benchmarks from 20b are blowing away major 500b models insane on my hardware 43 tokens sec i got an error with flash attention turning on cant run it with flash attention 31 000 context is max it will allow or model wont load no kv or v quantization", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "incomingpain", "node_time": "2025-08-05T17:23:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801135, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "What a day! Models aside, the Harmony Response Format[1] also seems pretty interesting and I wonder how much of an impact it might have in performance of these models. [1]", "normalized_text": "what a day models aside the harmony response format 1 also seems pretty interesting and i wonder how much of an impact it might have in performance of these models 1", "model_tags": [], "aspect_hints": ["ethics", "regulation_policy"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "rmonvfer", "node_time": "2025-08-05T17:24:34+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801210, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "The coding seems to be one of the strongest use cases for LLMs. Though currently they are eating too many tokens to be profitable. So perhaps these local models could offload some tasks to local computers. E.g. Hybrid architecture. Local model gathers more data, runs tests, does simple fixes, but frequently asks the stronger model to do the real job. Local model gathers data using tools and sends more data to the stronger model. It", "normalized_text": "the coding seems to be one of the strongest use cases for llms though currently they are eating too many tokens to be profitable so perhaps these local models could offload some tasks to local computers e g hybrid architecture local model gathers more data runs tests does simple fixes but frequently asks the stronger model to do the real job local model gathers data using tools and sends more data to the stronger model it", "model_tags": [], "aspect_hints": ["privacy"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "jakozaur", "node_time": "2025-08-05T17:29:01+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801237, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Why do companies release open source LLMs? I would understand it, if there was some technology lock-in. But with LLMs, there is no such thing. One can switch out LLMs without any friction.", "normalized_text": "why do companies release open source llms i would understand it if there was some technology lock in but with llms there is no such thing one can switch out llms without any friction", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "ArtTimeInvestor", "node_time": "2025-08-05T17:31:04+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801245, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Holy smokes, there's already llama.cpp support:", "normalized_text": "holy smokes there s already llama cpp support", "model_tags": ["meta"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "HanClinto", "node_time": "2025-08-05T17:31:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801341, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Shoutout to the hn consensus regarding an OpenAI open model release from 4 days ago:", "normalized_text": "shoutout to the hn consensus regarding an openai open model release from 4 days ago", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "jstummbillig", "node_time": "2025-08-05T17:36:30+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801381, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Orthogonal, but I just wanted to say how awesome Ollama is. It took 2 seconds to find the model and a minute to download and now I'm using it. Kudos to that team.", "normalized_text": "orthogonal but i just wanted to say how awesome ollama is it took 2 seconds to find the model and a minute to download and now i m using it kudos to that team", "model_tags": ["meta"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "timmg", "node_time": "2025-08-05T17:38:39+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801408, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "I love how they frame High-end desktops and laptops as having \"a single H100 GPU\".", "normalized_text": "i love how they frame high end desktops and laptops as having a single h100 gpu", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "PeterStuer", "node_time": "2025-08-05T17:39:54+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801714, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Model cards, for the people interested in the guts: In my mind, I’m comparing the model architecture they describe to what the leading open-weights models (Deepseek, Qwen, GLM, Kimi) have been doing. Honestly, it just seems “ok” at a technical level: - both models use standard Grouped-Query Attention (64 query heads, 8 KV heads). The card talks about how they’ve used an older optimization from GPT3, which is alternating between banded window (sparse, 128 tokens) and fully dense attention patterns. It uses RoPE extended with YaRN (for a 131K context window). So they haven’t been taking advantage of the special-sauce Multi-head Latent Attention from Deepseek, or any of the other similar improvements over GQA. - both models are standard MoE transformers. The 120B model (116.8B total, 5.1B active) uses 128 experts with Top-4 routing. They’re using some kind of Gated SwiGLU activation, which the card talks about as being \"unconventional\" because of to clamping and whatever residual connections that implies. Again, not using any of Deepseek’s “shared experts” (for general patterns) + “routed experts” (for specialization) architectural improvements, Qwen’s load-balancing strategies, etc. - the most interesting thing IMO is probably their quantization solution. They did something to quantize >90% of the model parameters to the MXFP4 format (4.25 bits/parameter) to let the 120B model to fit on a single 80GB GPU, which is pretty cool. But we’ve also got Unsloth with their famous 1.58bit quants :) All this to say, it seems like even though the training they did for their agentic behavior and reasoning is undoubtedly very good, they’re keeping their actual technical advancements “in their pocket”.", "normalized_text": "model cards for the people interested in the guts in my mind i’m comparing the model architecture they describe to what the leading open weights models deepseek qwen glm kimi have been doing honestly it just seems “ok” at a technical level both models use standard grouped query attention 64 query heads 8 kv heads the card talks about how they’ve used an older optimization from gpt3 which is alternating between banded window sparse 128 tokens and fully dense attention patterns it uses rope extended with yarn for a 131k context window so they haven’t been taking advantage of the special sauce multi head latent attention from deepseek or any of the other similar improvements over gqa both models are standard moe transformers the 120b model 116 8b total 5 1b active uses 128 experts with top 4 routing they’re using some kind of gated swiglu activation which the card talks about as being unconventional because of to clamping and whatever residual connections that implies again not using any of deepseek’s “shared experts” for general patterns “routed experts” for specialization architectural improvements qwen’s load balancing strategies etc the most interesting thing imo is probably their quantization solution they did something to quantize 90 of the model parameters to the mxfp4 format 4 25 bits parameter to let the 120b model to fit on a single 80gb gpu which is pretty cool but we’ve also got unsloth with their famous 1 58bit quants all this to say it seems like even though the training they did for their agentic behavior and reasoning is undoubtedly very good they’re keeping their actual technical advancements “in their pocket”", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "foundry27", "node_time": "2025-08-05T17:57:40+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801729, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Newbie question: I remember folks talking about how kimi 2’s launch might have pushed OpenAI to launch their model later. Now that we (shortly will) know how this model performs, how do they stack up? Did openAI likely actually hold off releasing weights because of kimi, in retrospect?", "normalized_text": "newbie question i remember folks talking about how kimi 2’s launch might have pushed openai to launch their model later now that we shortly will know how this model performs how do they stack up did openai likely actually hold off releasing weights because of kimi in retrospect", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "user_7832", "node_time": "2025-08-05T17:58:24+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801737, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Open models are going to win long-term. Anthropics' own research has to use OSS models [0]. China is demonstrating how quickly companies can iterate on open models, allowing smaller teams access and augmentation to the abilities of a model without paying the training cost. My personal prediction is that the US foundational model makers will OSS something close to N-1 for the next 1-3 iterations. The CAPEX for the foundational model creation is too high to justify OSS for the current generation. Unless the US Gov steps up and starts subsidizing power, or Stargate does 10x what it is planned right now. N-1 model value depreciates insanely fast. Making an OSS release of them and allowing specialized use cases and novel developments allows potential value to be captured and integrated into future model designs. It's medium risk, as you may lose market share. But also high potential value, as the shared discoveries could substantially increase the velocity of next-gen development. There will be a plethora of small OSS models. Iteration on the OSS releases is going to be biased towards local development, creating more capable and specialized models that work on smaller and smaller devices. In an agentic future, every different agent in a domain may have its own model. Distilled and customized for its use case without significant cost. Everyone is racing to AGI/SGI. The models along the way are to capture market share and use data for training and evaluations. Once someone hits AGI/SGI, the consumer market is nice to have, but the real value is in novel developments in science, engineering, and every other aspect of the world. [0] > We demonstrate these applications on two open-source models, Qwen 2.5-7B-Instruct and Llama-3.1-8B-Instruct.", "normalized_text": "open models are going to win long term anthropics own research has to use oss models 0 china is demonstrating how quickly companies can iterate on open models allowing smaller teams access and augmentation to the abilities of a model without paying the training cost my personal prediction is that the us foundational model makers will oss something close to n 1 for the next 1 3 iterations the capex for the foundational model creation is too high to justify oss for the current generation unless the us gov steps up and starts subsidizing power or stargate does 10x what it is planned right now n 1 model value depreciates insanely fast making an oss release of them and allowing specialized use cases and novel developments allows potential value to be captured and integrated into future model designs it s medium risk as you may lose market share but also high potential value as the shared discoveries could substantially increase the velocity of next gen development there will be a plethora of small oss models iteration on the oss releases is going to be biased towards local development creating more capable and specialized models that work on smaller and smaller devices in an agentic future every different agent in a domain may have its own model distilled and customized for its use case without significant cost everyone is racing to agi sgi the models along the way are to capture market share and use data for training and evaluations once someone hits agi sgi the consumer market is nice to have but the real value is in novel developments in science engineering and every other aspect of the world 0 we demonstrate these applications on two open source models qwen 2 5 7b instruct and llama 3 1 8b instruct", "model_tags": ["anthropic", "meta"], "aspect_hints": ["performance_speed", "privacy", "usability_ux", "cost_price", "ethics", "business_model"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "ClassAndBurn", "node_time": "2025-08-05T17:58:53+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801839, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Getting great performance running gpt-oss on 3x A4000's: gpt-oss:20b = ~46 tok/s More than 2x faster than my previous leading OSS models: mistral-small3.2:24b = ~22 tok/s gemma3:27b = ~19.5 tok/s Strangely getting nearly the opposite performance running on 1x 5070 Ti: mistral-small3.2:24b = ~39 tok/s gpt-oss:20b = ~21 tok/s Where gpt-oss is nearly 2x slow vs mistral-small 3.2.", "normalized_text": "getting great performance running gpt oss on 3x a4000 s gpt oss 20b 46 tok s more than 2x faster than my previous leading oss models mistral small3 2 24b 22 tok s gemma3 27b 19 5 tok s strangely getting nearly the opposite performance running on 1x 5070 ti mistral small3 2 24b 39 tok s gpt oss 20b 21 tok s where gpt oss is nearly 2x slow vs mistral small 3 2", "model_tags": ["openai", "mistral"], "aspect_hints": ["performance_speed"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "mythz", "node_time": "2025-08-05T18:04:21+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801921, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "I'm out of the loop for local models. For my M3 24gb ram macbook, what token throughput can I expect? Edit: I tried it out, I have no idea in terms of of tokens but it was fluid enough for me. A bit slower than using o3 in the browser but definitely tolerable. I think I will set it up in my GF's machine so she can stop paying for the full subscription (she's a non-tech professional)", "normalized_text": "i m out of the loop for local models for my m3 24gb ram macbook what token throughput can i expect edit i tried it out i have no idea in terms of of tokens but it was fluid enough for me a bit slower than using o3 in the browser but definitely tolerable i think i will set it up in my gf s machine so she can stop paying for the full subscription she s a non tech professional", "model_tags": ["openai"], "aspect_hints": ["performance_speed", "usability_ux", "cost_price"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "jcmontx", "node_time": "2025-08-05T18:10:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801924, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "What's the best agent to run this on? Is it compatible with Codex? For OSS agents, I've been using Qwen Code (clunky fork of Gemini), and Goose.", "normalized_text": "what s the best agent to run this on is it compatible with codex for oss agents i ve been using qwen code clunky fork of gemini and goose", "model_tags": ["google"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "Rhubarrbb", "node_time": "2025-08-05T18:10:37+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44801998, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Seeing a 20B model competing with o3's performance is mind blowing like just a year ago, most of us would've called this impossible - not just the intelligence leap, but getting this level of capability in such a compact size. I think that the point that makes me more excited is that we can train trillion-parameter giants and distill them down to just billions without losing the magic. Imagine coding with Claude 4 Opus-level intelligence packed into a 10B model running locally at 2000 tokens/sec - like instant AI collaboration. That would fundamentally change how we develop software.", "normalized_text": "seeing a 20b model competing with o3 s performance is mind blowing like just a year ago most of us would ve called this impossible not just the intelligence leap but getting this level of capability in such a compact size i think that the point that makes me more excited is that we can train trillion parameter giants and distill them down to just billions without losing the magic imagine coding with claude 4 opus level intelligence packed into a 10b model running locally at 2000 tokens sec like instant ai collaboration that would fundamentally change how we develop software", "model_tags": ["openai", "anthropic"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "henriquegodoy", "node_time": "2025-08-05T18:16:24+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44802231, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "It seems like OSS will win, I can't see people willing to pay like 10x the price for what seems like 10% more performance. Especially once we get better at routing the hardest questions to the better models and then using that response to augment/fine-tune the OSS ones.", "normalized_text": "it seems like oss will win i can t see people willing to pay like 10x the price for what seems like 10 more performance especially once we get better at routing the hardest questions to the better models and then using that response to augment fine tune the oss ones", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "siliconc0w", "node_time": "2025-08-05T18:32:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44802321, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Inference in Python uses harmony [1] (for request and response format) which is written in Rust with Python bindings. Another OpenAI's Rust library is tiktoken [2], used for all tokenization and detokenization. OpenAI Codex [3] is also written in Rust. It looks like OpenAI is increasingly adopting Rust (at least for inference). [1] [2] [3]", "normalized_text": "inference in python uses harmony 1 for request and response format which is written in rust with python bindings another openai s rust library is tiktoken 2 used for all tokenization and detokenization openai codex 3 is also written in rust it looks like openai is increasingly adopting rust at least for inference 1 2 3", "model_tags": ["openai"], "aspect_hints": ["ethics"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "lukax", "node_time": "2025-08-05T18:38:46+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44802493, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Super excited to see these released! Major points of interest for me: - In the \"Main capabilities evaluations\" section, the 120b outperform o3-mini and approaches o4 on most evals. 20b model is also decent, passing o3-mini on one of the tasks. - AIME 2025 is nearly saturated with large CoT - CBRN threat levels kind of on par with other SOTA open source models. Plus, demonstrated good refusals even after adversarial fine tuning. - Interesting to me how a lot of the safety benchmarking runs on trust, since methodology can't be published too openly due to counterparty risk. Model cards with some of my annotations:", "normalized_text": "super excited to see these released major points of interest for me in the main capabilities evaluations section the 120b outperform o3 mini and approaches o4 on most evals 20b model is also decent passing o3 mini on one of the tasks aime 2025 is nearly saturated with large cot cbrn threat levels kind of on par with other sota open source models plus demonstrated good refusals even after adversarial fine tuning interesting to me how a lot of the safety benchmarking runs on trust since methodology can t be published too openly due to counterparty risk model cards with some of my annotations", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "sabakhoj", "node_time": "2025-08-05T18:51:05+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44802690, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Big picture, what's the balance going to look like, going forward between what normal people can run on a fancy computer at home vs heavy duty systems hosted in big data centers that are the exclusive domain of Big Companies? This is something about AI that worries me, a 'child' of the open source coming of age era in the 90ies. I don't want to be forced to rely on those big companies to do my job in an efficient way, if AI becomes part of the day to day workflow.", "normalized_text": "big picture what s the balance going to look like going forward between what normal people can run on a fancy computer at home vs heavy duty systems hosted in big data centers that are the exclusive domain of big companies this is something about ai that worries me a child of the open source coming of age era in the 90ies i don t want to be forced to rely on those big companies to do my job in an efficient way if ai becomes part of the day to day workflow", "model_tags": [], "aspect_hints": ["privacy", "usability_ux"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "davidw", "node_time": "2025-08-05T19:03:08+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44802718, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "> We introduce gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models available under the Apache 2.0 license and our gpt-oss usage policy. [0] Is it even valid to have additional restriction on top of Apache 2.0? [0]:", "normalized_text": "we introduce gpt oss 120b and gpt oss 20b two open weight reasoning models available under the apache 2 0 license and our gpt oss usage policy 0 is it even valid to have additional restriction on top of apache 2 0 0", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "maxloh", "node_time": "2025-08-05T19:05:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44802963, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "thanks openai for being open ;) Surprised there are no official MLX versions and only one mention of MLX in this thread. MLX basically converst the models to take advntage of mac unified memory for 2-5x increase in power, enabling macs to run what would otherwise take expensive gpus (within limits). So FYI to any one on mac, the easiest way to run these models right now is using LM Studio ( ), its free. You just search for the model, usually 3rd party groups mlx-community or lmstudio-community have mlx versions within a day or 2 of releases. I go for the 8-bit quantizations (4-bit faster, but quality drops). You can also convert to mlx yourself... Once you have it running on LM studio, you can chat there in their chat interface, or you can run it through api that defaults to You can run multiple models that hot swap and load instantly and switch between them etc. Its surpassingly easy, and fun.There are actually a lot of cool niche models comings out, like this tiny high-quality search model released today as well (and who released official mlx version) Other fun ones are gemma 3n which is model multi-modal, larger one that is actually solid model but takes more memory is the new Qwen3 30b A3B (coder and instruct), Pixtral (mixtral vision with full resolution images), etc. Look forward to playing with this model and see how it compares.", "normalized_text": "thanks openai for being open surprised there are no official mlx versions and only one mention of mlx in this thread mlx basically converst the models to take advntage of mac unified memory for 2 5x increase in power enabling macs to run what would otherwise take expensive gpus within limits so fyi to any one on mac the easiest way to run these models right now is using lm studio its free you just search for the model usually 3rd party groups mlx community or lmstudio community have mlx versions within a day or 2 of releases i go for the 8 bit quantizations 4 bit faster but quality drops you can also convert to mlx yourself once you have it running on lm studio you can chat there in their chat interface or you can run it through api that defaults to you can run multiple models that hot swap and load instantly and switch between them etc its surpassingly easy and fun there are actually a lot of cool niche models comings out like this tiny high quality search model released today as well and who released official mlx version other fun ones are gemma 3n which is model multi modal larger one that is actually solid model but takes more memory is the new qwen3 30b a3b coder and instruct pixtral mixtral vision with full resolution images etc look forward to playing with this model and see how it compares", "model_tags": ["openai", "mistral"], "aspect_hints": ["performance_speed", "usability_ux", "cost_price", "regulation_policy", "community_tone"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "matznerd", "node_time": "2025-08-05T19:22:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44803389, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "I just tried it on open router but i was served by cerebras. Holy... 40,000 tokens per second. That was SURREAL. I got a 1.7k token reply delivered too fast for the human eye to perceive the streaming. n=1 for this 120b model but id rank the reply #1 just ahead of claude sonnet 4 for a boring JIRA ticket shuffling type challenge. EDIT: The same prompt on gpt-oss, despite being served 1000x slower, wasn't as good but was in a similar vein. It wanted to clarify more and as a result only half responded.", "normalized_text": "i just tried it on open router but i was served by cerebras holy 40 000 tokens per second that was surreal i got a 1 7k token reply delivered too fast for the human eye to perceive the streaming n 1 for this 120b model but id rank the reply 1 just ahead of claude sonnet 4 for a boring jira ticket shuffling type challenge edit the same prompt on gpt oss despite being served 1000x slower wasn t as good but was in a similar vein it wanted to clarify more and as a result only half responded", "model_tags": ["openai", "anthropic"], "aspect_hints": ["performance_speed"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "CraigJPerry", "node_time": "2025-08-05T19:52:19+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44803712, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "The 120B model badly hallucinates facts on the level of a 0.6B model. My go to test for checking hallucinations is 'Tell me about Mercantour park' (a national park in south eastern France). Easily half of the facts are invented. Non-existing mountain summits, brown bears (no, there are none), villages that are elsewhere, wrong advice ('dogs allowed' - no they are not).", "normalized_text": "the 120b model badly hallucinates facts on the level of a 0 6b model my go to test for checking hallucinations is tell me about mercantour park a national park in south eastern france easily half of the facts are invented non existing mountain summits brown bears no there are none villages that are elsewhere wrong advice dogs allowed no they are not", "model_tags": [], "aspect_hints": ["accuracy_reliability", "regulation_policy"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "dust42", "node_time": "2025-08-05T20:18:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44804034, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Just posted my initial impressions, took a couple of hours to write them up because there's a lot in this release! TLDR: I think OpenAI may have taken the medal for best available open weight model back from the Chinese AI labs. Will be interesting to see if independent benchmarks resolve in that direction as well. The 20B model runs on my Mac laptop using less than 15GB of RAM.", "normalized_text": "just posted my initial impressions took a couple of hours to write them up because there s a lot in this release tldr i think openai may have taken the medal for best available open weight model back from the chinese ai labs will be interesting to see if independent benchmarks resolve in that direction as well the 20b model runs on my mac laptop using less than 15gb of ram", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "simonw", "node_time": "2025-08-05T20:46:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44804397, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "The lede is being missed imo. gpt-oss:20b is a top ten model (on MMLU (right behind Gemini-2.5-Pro) and I just ran it locally on my Macbook Air M3 from last year. I've been experimenting with a lot of local models, both on my laptop and on my phone (Pixel 9 Pro), and I figured we'd be here in a year or two. But no, we're here today. A basically frontier model, running for the cost of electricity (free with a rounding error) on my laptop. No $200/month subscription, no lakes being drained, etc. I'm blown away.", "normalized_text": "the lede is being missed imo gpt oss 20b is a top ten model on mmlu right behind gemini 2 5 pro and i just ran it locally on my macbook air m3 from last year i ve been experimenting with a lot of local models both on my laptop and on my phone pixel 9 pro and i figured we d be here in a year or two but no we re here today a basically frontier model running for the cost of electricity free with a rounding error on my laptop no 200 month subscription no lakes being drained etc i m blown away", "model_tags": ["openai", "google"], "aspect_hints": ["cost_price"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "cco", "node_time": "2025-08-05T21:13:25+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44804412, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "I benchmarked the 120B version on the Extended NYT Connections (759 questions, ) and on 120B and 20B on Thematic Generalization (810 questions, ). Opus 4.1 benchmarks are also there.", "normalized_text": "i benchmarked the 120b version on the extended nyt connections 759 questions and on 120b and 20b on thematic generalization 810 questions opus 4 1 benchmarks are also there", "model_tags": [], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "zone411", "node_time": "2025-08-05T21:14:58+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44804468, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "> To improve the safety of the model, we filtered the data for harmful content in pre-training, especially around hazardous biosecurity knowledge, by reusing the CBRN pre-training filters from GPT-4o. Our model has a knowledge cutoff of June 2024. This would be a great \"AGI\" test. See if it can derive biohazards from first principles", "normalized_text": "to improve the safety of the model we filtered the data for harmful content in pre training especially around hazardous biosecurity knowledge by reusing the cbrn pre training filters from gpt 4o our model has a knowledge cutoff of june 2024 this would be a great agi test see if it can derive biohazards from first principles", "model_tags": ["openai"], "aspect_hints": ["security", "privacy", "ethics"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "FergusArgyll", "node_time": "2025-08-05T21:19:37+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44805075, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "I was able to get gpt-oss:20b wired up to claude code locally via a thin proxy and ollama. It's fun that it works, but the prefill time makes it feel unusable. (2-3 minutes per tool-use / completion). Means a ~10-20 tool-use interaction could take 30-60 minutes. (This editing a single server.py file that was ~1000 lines, the tool definitions + claude context was around 30k tokens input, and then after the file read, input was around ~50k tokens. Definitely could be optimized. Also I'm not sure if ollama supports a kv-cache between invocations of /v1/completions, which could help)", "normalized_text": "i was able to get gpt oss 20b wired up to claude code locally via a thin proxy and ollama it s fun that it works but the prefill time makes it feel unusable 2 3 minutes per tool use completion means a 10 20 tool use interaction could take 30 60 minutes this editing a single server py file that was 1000 lines the tool definitions claude context was around 30k tokens input and then after the file read input was around 50k tokens definitely could be optimized also i m not sure if ollama supports a kv cache between invocations of v1 completions which could help", "model_tags": ["openai", "anthropic", "meta"], "aspect_hints": ["performance_speed", "regulation_policy"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "bluecoconut", "node_time": "2025-08-05T22:11:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44805510, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Releasing this under the Apache license is a shot at competitors that want to license their models on Open Router and enterprise. It eliminates any reason to use an inferior Meta or Chinese model that costs money to license, thus there are no funds for these competitors to build a GPT 5 competitor.", "normalized_text": "releasing this under the apache license is a shot at competitors that want to license their models on open router and enterprise it eliminates any reason to use an inferior meta or chinese model that costs money to license thus there are no funds for these competitors to build a gpt 5 competitor", "model_tags": ["openai"], "aspect_hints": ["usability_ux", "cost_price"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "mortsnort", "node_time": "2025-08-05T22:55:19+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44805574, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Reading the comments it becomes clear how befuddled many HN participants are about AI. I don't think there has been a technical topic that HN has seemed so dull on in the many years I've been reading HN. This must be an indication that we are in a bubble. One basic point that is often missed is: Different aspects of LLM performance (in the cognitive performance sense) and LLM resource utilization are relevant to various use cases and business models. Another is that there are many use cases where users prefer to run inference locally, for a variety of domain-specific or business model reasons. The list goes on.", "normalized_text": "reading the comments it becomes clear how befuddled many hn participants are about ai i don t think there has been a technical topic that hn has seemed so dull on in the many years i ve been reading hn this must be an indication that we are in a bubble one basic point that is often missed is different aspects of llm performance in the cognitive performance sense and llm resource utilization are relevant to various use cases and business models another is that there are many use cases where users prefer to run inference locally for a variety of domain specific or business model reasons the list goes on", "model_tags": [], "aspect_hints": ["business_model"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "resters", "node_time": "2025-08-05T23:01:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44807027, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "I think this is a belated but smart move by OpenAI. They are basically fully moving in on Meta's strategy now, taking advantage of what may be a temporary situation with Meta dropping back in model race. It will be interesting to see if these models now get taken up by the local model / fine tuning community the way llama was. It's a very appealing strategy to test / dev with a local model and then have the option to deploy to prod on a high powered version of the same thing. Always knowing if the provider goes full hostile, or you end up with data that can't move off prem, you have self hosting as an option with a decent performing model. Which is all to say, availability of these local models for me is a key incentive that I didn't have before to use OpenAI's hosted ones.", "normalized_text": "i think this is a belated but smart move by openai they are basically fully moving in on meta s strategy now taking advantage of what may be a temporary situation with meta dropping back in model race it will be interesting to see if these models now get taken up by the local model fine tuning community the way llama was it s a very appealing strategy to test dev with a local model and then have the option to deploy to prod on a high powered version of the same thing always knowing if the provider goes full hostile or you end up with data that can t move off prem you have self hosting as an option with a decent performing model which is all to say availability of these local models for me is a key incentive that i didn t have before to use openai s hosted ones", "model_tags": ["openai", "meta"], "aspect_hints": ["privacy", "community_tone"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "zmmmmm", "node_time": "2025-08-06T02:39:39+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44807382, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Wow I really didn’t think this would happen any time soon, they seem to have more to lose than to gain. If you’re a company building AI into your product right now I think you would be irresponsible to not investigate how much you can do on open weights models. The big AI labs are going to pull the ladder up eventually, building your business on the APIs long term is foolish. These open models will always be there for you to run though (if you can get GPUs anyway).", "normalized_text": "wow i really didn’t think this would happen any time soon they seem to have more to lose than to gain if you’re a company building ai into your product right now i think you would be irresponsible to not investigate how much you can do on open weights models the big ai labs are going to pull the ladder up eventually building your business on the apis long term is foolish these open models will always be there for you to run though if you can get gpus anyway", "model_tags": [], "aspect_hints": ["usability_ux", "ethics", "business_model"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "habosa", "node_time": "2025-08-06T03:44:35+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44807852, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Super shallow (24/36 layers) MoE with low active parameter counts (3.6B/5.1B), a tradeoff between inference speed and performance. Text only, which is okay. Weights partially in MXFP4, but no cuda kernel support for RTX 50 series (sm120). Why? This is a NO for me. Safety alignment shifts from off the charts to off the rails really fast if you keep prompting. This is a NO for me. In summary, a solid NO for me.", "normalized_text": "super shallow 24 36 layers moe with low active parameter counts 3 6b 5 1b a tradeoff between inference speed and performance text only which is okay weights partially in mxfp4 but no cuda kernel support for rtx 50 series sm120 why this is a no for me safety alignment shifts from off the charts to off the rails really fast if you keep prompting this is a no for me in summary a solid no for me", "model_tags": [], "aspect_hints": ["performance_speed", "regulation_policy"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "RandyOrion", "node_time": "2025-08-06T05:01:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44809876, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "This is an extremely welcome move in a good direction from OpenAI. I can only thank them for all of the extra work around the models - Harmony structure, metal/torch/triton implementations, inference guides, cookbooks & fine-tuning/reinforcement learning scripts, datasets etc. There is an insane amount of helpful information buried in this release", "normalized_text": "this is an extremely welcome move in a good direction from openai i can only thank them for all of the extra work around the models harmony structure metal torch triton implementations inference guides cookbooks fine tuning reinforcement learning scripts datasets etc there is an insane amount of helpful information buried in this release", "model_tags": ["openai"], "aspect_hints": ["privacy", "usability_ux", "ethics"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "jpcompartir", "node_time": "2025-08-06T09:41:43+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44810200, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "Why would OpenAI give this away for free? Is it to disrupt competition by setting a floor at the lower end of the market and make it harder for new competition to emerge while still retaining mind share?", "normalized_text": "why would openai give this away for free is it to disrupt competition by setting a floor at the lower end of the market and make it harder for new competition to emerge while still retaining mind share", "model_tags": ["openai"], "aspect_hints": ["business_model"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "__alexs", "node_time": "2025-08-06T10:28:10+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44810234, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "I'm a well-known OpenAI hater, but there's haters and haters, and refusing to acknowledge great work is the latter. Well done OpenAI, this seems like a sincere effort to do a real open model with competitive performance, usable/workable licensing, a tokenizer compatible with your commercial offerings, it's a real contribution. Probably the most open useful thing since Whisper that also kicked ass. Keep this sort of thing up and I might start re-evaliating how I feel about this company.", "normalized_text": "i m a well known openai hater but there s haters and haters and refusing to acknowledge great work is the latter well done openai this seems like a sincere effort to do a real open model with competitive performance usable workable licensing a tokenizer compatible with your commercial offerings it s a real contribution probably the most open useful thing since whisper that also kicked ass keep this sort of thing up and i might start re evaliating how i feel about this company", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "benreesman", "node_time": "2025-08-06T10:33:39+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44810311, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "I want to take this chance to say a big thank you to OpenAI and your work. I have always been a fan since I noticed you hired the sandbox game kickstarter guy about like 8 years ago. Even from the UK I knew you would all do great things ( I had had no idea who else was involved). I am glad I see the top comment is rare praise on HN. Thanks again and keep it up Sama and team.", "normalized_text": "i want to take this chance to say a big thank you to openai and your work i have always been a fan since i noticed you hired the sandbox game kickstarter guy about like 8 years ago even from the uk i knew you would all do great things i had had no idea who else was involved i am glad i see the top comment is rare praise on hn thanks again and keep it up sama and team", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "ionwake", "node_time": "2025-08-06T10:45:50+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44811891, "root_story_id": 44800746, "node_type": "comment", "comment_depth": 1, "text": "I did a quick testing on an Macbook Pro M1 16GB. Pretty impressed with it so far. * It seems that using version @lmstudio's 20B gguf version ( ) will have options for reasoning effort. * My MBP M1 16GB config: temp 0.8, max content length 7990, GPU offload 8/24, runs slow and still fine for me. * I tried testing with MCP with the above config, with basic tools like time and fetch + reasoning effort low, and the tool calls instruction follow is quite good. * In LM Studio's Developer tab there is a log output about the model information which is useful to learn. Overall, I like the way OpenAI backs to being Open AI, again, after all those years. -- Shameless plug, If anyone want to try out gpt-oss-120b and gpt-oss-20b as alternative to their own demo page [0], I have added both models with OpenRouter providers in VT Chat [1] as real product. You can try with an OpenRouter API Key. [0] [1]", "normalized_text": "i did a quick testing on an macbook pro m1 16gb pretty impressed with it so far it seems that using version lmstudio s 20b gguf version will have options for reasoning effort my mbp m1 16gb config temp 0 8 max content length 7990 gpu offload 8 24 runs slow and still fine for me i tried testing with mcp with the above config with basic tools like time and fetch reasoning effort low and the tool calls instruction follow is quite good in lm studio s developer tab there is a log output about the model information which is useful to learn overall i like the way openai backs to being open ai again after all those years shameless plug if anyone want to try out gpt oss 120b and gpt oss 20b as alternative to their own demo page 0 i have added both models with openrouter providers in vt chat 1 as real product you can try with an openrouter api key 0 1", "model_tags": ["openai"], "aspect_hints": ["performance_speed", "usability_ux"], "context": {"root_title": "Open models by OpenAI", "root_author": "lackoftactics", "root_url": "https://openai.com/open-models/", "node_author": "vinhnx", "node_time": "2025-08-06T13:41:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44826563, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "For day to day coding, I've found Anthropic to be killing it with Sonnet 3.7 and now Sonnet 4, and Claude Code feeling like it has even bigger advantages over when it's used in Cursor (And I can't explain why). I don't even try to use the OpenAI models because it's felt like night and day. Hopefully GPT-5 helps them catch up. Although I'm sure there are 100 people that have their own personal \"hopefully GPT-5 fixes my personal issue with GPT4\"", "normalized_text": "for day to day coding i ve found anthropic to be killing it with sonnet 3 7 and now sonnet 4 and claude code feeling like it has even bigger advantages over when it s used in cursor and i can t explain why i don t even try to use the openai models because it s felt like night and day hopefully gpt 5 helps them catch up although i m sure there are 100 people that have their own personal hopefully gpt 5 fixes my personal issue with gpt4", "model_tags": ["openai", "anthropic"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "atonse", "node_time": "2025-08-07T16:25:03+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44826932, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "It's very unclear if OpenAI has been casually leaking things to create buzz, but a few days ago there was a pretty stunning pelican on a bike attempt: In practice, it's very clear to me that the most important value in writing software with an LLM isn't it's ability to one-shot hard problems, but rather it's ability to effectively manage complex context. There are no good evals for this kind of problem, but that's what I'm keenly interested in understanding. Show me GPT-5 can move through 10 steps in a list of tasks without completely losing the objective by the end.", "normalized_text": "it s very unclear if openai has been casually leaking things to create buzz but a few days ago there was a pretty stunning pelican on a bike attempt in practice it s very clear to me that the most important value in writing software with an llm isn t it s ability to one shot hard problems but rather it s ability to effectively manage complex context there are no good evals for this kind of problem but that s what i m keenly interested in understanding show me gpt 5 can move through 10 steps in a list of tasks without completely losing the objective by the end", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "aliljet", "node_time": "2025-08-07T16:54:14+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827005, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "# GPT5 all official links Livestream link: Research blog post: Developer blog post: API Docs: Note the free form function calling documentation: GPT5 prompting guide: GPT5 new params and tools: GPT5 frontend cookbook: prompt migrator/optimizor Enterprise blog post: System Card: What would you say if you could talk to a future OpenAI model? coding examples:", "normalized_text": "gpt5 all official links livestream link research blog post developer blog post api docs note the free form function calling documentation gpt5 prompting guide gpt5 new params and tools gpt5 frontend cookbook prompt migrator optimizor enterprise blog post system card what would you say if you could talk to a future openai model coding examples", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "swyx", "node_time": "2025-08-07T17:01:02+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827060, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "It's very interesting how memetic the language around different models is. Elon seems to have coined \"PhD level intelligence in all topics\" and now Sam repeated it in his presentation. Despite it not having an actual meaning. I think OpenAI will coin they've achieved AGI first (as they have incentives to based on the rumored contract with MSFT), and then everyone will claim we've achieved it.", "normalized_text": "it s very interesting how memetic the language around different models is elon seems to have coined phd level intelligence in all topics and now sam repeated it in his presentation despite it not having an actual meaning i think openai will coin they ve achieved agi first as they have incentives to based on the rumored contract with msft and then everyone will claim we ve achieved it", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "bmau5", "node_time": "2025-08-07T17:04:19+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827078, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "The eval bar I want to see here is simple: over a complex objective (e.g., deploy to prod using a git workflow), how many tasks can GPT-5 stay on track with before it falls off the train. Context is king and it's the most obvious and glaring problem with current models.", "normalized_text": "the eval bar i want to see here is simple over a complex objective e g deploy to prod using a git workflow how many tasks can gpt 5 stay on track with before it falls off the train context is king and it s the most obvious and glaring problem with current models", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "aliljet", "node_time": "2025-08-07T17:05:30+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827088, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "The marketing copy and the current livestream appear tautological: \"it's better because it's better.\" Not much explanation yet why GPT-5 warrants a major version bump. As usual, the model (and potentially OpenAI as a whole) will depend on output vibe checks.", "normalized_text": "the marketing copy and the current livestream appear tautological it s better because it s better not much explanation yet why gpt 5 warrants a major version bump as usual the model and potentially openai as a whole will depend on output vibe checks", "model_tags": ["openai"], "aspect_hints": ["business_model"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "minimaxir", "node_time": "2025-08-07T17:05:58+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827110, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Does this mean AGI is cancelled? 2027 hard takeoff was just sci-fi?", "normalized_text": "does this mean agi is cancelled 2027 hard takeoff was just sci fi", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "ipnon", "node_time": "2025-08-07T17:07:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827119, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Seems LLMs really hit the wall.", "normalized_text": "seems llms really hit the wall", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "demirbey05", "node_time": "2025-08-07T17:07:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827123, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "The silent victory here is this seems like it is being built to be faster and cheaper than o3 while presenting a reasonable jump, which is an important jump in scaling law On the other hand if it's just getting bigger and slower it's not a good sign for LLMs", "normalized_text": "the silent victory here is this seems like it is being built to be faster and cheaper than o3 while presenting a reasonable jump which is an important jump in scaling law on the other hand if it s just getting bigger and slower it s not a good sign for llms", "model_tags": ["openai"], "aspect_hints": ["performance_speed", "usability_ux", "cost_price", "regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "cuuupid", "node_time": "2025-08-07T17:07:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827154, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Watching the livestream now, the improvement over their current models on the benchmarks is very small. I know they seemed to be trying to temper our expectations leading up to this, but this is much less improvement than I was expecting", "normalized_text": "watching the livestream now the improvement over their current models on the benchmarks is very small i know they seemed to be trying to temper our expectations leading up to this but this is much less improvement than i was expecting", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "doctoboggan", "node_time": "2025-08-07T17:08:59+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827167, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Note it's not available to everyone yet: > GPT-5 Rollout > We are gradually rolling out GPT-5 to ensure stability during launch. Some users may not yet see GPT-5 in their account as we increase availability in stages.", "normalized_text": "note it s not available to everyone yet gpt 5 rollout we are gradually rolling out gpt 5 to ensure stability during launch some users may not yet see gpt 5 in their account as we increase availability in stages", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "wgjordan", "node_time": "2025-08-07T17:09:47+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827170, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "SWE-Bench Verified score, with thinking, ties Opus 4.1 without thinking. AIME scores do not appear too impressive at first glance. They are downplaying benchmarks heavily in the live stream. This was the lab that has been flexing benchmarks as headline figures since forever. This is a product-focused update. There is no significant jump in raw intelligence or agentic behavior against SOTA.", "normalized_text": "swe bench verified score with thinking ties opus 4 1 without thinking aime scores do not appear too impressive at first glance they are downplaying benchmarks heavily in the live stream this was the lab that has been flexing benchmarks as headline figures since forever this is a product focused update there is no significant jump in raw intelligence or agentic behavior against sota", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "thegeomaster", "node_time": "2025-08-07T17:09:51+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827179, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "What's going on with their SWE bench graph?[0] GPT-5 non-thinking is labeled 52.8% accuracy, but o3 is shown as a much shorter bar, yet it's labeled 69.1%. And 4o is an identical bar to o3, but it's labeled 30.8%... [0]", "normalized_text": "what s going on with their swe bench graph 0 gpt 5 non thinking is labeled 52 8 accuracy but o3 is shown as a much shorter bar yet it s labeled 69 1 and 4o is an identical bar to o3 but it s labeled 30 8 0", "model_tags": ["openai"], "aspect_hints": ["accuracy_reliability"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "mtlynch", "node_time": "2025-08-07T17:10:12+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827204, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "The presentation asks for a moving svg to illustrate Bernoulli, that's suspiciously close to a Pelican.", "normalized_text": "the presentation asks for a moving svg to illustrate bernoulli that s suspiciously close to a pelican", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "croemer", "node_time": "2025-08-07T17:11:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827210, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Wait, isn't the Bernoulli effect thing they're demoing now wrong? I thought that was a \"common misconception\" and wings don't really work by the \"longer path\" that air takes over the top, and that it was more about angle of attack (which is why planes can fly upside down). It seems like it's actually an ideal \"trick\" question for an LLM actually, since so much content has been written about it incorrectly. I thought at first they were going to demo this to show that it knew better, but it seems like it's just regurgitating the same misleading stuff. So, not a good look.", "normalized_text": "wait isn t the bernoulli effect thing they re demoing now wrong i thought that was a common misconception and wings don t really work by the longer path that air takes over the top and that it was more about angle of attack which is why planes can fly upside down it seems like it s actually an ideal trick question for an llm actually since so much content has been written about it incorrectly i thought at first they were going to demo this to show that it knew better but it seems like it s just regurgitating the same misleading stuff so not a good look", "model_tags": [], "aspect_hints": ["accuracy_reliability", "regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "losvedir", "node_time": "2025-08-07T17:12:04+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827244, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "74.9 SWEBench. This increases the SOTA by a whole .4%. Although the pricing is great, it doesn't seem like OpenAI found a giant breakthrough yet like o1 or Claude 3.5 Sonnet", "normalized_text": "74 9 swebench this increases the sota by a whole 4 although the pricing is great it doesn t seem like openai found a giant breakthrough yet like o1 or claude 3 5 sonnet", "model_tags": ["openai", "anthropic"], "aspect_hints": ["cost_price"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "oof-baroomf", "node_time": "2025-08-07T17:13:51+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827250, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "These presenters all give off such a “sterile” vibe", "normalized_text": "these presenters all give off such a “sterile” vibe", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "spruce_tips", "node_time": "2025-08-07T17:14:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827265, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "‘Twas the night before GPT-5, when all through the social-media-sphere, Not a creature was posting, not even @paulg nor @eshear Next morning’s posts were prepped and scheduled with care, In hopes that AGI soon would appear …", "normalized_text": "‘twas the night before gpt 5 when all through the social media sphere not a creature was posting not even paulg nor eshear next morning’s posts were prepped and scheduled with care in hopes that agi soon would appear …", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "mehulashah", "node_time": "2025-08-07T17:15:23+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827304, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "What's going on with this plot's y-axis?", "normalized_text": "what s going on with this plot s y axis", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "tylermw", "node_time": "2025-08-07T17:17:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827308, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Did they just say they're deprecating all of OpenAI's non-GPT-5 models?", "normalized_text": "did they just say they re deprecating all of openai s non gpt 5 models", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "CamelCaseName", "node_time": "2025-08-07T17:17:38+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827314, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Sam Altman, in the summer update video: > \"[GPT-5] can write an entire computer program from scratch, to help you with whatever you'd like. And we think this idea of software on demand is going to be one of the defining characteristics of the GPT-5 era.\"", "normalized_text": "sam altman in the summer update video gpt 5 can write an entire computer program from scratch to help you with whatever you d like and we think this idea of software on demand is going to be one of the defining characteristics of the gpt 5 era", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "davepeck", "node_time": "2025-08-07T17:17:52+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827442, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Pricing seems good, but the open question is still on tool calling reliability. Input: $1.25 / 1M tokens Cached: $0.125 / 1M tokens Output: $10 / 1M tokens With 74.9% on SWE-bench, this inches out Claude Opus 4.1 at 74.5%, but at a much cheaper cost. For context, Claude Opus 4.1 is $15 / 1M input tokens and $75 / 1M output tokens. > \"GPT-5 will scaffold the app, write files, install dependencies as needed, and show a live preview. This is the go-to solution for developers who want to bootstrap apps or add features quickly.\" [0] Since Claude Code launched, OpenAI has been behind. Maybe the RL on tool calling is good enough to be competitive now? [0]", "normalized_text": "pricing seems good but the open question is still on tool calling reliability input 1 25 1m tokens cached 0 125 1m tokens output 10 1m tokens with 74 9 on swe bench this inches out claude opus 4 1 at 74 5 but at a much cheaper cost for context claude opus 4 1 is 15 1m input tokens and 75 1m output tokens gpt 5 will scaffold the app write files install dependencies as needed and show a live preview this is the go to solution for developers who want to bootstrap apps or add features quickly 0 since claude code launched openai has been behind maybe the rl on tool calling is good enough to be competitive now 0", "model_tags": ["openai", "anthropic"], "aspect_hints": ["accuracy_reliability", "usability_ux", "cost_price"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "jumploops", "node_time": "2025-08-07T17:25:27+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827498, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "ChatGPT5 in this demo: > For an airplane wing (airfoil), the top surface is curved and the bottom is flatter. When the wing moves forward: > * Air over the top has to travel farther in the same amount of time -> it moves faster -> pressure on the top decreases. > * Air underneath moves slower -> pressure underneath is higher > * The presure difference creates an upward force - lift Isn't that explanation of why wings work completely wrong? There's nothing that forces the air to cover the top distance in the same time that it covers the bottom distance, and in fact it doesn't. Very strange to use a mistake as your first demo, especially while talking about how it's phd level.", "normalized_text": "chatgpt5 in this demo for an airplane wing airfoil the top surface is curved and the bottom is flatter when the wing moves forward air over the top has to travel farther in the same amount of time it moves faster pressure on the top decreases air underneath moves slower pressure underneath is higher the presure difference creates an upward force lift isn t that explanation of why wings work completely wrong there s nothing that forces the air to cover the top distance in the same time that it covers the bottom distance and in fact it doesn t very strange to use a mistake as your first demo especially while talking about how it s phd level", "model_tags": ["openai"], "aspect_hints": ["performance_speed", "regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "kybernetikos", "node_time": "2025-08-07T17:28:18+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827568, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "LLMs hitting a wall would be incredible. We could actually start building on the tech we have.", "normalized_text": "llms hitting a wall would be incredible we could actually start building on the tech we have", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "Jimmc414", "node_time": "2025-08-07T17:32:36+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827748, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "The reduction in hallucinations seems like potentially the biggest upgrade. If it reduces hallucinations by 75% or more over o3 and GPT-4o as the graphs claim, it will be a giant step forward. The inability to trust answers given by AI is the biggest single hurdle to clear for many applications.", "normalized_text": "the reduction in hallucinations seems like potentially the biggest upgrade if it reduces hallucinations by 75 or more over o3 and gpt 4o as the graphs claim it will be a giant step forward the inability to trust answers given by ai is the biggest single hurdle to clear for many applications", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "modeless", "node_time": "2025-08-07T17:43:40+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827857, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Going by the system card at: > GPT‑5 is a unified system . . . OK > . . . with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and a real-time router that quickly decides which model to use based on conversation type, complexity, tool needs, and explicit intent (for example, if you say “think hard about this” in the prompt). So that's not really a unified system then, it's just supposed to appear as if it is. This looks like they're not training the single big model but instead have gone off to develop special sub models and attempt to gloss over them with yet another model. That's what you resort to only when doing the end-to-end training has become too expensive for you.", "normalized_text": "going by the system card at gpt‑5 is a unified system ok with a smart and fast model that answers most questions a deeper reasoning model for harder problems and a real time router that quickly decides which model to use based on conversation type complexity tool needs and explicit intent for example if you say “think hard about this” in the prompt so that s not really a unified system then it s just supposed to appear as if it is this looks like they re not training the single big model but instead have gone off to develop special sub models and attempt to gloss over them with yet another model that s what you resort to only when doing the end to end training has become too expensive for you", "model_tags": ["openai"], "aspect_hints": ["performance_speed", "usability_ux", "cost_price"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "fidotron", "node_time": "2025-08-07T17:49:31+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827878, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "> 400,000 context window > 128,000 max output tokens > Input $1.25 > Output $10.00 Source: If this performs well in independent needle-in-haystack and adherence evaluations, this pricing with this context window alone would make GPT-5 extremely competitive with Gemini 2.5 Pro and Claude Opus 4.1, even if the output isn't a significant improvement over o3. If the output quality ends up on-par or better than the two major competitors, that'd be truly a massive leap forward for OpenAI, mini and nano maybe even more so.", "normalized_text": "400 000 context window 128 000 max output tokens input 1 25 output 10 00 source if this performs well in independent needle in haystack and adherence evaluations this pricing with this context window alone would make gpt 5 extremely competitive with gemini 2 5 pro and claude opus 4 1 even if the output isn t a significant improvement over o3 if the output quality ends up on par or better than the two major competitors that d be truly a massive leap forward for openai mini and nano maybe even more so", "model_tags": ["openai", "anthropic", "google"], "aspect_hints": ["cost_price"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "Topfi", "node_time": "2025-08-07T17:51:02+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827929, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "GPT-5 knowledge cutoff: Sep 30, 2024 (10 months before release). Compare that to Gemini 2.5 Pro knowledge cutoff: Jan 2025 (3 months before release) Claude Opus 4.1: knowledge cutoff: Mar 2025 (4 months before release)", "normalized_text": "gpt 5 knowledge cutoff sep 30 2024 10 months before release compare that to gemini 2 5 pro knowledge cutoff jan 2025 3 months before release claude opus 4 1 knowledge cutoff mar 2025 4 months before release", "model_tags": ["openai", "anthropic", "google"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "surround", "node_time": "2025-08-07T17:53:29+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44827962, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "I know HN isn’t the place to go for positive, uplifting commentary or optimism about technology - but I am truly excited for this release and grateful to all the team members who made it possible. What a great time to be alive.", "normalized_text": "i know hn isn’t the place to go for positive uplifting commentary or optimism about technology but i am truly excited for this release and grateful to all the team members who made it possible what a great time to be alive", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "mrcwinn", "node_time": "2025-08-07T17:55:49+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44828079, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Some people have hypothesized that GPT-5 is actually about cost reduction and internal optimization for OpenAI, since there doesn't seem to be much of a leap forward, but another element that they seem to have focused on that'll probably make a huge difference to \"normal\" (non-tech) users is making precise and specifically worded prompts less necessary. They've mentioned improvements in that aspects a few times now, and if it actually materializes, that would be a big leap forward for most users even if underneath GPT-4 was also technically able to do the same things if prompted just the right way.", "normalized_text": "some people have hypothesized that gpt 5 is actually about cost reduction and internal optimization for openai since there doesn t seem to be much of a leap forward but another element that they seem to have focused on that ll probably make a huge difference to normal non tech users is making precise and specifically worded prompts less necessary they ve mentioned improvements in that aspects a few times now and if it actually materializes that would be a big leap forward for most users even if underneath gpt 4 was also technically able to do the same things if prompted just the right way", "model_tags": ["openai"], "aspect_hints": ["cost_price", "regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "sundarurfriend", "node_time": "2025-08-07T18:02:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44828130, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Nay, laddie, that's no' the real AGI Scotsman. He's grander still! Wait til GPT-6 come out, you'll be blown away!", "normalized_text": "nay laddie that s no the real agi scotsman he s grander still wait til gpt 6 come out you ll be blown away", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "firefoxd", "node_time": "2025-08-07T18:04:57+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44828137, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "It is frequently suggested that once one of the AI companies reaches an AGI threshold, they will take off ahead of the rest. It's interesting to note that at least so far, the trend has been the opposite: as time goes on and the models get better, the performance of the different company's gets clustered closer together. Right now GPT-5, Claude Opus, Grok 4, Gemini 2.5 Pro all seem quite good across the board (ie they can all basically solve moderately challenging math and coding problems). As a user, it feels like the race has never been as close as it is now. Perhaps dumb to extrapolate, but it makes me lean more skeptical about the hard take-off / winner-take-all mental model that has been pushed. Would be curious to hear the take of a researcher at one of these firms - do you expect the AI offerings across competitors to become more competitive and clustered over the next few years, or less so?", "normalized_text": "it is frequently suggested that once one of the ai companies reaches an agi threshold they will take off ahead of the rest it s interesting to note that at least so far the trend has been the opposite as time goes on and the models get better the performance of the different company s gets clustered closer together right now gpt 5 claude opus grok 4 gemini 2 5 pro all seem quite good across the board ie they can all basically solve moderately challenging math and coding problems as a user it feels like the race has never been as close as it is now perhaps dumb to extrapolate but it makes me lean more skeptical about the hard take off winner take all mental model that has been pushed would be curious to hear the take of a researcher at one of these firms do you expect the ai offerings across competitors to become more competitive and clustered over the next few years or less so", "model_tags": ["openai", "anthropic", "google"], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "highfrequency", "node_time": "2025-08-07T18:05:12+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44828159, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "They will retire lots of models: GPT-4o, GPT-4.1, GPT-4.5, GPT-4.1-mini, o4-mini, o4-mini-high, o3, o3-pro. \"If you open a conversation that used one of these models, ChatGPT will automatically switch it to the closest GPT-5 equivalent.\" - 4o, 4.1, 4.5, 4.1-mini, o4-mini, or o4-mini-high => GPT-5 - o3 => GPT-5-Thinking - o3-Pro => GPT-5-Pro", "normalized_text": "they will retire lots of models gpt 4o gpt 4 1 gpt 4 5 gpt 4 1 mini o4 mini o4 mini high o3 o3 pro if you open a conversation that used one of these models chatgpt will automatically switch it to the closest gpt 5 equivalent 4o 4 1 4 5 4 1 mini o4 mini or o4 mini high gpt 5 o3 gpt 5 thinking o3 pro gpt 5 pro", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "hrpnk", "node_time": "2025-08-07T18:06:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44828661, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "That SWE-bench chart with the mismatched bars (52.8% somehow appearing larger than 69.1%) was emblematic of the entire presentation - rushed and underwhelming. It's the kind of error that would get flagged in any internal review, yet here it is in a billion-dollar product launch. Combined with the Bernoulli effect demo confidently explaining how airplane wings work incorrectly (the equal transit time fallacy that NASA explicitly debunks), it doesn't inspire confidence in either the model's capabilities or OpenAI's quality control. The actual benchmark improvements are marginal at best - we're talking single-digit percentage gains over o3 on most metrics, which hardly justifies a major version bump. What we're seeing looks more like the plateau of an S-curve than a breakthrough. The pricing is competitive ($1.25/1M input tokens vs Claude's $15), but that's about optimization and economics, not the fundamental leap forward that \"GPT-5\" implies. Even their \"unified system\" turns out to be multiple models with a router, essentially admitting that the end-to-end training approach has hit diminishing returns. The irony is that while OpenAI maintains their secretive culture (remember when they claimed o1 used tree search instead of RL?), their competitors are catching up or surpassing them. Claude has been consistently better for coding tasks, Gemini 2.5 Pro has more recent training data, and everyone seems to be converging on similar performance levels. This launch feels less like a victory lap and more like OpenAI trying to maintain relevance while the rest of the field has caught up. Looking forward to seeing what Gemini 3.0 brings to the table.", "normalized_text": "that swe bench chart with the mismatched bars 52 8 somehow appearing larger than 69 1 was emblematic of the entire presentation rushed and underwhelming it s the kind of error that would get flagged in any internal review yet here it is in a billion dollar product launch combined with the bernoulli effect demo confidently explaining how airplane wings work incorrectly the equal transit time fallacy that nasa explicitly debunks it doesn t inspire confidence in either the model s capabilities or openai s quality control the actual benchmark improvements are marginal at best we re talking single digit percentage gains over o3 on most metrics which hardly justifies a major version bump what we re seeing looks more like the plateau of an s curve than a breakthrough the pricing is competitive 1 25 1m input tokens vs claude s 15 but that s about optimization and economics not the fundamental leap forward that gpt 5 implies even their unified system turns out to be multiple models with a router essentially admitting that the end to end training approach has hit diminishing returns the irony is that while openai maintains their secretive culture remember when they claimed o1 used tree search instead of rl their competitors are catching up or surpassing them claude has been consistently better for coding tasks gemini 2 5 pro has more recent training data and everyone seems to be converging on similar performance levels this launch feels less like a victory lap and more like openai trying to maintain relevance while the rest of the field has caught up looking forward to seeing what gemini 3 0 brings to the table", "model_tags": ["openai", "anthropic", "google"], "aspect_hints": ["accuracy_reliability", "privacy", "cost_price", "regulation_policy", "community_tone"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "henriquegodoy", "node_time": "2025-08-07T18:41:00+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44828914, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Very funny. The very first answer it gave to illustrate its \"Expert knowledge\" is quite common, and it's wrong. What's even funnier is that you can find why on Wikipedia: What's terminally funny is that in the visualisation app, it used a symmetric wing, which of course wouldn't generate lift according to its own explanation (as the travelled distance and hence air flow speed would be the same). I work as a game physics programmer, so I noticed that immediately and almost laughed. I watched only that part so far while I was still at the office, though.", "normalized_text": "very funny the very first answer it gave to illustrate its expert knowledge is quite common and it s wrong what s even funnier is that you can find why on wikipedia what s terminally funny is that in the visualisation app it used a symmetric wing which of course wouldn t generate lift according to its own explanation as the travelled distance and hence air flow speed would be the same i work as a game physics programmer so i noticed that immediately and almost laughed i watched only that part so far while i was still at the office though", "model_tags": [], "aspect_hints": ["performance_speed", "usability_ux"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "m4nu3l", "node_time": "2025-08-07T19:02:17+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44829109, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Answer in one word: Underwhelming. Bad data on graphs, demos that would have been impressive a year ago, vibe coding the easiest requests (financial dashboard), running out of talking points while cursor is looping on a bug, marginal benchmark improvements. At least the models are kind of cheaper to run.", "normalized_text": "answer in one word underwhelming bad data on graphs demos that would have been impressive a year ago vibe coding the easiest requests financial dashboard running out of talking points while cursor is looping on a bug marginal benchmark improvements at least the models are kind of cheaper to run", "model_tags": [], "aspect_hints": ["accuracy_reliability", "privacy", "cost_price"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "ftkftk", "node_time": "2025-08-07T19:18:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44829627, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Wish they would stop mentioning AGI. It's like the creator of a new car claiming it's a step closer to teleportation.", "normalized_text": "wish they would stop mentioning agi it s like the creator of a new car claiming it s a step closer to teleportation", "model_tags": [], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "DrSiemer", "node_time": "2025-08-07T20:00:41+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44829730, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "I'm not really convinced, the benchmark blunder was really strange but the demos were quite underwhelming, and it appears this was reflected by a huge market correction in the betting markets as to who will have the best AI by end of the year. What excites me now is that Gemini 3.0 or some answer from Google is coming soon and that will be the one I will actually end up using. It seems like the last mover in the LLM race is more advantageous.", "normalized_text": "i m not really convinced the benchmark blunder was really strange but the demos were quite underwhelming and it appears this was reflected by a huge market correction in the betting markets as to who will have the best ai by end of the year what excites me now is that gemini 3 0 or some answer from google is coming soon and that will be the one i will actually end up using it seems like the last mover in the llm race is more advantageous", "model_tags": ["google"], "aspect_hints": ["accuracy_reliability", "usability_ux", "regulation_policy", "business_model"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "AgentMatrixAI", "node_time": "2025-08-07T20:09:20+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44829867, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "I ran the below prompt to both Kimi2 and GPT5. how many rs in cranberry? -- GPT5's response: The word cranberry has two “r”s. One in cran and one in berry. Kimi2's response: There are three letter rs in the word \"cranberry\".", "normalized_text": "i ran the below prompt to both kimi2 and gpt5 how many rs in cranberry gpt5 s response the word cranberry has two “r”s one in cran and one in berry kimi2 s response there are three letter rs in the word cranberry", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "punee94", "node_time": "2025-08-07T20:22:48+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44830541, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Anecdotally, as someone who operates in a very large legacy codebase, I am very impressed by GPT-5's agentic abilities so far. I've given it the same tasks I've given Claude and previous iterations via the Codex CLI, and instead of getting loss due to the massive scope of the problem, it correctly identifies the large scope and breaks it down into it's correct parts and creates the correct plan and begins executing. I am wildly impressed. I do not believe that the 0.x% increase in benchmarks tell the story of this release at all.", "normalized_text": "anecdotally as someone who operates in a very large legacy codebase i am very impressed by gpt 5 s agentic abilities so far i ve given it the same tasks i ve given claude and previous iterations via the codex cli and instead of getting loss due to the massive scope of the problem it correctly identifies the large scope and breaks it down into it s correct parts and creates the correct plan and begins executing i am wildly impressed i do not believe that the 0 x increase in benchmarks tell the story of this release at all", "model_tags": ["openai", "anthropic"], "aspect_hints": ["accuracy_reliability"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "hahahacorn", "node_time": "2025-08-07T21:23:17+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44830601, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "It's a really good model from my testing so far. You can see the difference in how it tries to use tools to the greatest extent when answering a question, especially compared to 4.1 and o3. In this example it used 6! tool calls in the first response to try and collect as much info as possible.", "normalized_text": "it s a really good model from my testing so far you can see the difference in how it tries to use tools to the greatest extent when answering a question especially compared to 4 1 and o3 in this example it used 6 tool calls in the first response to try and collect as much info as possible", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "joshmlewis", "node_time": "2025-08-07T21:28:25+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44831004, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Whenever OpenAI releases a new ChatGPT feature or model, it's always a crapshoot when you'll actually be able to use it. The headlines - both from tech media coverage and OpenAI itself - always read \"now available\", but then I go to ChatGPT (and I'm a paid pro user) and it's not available yet. As an engineer I understand rollouts, but maybe don't say it's generally available when it's not?", "normalized_text": "whenever openai releases a new chatgpt feature or model it s always a crapshoot when you ll actually be able to use it the headlines both from tech media coverage and openai itself always read now available but then i go to chatgpt and i m a paid pro user and it s not available yet as an engineer i understand rollouts but maybe don t say it s generally available when it s not", "model_tags": ["openai"], "aspect_hints": ["regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "jdelman", "node_time": "2025-08-07T22:11:18+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44831137, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "GPT-5 set a new record on my Confabulations on Provided Texts benchmark:", "normalized_text": "gpt 5 set a new record on my confabulations on provided texts benchmark", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "zone411", "node_time": "2025-08-07T22:23:53+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44831822, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "I am thoroughly unimpressed by GPT-5. It still can't compose iambic trimeters in ancient Greek with a proper penthemimeral cæsura, and it insists on providing totally incorrect scansion of the flawed lines it does compose. I corrected its metrical sins twice, which sent it into \"thinking\" mode until it finally returned a \"Reasoning failed\" error. There is no intelligence here: it's still just giving plausible output. That's why it can't metrically scan its own lines or put a cæsura in the right place.", "normalized_text": "i am thoroughly unimpressed by gpt 5 it still can t compose iambic trimeters in ancient greek with a proper penthemimeral cæsura and it insists on providing totally incorrect scansion of the flawed lines it does compose i corrected its metrical sins twice which sent it into thinking mode until it finally returned a reasoning failed error there is no intelligence here it s still just giving plausible output that s why it can t metrically scan its own lines or put a cæsura in the right place", "model_tags": ["openai"], "aspect_hints": ["accuracy_reliability", "regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "Telemakhos", "node_time": "2025-08-07T23:51:31+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44832987, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Something that's really hitting me is something brought up in this piece: When a model comes out, I usually think about it in terms of my own use. This is largely agentic tooling, and I mostly us Claude Code. All the hallucination and eval talk doesn't really catch me because I feel like I'm getting value of these tools today. However, this model is not _for_ me in the same way models normally are. This is for the 800m or whatever people that open up chatgpt every day and type stuff in. All of them have been stuck on GPT-4o unbeknwst to them. They had no idea SOTA was far beyond that. They probably dont even know that there is a \"model\" at all. But for all these people, they just got a MAJOR upgrade. It will probably feel like turning the lights on for these people, who have been using a subpar model for the past year. That said I'm also giving GPT-5 a run in Codex and it's doing a pretty good job!", "normalized_text": "something that s really hitting me is something brought up in this piece when a model comes out i usually think about it in terms of my own use this is largely agentic tooling and i mostly us claude code all the hallucination and eval talk doesn t really catch me because i feel like i m getting value of these tools today however this model is not for me in the same way models normally are this is for the 800m or whatever people that open up chatgpt every day and type stuff in all of them have been stuck on gpt 4o unbeknwst to them they had no idea sota was far beyond that they probably dont even know that there is a model at all but for all these people they just got a major upgrade it will probably feel like turning the lights on for these people who have been using a subpar model for the past year that said i m also giving gpt 5 a run in codex and it s doing a pretty good job", "model_tags": ["openai", "anthropic"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "kkukshtel", "node_time": "2025-08-08T03:08:15+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44835029, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "created a summary of comments from this thread about 15 hours after it had been posted and had 1983 comments, using gpt-5-high and gemini-2.5-pro using a prompt similar to simonw [1]. Used a Python script [2] that I wrote to generate the summary. - gpt-5-high summary: - gemini-2.5-pro summary: [1]: [2]:", "normalized_text": "created a summary of comments from this thread about 15 hours after it had been posted and had 1983 comments using gpt 5 high and gemini 2 5 pro using a prompt similar to simonw 1 used a python script 2 that i wrote to generate the summary gpt 5 high summary gemini 2 5 pro summary 1 2", "model_tags": ["openai", "google"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "primaprashant", "node_time": "2025-08-08T09:13:58+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44835612, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Ok this[0] sounds very, uh bold to me? Surely this is going to break a ton of workflows etc seemingly with nearly no notice? I'm assuming 'launches' equates with 'fully rolls out' or something but it's not that clear to me. When GPT-5 launches, several older models will be retired, including: - GPT-4o - GPT-4.1 - GPT-4.5 - GPT-4.1-mini - o4-mini - o4-mini-high - o3 - o3-pro If you open a conversation that used one of these models, ChatGPT will automatically switch it to the closest GPT-5 equivalent. Chats with 4o, 4.1, 4.5, 4.1-mini, o4-mini, or o4-mini-high will open in GPT-5, chats with o3 will open in GPT-5-Thinking, and chats with o3-Pro will open in GPT-5-Pro (available only on Pro and Team). [0]", "normalized_text": "ok this 0 sounds very uh bold to me surely this is going to break a ton of workflows etc seemingly with nearly no notice i m assuming launches equates with fully rolls out or something but it s not that clear to me when gpt 5 launches several older models will be retired including gpt 4o gpt 4 1 gpt 4 5 gpt 4 1 mini o4 mini o4 mini high o3 o3 pro if you open a conversation that used one of these models chatgpt will automatically switch it to the closest gpt 5 equivalent chats with 4o 4 1 4 5 4 1 mini o4 mini or o4 mini high will open in gpt 5 chats with o3 will open in gpt 5 thinking and chats with o3 pro will open in gpt 5 pro available only on pro and team 0", "model_tags": ["openai"], "aspect_hints": ["usability_ux"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "ritzaco", "node_time": "2025-08-08T11:02:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44836626, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Already a lot of comments here (2188 at the time of this comment) but wanted to share my 2c: * It feels a bit more competent, as if it had more nuance or detail to say about each point. * It got a few obscure details about OpenBSD correct right away - both Sonnet 4 and 4o sometimes conflate Linux and OpenBSD commands. * It was fun asking GPT-5 to not only answer the query, but also to provide a brief analysis of the query itself for insights into myself! Not a detailed review, but just a couple things I noticed with some limited usage.", "normalized_text": "already a lot of comments here 2188 at the time of this comment but wanted to share my 2c it feels a bit more competent as if it had more nuance or detail to say about each point it got a few obscure details about openbsd correct right away both sonnet 4 and 4o sometimes conflate linux and openbsd commands it was fun asking gpt 5 to not only answer the query but also to provide a brief analysis of the query itself for insights into myself not a detailed review but just a couple things i noticed with some limited usage", "model_tags": ["openai"], "aspect_hints": ["accuracy_reliability", "usability_ux"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "accrual", "node_time": "2025-08-08T13:19:12+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44837225, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "They really nerfed Plus[0]. 80 messages every 3 hours for normal GPT-5. And only 200 messages per week for GPT-5 Thinking. It seems like terrible value. Before it was: 100 o3 per week 100 o4-mini-high per day 300 o4-mini per day 50 4.5 per week [0]", "normalized_text": "they really nerfed plus 0 80 messages every 3 hours for normal gpt 5 and only 200 messages per week for gpt 5 thinking it seems like terrible value before it was 100 o3 per week 100 o4 mini high per day 300 o4 mini per day 50 4 5 per week 0", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "Argonaut998", "node_time": "2025-08-08T14:15:22+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44837940, "root_story_id": 44826997, "node_type": "comment", "comment_depth": 1, "text": "Is anyone else having problems with factual correctness? I had a number of 4o and o3 conversations going and those models were factually correct about a number of different subjects. Asking GPT-5 about the same things results in wrong answers even though its training data is newer. And it won't look things up to correct itself unless I manually switch to the thinking variant. This is worse. I cancelled my subscription.", "normalized_text": "is anyone else having problems with factual correctness i had a number of 4o and o3 conversations going and those models were factually correct about a number of different subjects asking gpt 5 about the same things results in wrong answers even though its training data is newer and it won t look things up to correct itself unless i manually switch to the thinking variant this is worse i cancelled my subscription", "model_tags": ["openai"], "aspect_hints": ["accuracy_reliability", "privacy", "cost_price", "regulation_policy"], "context": {"root_title": "GPT-5", "root_author": "rd", "root_url": "https://openai.com/gpt-5/", "node_author": "00deadbeef", "node_time": "2025-08-08T15:09:37+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972416, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "He wants educators to instead teach “how do you think and how do you decompose problems” Ahmen! I attend this same church. My favorite professor in engineering school always gave open book tests. In the real world of work, everyone has full access to all the available data and information. Very few jobs involve paying someone simply to look up data in a book or on the internet. What they will pay for is someone who can analyze, understand, reason and apply data and information in unique ways needed to solve problems. Doing this is called \"engineering\". And this is what this professor taught.", "normalized_text": "he wants educators to instead teach “how do you think and how do you decompose problems” ahmen i attend this same church my favorite professor in engineering school always gave open book tests in the real world of work everyone has full access to all the available data and information very few jobs involve paying someone simply to look up data in a book or on the internet what they will pay for is someone who can analyze understand reason and apply data and information in unique ways needed to solve problems doing this is called engineering and this is what this professor taught", "model_tags": [], "aspect_hints": ["privacy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "jqpabc123", "node_time": "2025-08-21T13:18:36+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972458, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Might want to clarify things with your boss who says otherwise [1]? I do wish journalists would stop quoting these people unedited. No one knows what will actually happen. [1]:", "normalized_text": "might want to clarify things with your boss who says otherwise 1 i do wish journalists would stop quoting these people unedited no one knows what will actually happen 1", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "pj_mukh", "node_time": "2025-08-21T13:22:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972482, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Most people don't notice but there has been a inflation in headcounts over the years now. This happened around the time microservices architecture trend took over. All of sudden to ensure better support and separation of concerns people needed a team with a manager for each service. If this hadn't been the case, the industry as a whole can likely work with 40% - 50% less people eventually. Thats because at any given point in time even with a large monolithic codebase only 10 - 20% of the code base is in active evolution, what that means in microservices world is equivalent amount teams are sitting idle. When I started out huge C++ and Java code bases were pretty much the norm, and it was also one of the reasons why things were hard and barrier to entry high. In this microservices world, things are small enough that any small group of even low productivity employees can make things work. That is quite literally true, because smaller things that work well don't even need all that many changes on a everyday basis. To me its these kind of places that are in real trouble. There is not enough work to justify keeping dozens to even hundreds of teams, their managements and their hierarchies all working for quite literally doing nothing.", "normalized_text": "most people don t notice but there has been a inflation in headcounts over the years now this happened around the time microservices architecture trend took over all of sudden to ensure better support and separation of concerns people needed a team with a manager for each service if this hadn t been the case the industry as a whole can likely work with 40 50 less people eventually thats because at any given point in time even with a large monolithic codebase only 10 20 of the code base is in active evolution what that means in microservices world is equivalent amount teams are sitting idle when i started out huge c and java code bases were pretty much the norm and it was also one of the reasons why things were hard and barrier to entry high in this microservices world things are small enough that any small group of even low productivity employees can make things work that is quite literally true because smaller things that work well don t even need all that many changes on a everyday basis to me its these kind of places that are in real trouble there is not enough work to justify keeping dozens to even hundreds of teams their managements and their hierarchies all working for quite literally doing nothing", "model_tags": [], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "kamaal", "node_time": "2025-08-21T13:25:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972539, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Maybe source of \"AI replacing junior staff\" is the statement AWS CEO made during a private meeting with client.", "normalized_text": "maybe source of ai replacing junior staff is the statement aws ceo made during a private meeting with client", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "geodel", "node_time": "2025-08-21T13:30:13+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972547, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Simple, just replace the CEO with an LLM and it will be singing a different tune :-P", "normalized_text": "simple just replace the ceo with an llm and it will be singing a different tune p", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "einpoklum", "node_time": "2025-08-21T13:31:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972550, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "I would bet that anyone who's worked with these models extensively would agree. I'll never forget the sama AGI posts before o3 launched and the subsequent doomer posting from techies. Feels so stupid in hindsight.", "normalized_text": "i would bet that anyone who s worked with these models extensively would agree i ll never forget the sama agi posts before o3 launched and the subsequent doomer posting from techies feels so stupid in hindsight", "model_tags": ["openai"], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "mac-monet", "node_time": "2025-08-21T13:31:18+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972551, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "> Garman is also not keen on another idea about AI – measuring its value by what percentage of code it contributes at an organization. You really want to believe, maybe even need to believe, that anyone who comes up with this idea in their head has never written a single line of code in their life. It is on its face absurd. And yet I don't doubt for a second that Garman et al. have to fend off legions of hacks who froth at the mouth over this kind of thing.", "normalized_text": "garman is also not keen on another idea about ai – measuring its value by what percentage of code it contributes at an organization you really want to believe maybe even need to believe that anyone who comes up with this idea in their head has never written a single line of code in their life it is on its face absurd and yet i don t doubt for a second that garman et al have to fend off legions of hacks who froth at the mouth over this kind of thing", "model_tags": [], "aspect_hints": ["security"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "jihadjihad", "node_time": "2025-08-21T13:31:20+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972729, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "So to summarize: My boss said we were gonna fire a bunch of people “because AI” as part of some fluff PR to pretend we were actually leaders in AI. We tried that a bit, it was a total mess and we have no clue what we’re doing, I’ve been sent out to walk back our comments.", "normalized_text": "so to summarize my boss said we were gonna fire a bunch of people “because ai” as part of some fluff pr to pretend we were actually leaders in ai we tried that a bit it was a total mess and we have no clue what we’re doing i’ve been sent out to walk back our comments", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "JCM9", "node_time": "2025-08-21T13:45:40+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972760, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "I can't wait for that damn bubble to explode, really... This is becoming unbreathable for hackers.", "normalized_text": "i can t wait for that damn bubble to explode really this is becoming unbreathable for hackers", "model_tags": [], "aspect_hints": ["security"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "Martin_Silenus", "node_time": "2025-08-21T13:48:21+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972768, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "> “How's that going to work when ten years in the future you have no one that has learned anything,” Pretty obvious conclusion that I think anyone who's thought seriously about this situation has already come to. However, I'm not optimistic that most companies will be able to keep themselves from doing this kind of thing, because I think it's become rather clear that it's incredibly difficult for most leadership in 2025 to prioritize long-term sustainability over short-term profitability. That being said, internships/co-ops have been popular from companies that I'm familiar with for quite a while specifically to ensure that there are streams of potential future employees. I wonder if we'll see even more focus on internships in the future, to further skirt around the difficulties in hiring junior developers?", "normalized_text": "“how s that going to work when ten years in the future you have no one that has learned anything ” pretty obvious conclusion that i think anyone who s thought seriously about this situation has already come to however i m not optimistic that most companies will be able to keep themselves from doing this kind of thing because i think it s become rather clear that it s incredibly difficult for most leadership in 2025 to prioritize long term sustainability over short term profitability that being said internships co ops have been popular from companies that i m familiar with for quite a while specifically to ensure that there are streams of potential future employees i wonder if we ll see even more focus on internships in the future to further skirt around the difficulties in hiring junior developers", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "Forricide", "node_time": "2025-08-21T13:48:57+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972783, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Yesterday, I was asked to scrape data from a website. My friend used ChatGPT to scrape data but didn't succeded even spent 3h+. I looked website code and understand with my web knowledge and do some research with LLM. Then I described how to scrape data to LLM it took 30 minutes overall. The LLM cant create best way but you can create with using LLM. Everything is same, at the end of the day you need someone who can really think.", "normalized_text": "yesterday i was asked to scrape data from a website my friend used chatgpt to scrape data but didn t succeded even spent 3h i looked website code and understand with my web knowledge and do some research with llm then i described how to scrape data to llm it took 30 minutes overall the llm cant create best way but you can create with using llm everything is same at the end of the day you need someone who can really think", "model_tags": ["openai"], "aspect_hints": ["privacy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "demirbey05", "node_time": "2025-08-21T13:50:08+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972892, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "\"Learning how to learn\" is by far the most important lesson anyone can obtain. That's not just for AI/software/tech, but for anything.", "normalized_text": "learning how to learn is by far the most important lesson anyone can obtain that s not just for ai software tech but for anything", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "fghorow", "node_time": "2025-08-21T14:00:10+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44972966, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Looks like the AWS CEO has changed religion. A year back, he was aboard the ai-train - saying AI will do all coding in 2 years [1] Finally, the c-suite is getting it. [1]", "normalized_text": "looks like the aws ceo has changed religion a year back he was aboard the ai train saying ai will do all coding in 2 years 1 finally the c suite is getting it 1", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "bwfan123", "node_time": "2025-08-21T14:05:47+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973029, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Junior staff will be necessary but you'll have to defend them from the bean-counters. You need people who can validate LLM-generated code. It takes people with testing and architecture expertise to do so. You only get those things by having humans get expertise through experience.", "normalized_text": "junior staff will be necessary but you ll have to defend them from the bean counters you need people who can validate llm generated code it takes people with testing and architecture expertise to do so you only get those things by having humans get expertise through experience", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "lenerdenator", "node_time": "2025-08-21T14:10:20+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973065, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "That's right it should be used to replace senior stuff right away", "normalized_text": "that s right it should be used to replace senior stuff right away", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "singularity2001", "node_time": "2025-08-21T14:13:35+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973146, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "If AI is so great and had PhD level skills (Musk) then logic says you should be replacing all of your _senior_ developers. That is not the conclusion they reached which implies that the coding ability is not that hot. Q.E.D.", "normalized_text": "if ai is so great and had phd level skills musk then logic says you should be replacing all of your senior developers that is not the conclusion they reached which implies that the coding ability is not that hot q e d", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "stopandth1nk", "node_time": "2025-08-21T14:20:06+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973154, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "I was going to say something, then I realized my cynicism is already at maximum.", "normalized_text": "i was going to say something then i realized my cynicism is already at maximum", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "EternalFury", "node_time": "2025-08-21T14:20:42+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973238, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "At least one CEO seems to get it. Anyone touting this idea of skipping junior talent in favor of AI is dooming their company in the long run. When your senior talent leaves to start their own companies, where will that leave you? I’m not even sure AI is good for any engineer, let alone junior engineers. Software engineering at any level is a journey of discovery and learning. Any time I use it I can hear my algebra teacher telling me not to use a calculator or I won’t learn anything. But overall I’m starting to feel like AI is simply the natural culmination of US economic policy for the last 45 years: short term gains for the top 1% at the expense of a healthy business and the economy in the long term for the rest of us. Jack Welch would be so proud.", "normalized_text": "at least one ceo seems to get it anyone touting this idea of skipping junior talent in favor of ai is dooming their company in the long run when your senior talent leaves to start their own companies where will that leave you i’m not even sure ai is good for any engineer let alone junior engineers software engineering at any level is a journey of discovery and learning any time i use it i can hear my algebra teacher telling me not to use a calculator or i won’t learn anything but overall i’m starting to feel like ai is simply the natural culmination of us economic policy for the last 45 years short term gains for the top 1 at the expense of a healthy business and the economy in the long term for the rest of us jack welch would be so proud", "model_tags": [], "aspect_hints": ["regulation_policy", "business_model"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "pico303", "node_time": "2025-08-21T14:29:07+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973286, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Point is nobody has figured out how much AI can replace humans. People. There is so much of hype out there as every tech celebrity sharing their opinions without responsibility of owning them. We have to wait & see. We could change courses when we know the reality. Until then, do what we know well.", "normalized_text": "point is nobody has figured out how much ai can replace humans people there is so much of hype out there as every tech celebrity sharing their opinions without responsibility of owning them we have to wait see we could change courses when we know the reality until then do what we know well", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "the_arun", "node_time": "2025-08-21T14:32:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973305, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Bravo.. Finally a voice of reason. As someone who works in AI, any CEO who says that AI is going to replace junior workers has no f*cking clue what they are talking about.", "normalized_text": "bravo finally a voice of reason as someone who works in ai any ceo who says that ai is going to replace junior workers has no f cking clue what they are talking about", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "farceSpherule", "node_time": "2025-08-21T14:34:20+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973321, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "My respect for people that take this approach is very high. This is the right way to approach integration of technology. Can SOME people's jobs be replaced by AI. Maybe on paper. But there are tons of tradeoffs to START with that approach and assume fidelity of outcome.", "normalized_text": "my respect for people that take this approach is very high this is the right way to approach integration of technology can some people s jobs be replaced by ai maybe on paper but there are tons of tradeoffs to start with that approach and assume fidelity of outcome", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "tomrod", "node_time": "2025-08-21T14:36:14+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973324, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "AWS CEO says what he has to say to push his own agenda and obviously to align himself with the most currently popular view.", "normalized_text": "aws ceo says what he has to say to push his own agenda and obviously to align himself with the most currently popular view", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "segmondy", "node_time": "2025-08-21T14:36:32+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973347, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Did a double take at Berman bring described as an AI investor. He does invest but a more appropriate description would be \"AI YouTuber\". I don't mean that as a negative, he's doing great work explaining AI to (dev) masses!", "normalized_text": "did a double take at berman bring described as an ai investor he does invest but a more appropriate description would be ai youtuber i don t mean that as a negative he s doing great work explaining ai to dev masses", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "senko", "node_time": "2025-08-21T14:37:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973513, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "\"AGI\" always has been a narrative scam after late 2022.", "normalized_text": "agi always has been a narrative scam after late 2022", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "rvz", "node_time": "2025-08-21T14:50:49+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973597, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "In academia the research pipeline is this Undergraduate -> Graduate Student -> Post-doc -> Tenure/Senior Some exceptions occur for people getting Tenure without post doc or people doing some other things like taking undergraduate in one or two years. But no one expect that we for whole skip the first two and then get any senior researchers. The same idea applies anywhere, the rule is that if you don't have juniors then you don't get seniors so better prepare your bot to do everything.", "normalized_text": "in academia the research pipeline is this undergraduate graduate student post doc tenure senior some exceptions occur for people getting tenure without post doc or people doing some other things like taking undergraduate in one or two years but no one expect that we for whole skip the first two and then get any senior researchers the same idea applies anywhere the rule is that if you don t have juniors then you don t get seniors so better prepare your bot to do everything", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "elashri", "node_time": "2025-08-21T14:57:42+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973640, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "I completely agree. On a side note.. ya’ll must be prompt wizards if you can actually use the LLM code. I use it for debugging sometimes to get an idea, or a quick sketch up of an UI. As for actual code.. the code it writes is a huge mess of spaghetti code, overly verbose, with serious performance and security risks, and complete misunderstanding of pretty much every design pattern I give it..", "normalized_text": "i completely agree on a side note ya’ll must be prompt wizards if you can actually use the llm code i use it for debugging sometimes to get an idea or a quick sketch up of an ui as for actual code the code it writes is a huge mess of spaghetti code overly verbose with serious performance and security risks and complete misunderstanding of pretty much every design pattern i give it", "model_tags": [], "aspect_hints": ["accuracy_reliability", "security", "usability_ux", "regulation_policy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "moi2388", "node_time": "2025-08-21T15:01:50+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973705, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Agreed. LLMs are actually -the worst- at doing very specific repetitive things. It'd be much more appropriate for one to replace the CEO (the generalist) rather than junior staff.", "normalized_text": "agreed llms are actually the worst at doing very specific repetitive things it d be much more appropriate for one to replace the ceo the generalist rather than junior staff", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "mvkel", "node_time": "2025-08-21T15:05:42+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44973894, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Remark is at 12:02 in the video.", "normalized_text": "remark is at 12 02 in the video", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "latexr", "node_time": "2025-08-21T15:19:30+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44974117, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "As always, the truth is somewhere in the middle. AI is not going to replace everyone tomorrow, but I also don't think we can ignore productivity improvements from AI. It's not going to replace engineers completely now or in the near future, but AI will probably reduce the number of engineers needed to solve a problem.", "normalized_text": "as always the truth is somewhere in the middle ai is not going to replace everyone tomorrow but i also don t think we can ignore productivity improvements from ai it s not going to replace engineers completely now or in the near future but ai will probably reduce the number of engineers needed to solve a problem", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "tananaev", "node_time": "2025-08-21T15:37:24+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44974218, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Finally someone from a top position said this. After all the trash the CEOs have been spewing and sensationalizing every AI improvement, for a change, a person in a non-engineering role speaks the truth.", "normalized_text": "finally someone from a top position said this after all the trash the ceos have been spewing and sensationalizing every ai improvement for a change a person in a non engineering role speaks the truth", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "thallavajhula", "node_time": "2025-08-21T15:45:10+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44974249, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": ">teach “how do you think and how do you decompose problems” That's rich coming from AWS! I think he meant \"how do you think about adding unnecessary complexity to problems such that it can enable the maximum amount of meetings, design docs and promo packages for years to come\"!", "normalized_text": "teach “how do you think and how do you decompose problems” that s rich coming from aws i think he meant how do you think about adding unnecessary complexity to problems such that it can enable the maximum amount of meetings design docs and promo packages for years to come", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "lbrito", "node_time": "2025-08-21T15:47:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44974278, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "I heard from several sources that AWS has a mandate to put GenAI in everything and force everyone to use it so... yeah.", "normalized_text": "i heard from several sources that aws has a mandate to put genai in everything and force everyone to use it so yeah", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "oblio", "node_time": "2025-08-21T15:50:26+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44974315, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Are we trying to guilt trip corporations to do socially responsible thing regarding young workers skill acquisition? Haven't we learned that it almost always ends up in hollow PR and marketing theater? Basically the solution to this is extending education so that people entering workforce are already at senior level. Of course this can't be financed by the students, because their careers get shortened by longer education. So we need higher taxes on the entities that reap the new spoils. Namely those corporations that now can pass on hiring junior employees.", "normalized_text": "are we trying to guilt trip corporations to do socially responsible thing regarding young workers skill acquisition haven t we learned that it almost always ends up in hollow pr and marketing theater basically the solution to this is extending education so that people entering workforce are already at senior level of course this can t be financed by the students because their careers get shortened by longer education so we need higher taxes on the entities that reap the new spoils namely those corporations that now can pass on hiring junior employees", "model_tags": [], "aspect_hints": ["usability_ux", "ethics", "business_model"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "scotty79", "node_time": "2025-08-21T15:53:16+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44974351, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "It is too late it is already happening. The evolution of tech field is people being more experienced and not AI. But AI will be there for questions and easy one liners. Properly formalized documentation, even TLDRs.", "normalized_text": "it is too late it is already happening the evolution of tech field is people being more experienced and not ai but ai will be there for questions and easy one liners properly formalized documentation even tldrs", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "Sparkyte", "node_time": "2025-08-21T15:57:08+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44974438, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "The cost of not hiring and training juniors is trying to retain your seniors while continuously resetting expectations with them about how they are the only human accountable for more and more stuff.", "normalized_text": "the cost of not hiring and training juniors is trying to retain your seniors while continuously resetting expectations with them about how they are the only human accountable for more and more stuff", "model_tags": [], "aspect_hints": ["cost_price"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "nlawalker", "node_time": "2025-08-21T16:05:37+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44974707, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Unfortunately, this is the kind of view that is at once completely correct and anathema to private equity because they can squeeze a next quarter return by firing a chunk of the labor force.", "normalized_text": "unfortunately this is the kind of view that is at once completely correct and anathema to private equity because they can squeeze a next quarter return by firing a chunk of the labor force", "model_tags": [], "aspect_hints": ["accuracy_reliability", "usability_ux"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "tehjoker", "node_time": "2025-08-21T16:28:33+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44975343, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "In the last few months we have worked with startups who have vibe coded themselves into an abyss. Either because they never made the correct hires in the first place or they let technical talent go. [1] The thinking was that they could iterate faster, ship better code, and have an always on 10x engineer in the form of Claude code. I've observed perfectly rational founders become addicted to the dopamine hit as they see Claude code output what looks like weeks or years of software engineering work. It's overgenerous to allow anyone to believe AI can actually \"think\" or \"reason\" through complex problems. Perhaps we should be measuring time saved typing rather than cognition. [1] vibebusters.com", "normalized_text": "in the last few months we have worked with startups who have vibe coded themselves into an abyss either because they never made the correct hires in the first place or they let technical talent go 1 the thinking was that they could iterate faster ship better code and have an always on 10x engineer in the form of claude code i ve observed perfectly rational founders become addicted to the dopamine hit as they see claude code output what looks like weeks or years of software engineering work it s overgenerous to allow anyone to believe ai can actually think or reason through complex problems perhaps we should be measuring time saved typing rather than cognition 1 vibebusters com", "model_tags": ["anthropic"], "aspect_hints": ["performance_speed", "accuracy_reliability", "regulation_policy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "jryio", "node_time": "2025-08-21T17:11:32+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44975475, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "A lot of companies that have stopped hiring junior employees are going to be really hurting in a couple of years, once all of their seniors have left and they have no replacements trained and ready to go.", "normalized_text": "a lot of companies that have stopped hiring junior employees are going to be really hurting in a couple of years once all of their seniors have left and they have no replacements trained and ready to go", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "dcchambers", "node_time": "2025-08-21T17:22:08+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44975629, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "I'm a technical co-founder rapidly building a software product. I've been coding since 2006. We have every incentive to have AI just build our product. But it can't. I keep trying to get it to...but it can't. Oh, it tries, but the code it writes is often overly complex and overly-verbose. I started out being amazed at the way it could solve problems, but that's because I gave it small, bounded, well-defined problems. But as expectations with agentic coding rose, I gave it more abstract problems and it quickly hit the ceiling. As was said, the engineering task is identifying the problem and decomposing it. I'd love to hear from someone who's used agentic coding with more success. So far I've tried Co-pilot, Windsurf, and Alex sidebar for Xcode projects. The most success I have is via a direct question with details to Gemini in the browser, usually a variant of \"write a function to do X\"", "normalized_text": "i m a technical co founder rapidly building a software product i ve been coding since 2006 we have every incentive to have ai just build our product but it can t i keep trying to get it to but it can t oh it tries but the code it writes is often overly complex and overly verbose i started out being amazed at the way it could solve problems but that s because i gave it small bounded well defined problems but as expectations with agentic coding rose i gave it more abstract problems and it quickly hit the ceiling as was said the engineering task is identifying the problem and decomposing it i d love to hear from someone who s used agentic coding with more success so far i ve tried co pilot windsurf and alex sidebar for xcode projects the most success i have is via a direct question with details to gemini in the browser usually a variant of write a function to do x", "model_tags": ["google"], "aspect_hints": ["usability_ux", "regulation_policy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "cwoolfe", "node_time": "2025-08-21T17:32:39+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44975840, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Current generation of AI agents are great at writing a block of codes. Similar to writing a great paragraph. Know your tools.", "normalized_text": "current generation of ai agents are great at writing a block of codes similar to writing a great paragraph know your tools", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "lvl155", "node_time": "2025-08-21T17:48:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44975855, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "AWS is a very infrastructure intensive project with extremely tight SLAs, and no UI, makes a lot of sense.", "normalized_text": "aws is a very infrastructure intensive project with extremely tight slas and no ui makes a lot of sense", "model_tags": [], "aspect_hints": ["usability_ux"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "mhh__", "node_time": "2025-08-21T17:50:12+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44977648, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Perhaps I'm too cynical about messages coming out of FAANG. But I have a feeling they are saying things to placate the rising anger over mass layoffs, h1b abuse, and offshoring. I hope I'm wrong.", "normalized_text": "perhaps i m too cynical about messages coming out of faang but i have a feeling they are saying things to placate the rising anger over mass layoffs h1b abuse and offshoring i hope i m wrong", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "alecco", "node_time": "2025-08-21T20:26:51+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44981837, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Makes sense. Instead of replacing junior staff, they should be trained to use AI to get more done in less time. In next 2-3 years they will be experts doing good work with high productivity.", "normalized_text": "makes sense instead of replacing junior staff they should be trained to use ai to get more done in less time in next 2 3 years they will be experts doing good work with high productivity", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "subhashp", "node_time": "2025-08-22T07:24:44+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44982050, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "> “I think the skills that should be emphasized are how do you think for yourself? How do you develop critical reasoning for solving problems? How do you develop creativity? How do you develop a learning mindset that you're going to go learn to do the next thing?” In the Swedish schoolsystem, the idea for the past 20 years has been exactly this, that is to try to teach critical thinking, reasoning, problem solving etc rather than hard facts. The results has been...not great. We discovered that reasoning and critical thinking is impossible without a foundational knowledge about what to be critical about. I think the same can be said about software development.", "normalized_text": "“i think the skills that should be emphasized are how do you think for yourself how do you develop critical reasoning for solving problems how do you develop creativity how do you develop a learning mindset that you re going to go learn to do the next thing ” in the swedish schoolsystem the idea for the past 20 years has been exactly this that is to try to teach critical thinking reasoning problem solving etc rather than hard facts the results has been not great we discovered that reasoning and critical thinking is impossible without a foundational knowledge about what to be critical about i think the same can be said about software development", "model_tags": [], "aspect_hints": ["regulation_policy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "cambaceres", "node_time": "2025-08-22T08:11:43+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44982406, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Two things that will hurt us in the long run, working from home and AI. I'm generally in favour of both, but with newbies it hurts them as they are not spending enough face to face time with seniors to learn on the job. And AI will hurt them in their own development and with it taking over the tasks they would normally cut their teeth on. We'll have to find newer ways of helping the younger generation get in the door.", "normalized_text": "two things that will hurt us in the long run working from home and ai i m generally in favour of both but with newbies it hurts them as they are not spending enough face to face time with seniors to learn on the job and ai will hurt them in their own development and with it taking over the tasks they would normally cut their teeth on we ll have to find newer ways of helping the younger generation get in the door", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "VagabundoP", "node_time": "2025-08-22T09:10:55+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44983038, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "> I think the skills that should be emphasized are how do you think for yourself? Independent thinking is indeed the most important skill to have as a human. However, I sympathize for the younger generations, as they have become the primary target of this new technology that looks to make money by completely replacing some of their thinking. I have a small child and took her to see a disney film. Google produced a very high quality long form advert during the previews. The ad portrays a lonely young man looking for something to do in the evening that meets his explicit preferences. The AI suggests a concert, he gets there and locks eyes with an attractive young woman. Sending a message to lonely young men that AI will help reduce loneliness. The idea that you don't have to put any effort into gaining adaptive social skills to cure your own loneliness is scary to me. The advert is complete survivor bias. For each success in curing your boredom, how many failures are there with lonely young depressed men talking to their phone instead of friends? Critical thinking starts at home with the parents. Children will develop beliefs from their experience and confirm those beliefs with an authority figure. You can start teaching mindfulness to children at age 7. Teaching children mindfulness requires a tremendous amount of patience. Now the consequence for lacking patience is outsourcing your Childs critical thinking to AI.", "normalized_text": "i think the skills that should be emphasized are how do you think for yourself independent thinking is indeed the most important skill to have as a human however i sympathize for the younger generations as they have become the primary target of this new technology that looks to make money by completely replacing some of their thinking i have a small child and took her to see a disney film google produced a very high quality long form advert during the previews the ad portrays a lonely young man looking for something to do in the evening that meets his explicit preferences the ai suggests a concert he gets there and locks eyes with an attractive young woman sending a message to lonely young men that ai will help reduce loneliness the idea that you don t have to put any effort into gaining adaptive social skills to cure your own loneliness is scary to me the advert is complete survivor bias for each success in curing your boredom how many failures are there with lonely young depressed men talking to their phone instead of friends critical thinking starts at home with the parents children will develop beliefs from their experience and confirm those beliefs with an authority figure you can start teaching mindfulness to children at age 7 teaching children mindfulness requires a tremendous amount of patience now the consequence for lacking patience is outsourcing your childs critical thinking to ai", "model_tags": ["google"], "aspect_hints": ["usability_ux", "ethics", "regulation_policy"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "lazarus01", "node_time": "2025-08-22T11:05:54+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44983438, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "Rather than AI that can function as many junior coders to enable a senior programmer to be more efficient. Having AI function as a senior programmer for lots of junior programmers that helps them learn and limits the interruptions for human senior coders makes so much more sense.", "normalized_text": "rather than ai that can function as many junior coders to enable a senior programmer to be more efficient having ai function as a senior programmer for lots of junior programmers that helps them learn and limits the interruptions for human senior coders makes so much more sense", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "newsclues", "node_time": "2025-08-22T11:57:59+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44987429, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "If AI is truly this effective, we would be selling 10x-10Kx more stuff, building 10x more features (and more quickly), improving quality & reliability 10x. There would be no reason to fire anyone because the owners would be swimming in cash. I'm talking good old-fashioned greed here. You don't fire people if you anticipate a 100x growth. Who cares about saving 0.1% of your money in 10 years? You want to sell 100x / 1000x/ 10000x more . So the story is hard to swallow. The real reason is as usual, they anticipate a downturn and want to keep earnings stable.", "normalized_text": "if ai is truly this effective we would be selling 10x 10kx more stuff building 10x more features and more quickly improving quality reliability 10x there would be no reason to fire anyone because the owners would be swimming in cash i m talking good old fashioned greed here you don t fire people if you anticipate a 100x growth who cares about saving 0 1 of your money in 10 years you want to sell 100x 1000x 10000x more so the story is hard to swallow the real reason is as usual they anticipate a downturn and want to keep earnings stable", "model_tags": [], "aspect_hints": ["accuracy_reliability", "usability_ux"], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "tonymet", "node_time": "2025-08-22T17:45:50+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
{"id": 44987433, "root_story_id": 44972151, "node_type": "comment", "comment_depth": 1, "text": "I do not agreed. Its was not even worth without llm. Junior will always take a LOT of time from seniors. and when the junior become good enough, he will find another job. and the senior will be stuck in this loop. junior + llm, it even worse. they become prompt engineers", "normalized_text": "i do not agreed its was not even worth without llm junior will always take a lot of time from seniors and when the junior become good enough he will find another job and the senior will be stuck in this loop junior llm it even worse they become prompt engineers", "model_tags": [], "aspect_hints": [], "context": {"root_title": "AWS CEO says using AI to replace junior staff is 'Dumbest thing I've ever heard'", "root_author": "JustExAWS", "root_url": "https://www.theregister.com/2025/08/21/aws_ceo_entry_level_jobs_opinion/", "node_author": "fabioyy", "node_time": "2025-08-22T17:46:35+00:00"}, "prompt": "You are an expert analyst. Given the text and metadata, output STRICT JSON with this schema:\n{{\n  \"id\": <int>,\n  \"sentiment\": \"positive|neutral|negative|mixed\",\n  \"aspects\": [\n    {{\n      \"aspect\": <string from allowed list>,\n      \"present\": true|false,\n      \"evidence\": <string|null>,\n      \"sentiment\": <sentiment|null>,\n      \"confidence\": <0-1>,\n      \"implicit\": true|false\n    }}\n  ]\n}}\n\nRules:\n1. Aspect list = performance_speed, accuracy_reliability, security, privacy, usability_ux, cost_price, ethics, regulation_policy, community_tone, business_model, other.\n2. Detect aspects first (binary), then rate sentiment only when present/implicit.\n3. Use \"other\" for valid but uncategorized aspects.\n4. Consider metadata (root story title, author, depth) for context.\n5. If the text is empty or only metadata, emit sentiment \"neutral\" with all aspects present=false.\n", "taxonomy": [{"key": "performance_speed", "description": "Latency, throughput, efficiency, resource use"}, {"key": "accuracy_reliability", "description": "Correctness, hallucinations, evaluation quality"}, {"key": "security", "description": "Vulnerabilities, exploits, safeguards"}, {"key": "privacy", "description": "Data sharing, user privacy, surveillance"}, {"key": "usability_ux", "description": "User experience, workflow, ease of use"}, {"key": "cost_price", "description": "Pricing, licensing, monetization burden"}, {"key": "ethics", "description": "Bias, fairness, responsible use, societal impact"}, {"key": "regulation_policy", "description": "Law, policy, governance, compliance"}, {"key": "community_tone", "description": "Tone of discourse, collaboration, reputation"}, {"key": "business_model", "description": "Strategy, revenue, market dynamics"}, {"key": "other", "description": "Anything else relevant"}]}
